{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f55586-8f38-4083-bf9c-64ef78d5cf81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# パッケージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32f65d-4ce0-4a55-bc95-af30eed63a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    from tqdm.notebook import tqdm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import lightgbm as lgb\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    from tqdm.notebook import tqdm\n",
    "    import re\n",
    "    from urllib.request import urlopen\n",
    "    import optuna.integration.lightgbm as lgb_o\n",
    "    from itertools import combinations, permutations\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    from tkinter import messagebox\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    import os\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.webdriver.support.ui import Select\n",
    "    from selenium.webdriver.chrome import service as fs\n",
    "    from selenium.webdriver.common.by import By\n",
    "    import time\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import calendar\n",
    "    import glob\n",
    "    import schedule\n",
    "    from selenium.webdriver.common.alert import Alert\n",
    "    from IPython.display import clear_output\n",
    "    from selenium.common.exceptions import NoSuchElementException, NoAlertPresentException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dda94-4e5b-4939-8c19-b543f76df1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027811d-4675-40e0-bb8b-5daa97953288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    #クラス\n",
    "    class DataProcessor:\n",
    "        \"\"\"    \n",
    "        Attributes:\n",
    "        ----------\n",
    "        data : rawデータ\n",
    "        data_i : merge_horse_infomerge_horse_info後のデータ\n",
    "        data_j : merge_jockey_info後のデータ\n",
    "        data_p : preprocessing後のデータ\n",
    "        data_h : merge_horse_results後のデータ\n",
    "        data_cp : merge_horse_results後のデータ        \n",
    "        data_pe : concat_past_data後のデータ\n",
    "        data_c : process_categorical後のデータ\n",
    "        no_peds: Numpy.array\n",
    "            merge_pedsを実行した時に、血統データが存在しなかった馬のhorse_id一覧\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.data = pd.DataFrame()\n",
    "            self.data_i = pd.DataFrame()\n",
    "            self.data_j = pd.DataFrame()\n",
    "            self.data_p = pd.DataFrame()\n",
    "            self.data_h = pd.DataFrame()\n",
    "            self.data_cp = pd.DataFrame()\n",
    "            self.data_pe = pd.DataFrame()\n",
    "            self.data_c = pd.DataFrame()\n",
    "\n",
    "        def merge_horse_info(self, hi):\n",
    "            not_exist = list(set(self.data['horse_id']) - set(hi.horse_info.index))\n",
    "            if len(not_exist)>0:\n",
    "                print('not_exist_horse_info\\n',not_exist)\n",
    "                h_info = HorseResults.scrape(not_exist,False)\n",
    "                # h_result.to_pickle('pickle/syutuba/new_h_info/h_result_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "                h_info.to_pickle('pickle/syutuba/new_h_info/h_info_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "                #read_pickle後と一致させる\n",
    "                horse_info = h_info[['生年月日','調教師_id','馬主_id','生産者_id','近親馬_id1','近親馬_id2']]\n",
    "                condf = pd.concat([hi.horse_info,horse_info])\n",
    "                condf.to_pickle('pickle/syutuba/latest/h_info_latest.pickle')\n",
    "                self.data_i = pd.merge(self.data,condf,how='left',left_on='horse_id',right_index=True)\n",
    "            else:\n",
    "                self.data_i = pd.merge(self.data,hi.horse_info,how='left',left_on='horse_id',right_index=True)\n",
    "\n",
    "        def merge_jockey_info(self,jr,past_num):\n",
    "            not_exist = list(set(self.data['jockey_id']) - set(jr.jockey_results.index))\n",
    "\n",
    "            if len(not_exist)>0:\n",
    "                print('not_exist_jockey_id\\n',not_exist)\n",
    "                j_id = jockey_results.scrape(not_exist)\n",
    "                j_id.to_pickle('pickle/syutuba/new_j_id/j_id_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "                j_id_df = j_id[['年度', '順位', '1着', '2着', '3着', '着外', '重賞_出走', '重賞_勝利', '特別_出走', '特別_勝利',\\\n",
    "                                  '平場_出走', '平場_勝利', '芝_出走', '芝_勝利', 'ダート_出走', 'ダート_勝利', '勝率', '連対率',\\\n",
    "                                  '複勝率', '収得賞金(万円)']]\n",
    "                condf = pd.concat([jr.jockey_results,j_id_df])\n",
    "                condf.to_pickle('pickle/syutuba/latest/jockey_id_latest.pickle')\n",
    "                jockey_df = condf.copy()\n",
    "\n",
    "            else:\n",
    "                jockey_df = jr.jockey_results.copy()\n",
    "\n",
    "            jockey_id_list = jockey_df.index.unique()\n",
    "            jockey_df.reset_index(inplace=True)\n",
    "            jockey_df.rename(columns={'index': 'jockey_id'},inplace=True)\n",
    "            jockey_df['年度'].replace('累計',0,inplace=True)\n",
    "            jockey_df['年度'] = jockey_df['年度'].astype(\"int16\")\n",
    "\n",
    "            results = self.data_i.copy()\n",
    "            results['年度']=results['date'].str[:4].astype(\"int16\")\n",
    "            max_nen = results['年度'].unique().max()\n",
    "            min_nen = results['年度'].unique().min()\n",
    "            results.reset_index(inplace=True)\n",
    "            results.rename(columns={'index': 'race_id'},inplace=True)\n",
    "            results.index.name = None\n",
    "\n",
    "            #前年から順に抜き出し、指定した年数分のデータをくっつける\n",
    "            for i in range(max_nen,min_nen-1,-1):\n",
    "                # print(i)\n",
    "                condf = results[results['年度']==i]\n",
    "\n",
    "                for past in range(1,past_num+1):\n",
    "                    # print('past',i-past)\n",
    "                    tardf = jockey_df[jockey_df['年度']==i-past]\n",
    "                    tardf = tardf.add_suffix('_{}'.format(past))\n",
    "                    condf = pd.merge(condf,tardf,how='left',left_on=['jockey_id'],right_on =['jockey_id_{}'.format(past)])\n",
    "                    condf.drop('jockey_id_{}'.format(past), axis=1, inplace=True)   \n",
    "                #初回は結合先が無いため、代入\n",
    "                if i ==max_nen:\n",
    "                    concatdf=condf\n",
    "                else:\n",
    "                    concatdf = pd.concat([concatdf,condf])\n",
    "\n",
    "            concatdf.set_index('race_id',inplace=True)\n",
    "            concatdf.index.name = None\n",
    "\n",
    "            nendo_col=[]\n",
    "            for i in range(past_num):\n",
    "                nendo_col.append('年度_{}'.format(i+1))\n",
    "\n",
    "            concatdf.drop(nendo_col, axis=1, inplace=True)\n",
    "\n",
    "            self.data_j = concatdf\n",
    "\n",
    "            # del self.data_i\n",
    "            # del self.data\n",
    "        def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all'],rt=pd.DataFrame()):\n",
    "            \"\"\"\n",
    "            馬の過去成績データから、\n",
    "            n_samples_listで指定されたレース分の着順と賞金の平均を追加してdata_hに返す\n",
    "            Parameters:\n",
    "            ----------\n",
    "            hr : HorseResults\n",
    "                馬の過去成績データ\n",
    "            n_samples_list : list, default [5, 9, 'all']\n",
    "                過去何レース分追加するか\n",
    "            rt：results_p\n",
    "                出馬テーブルを作成する際に過去resultsをくっつけてSPIを算出するために必要となる\n",
    "\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            日付を取らないとdata_pに含まれるレース全レースを対象にしている\n",
    "            リークが起きていないかは確認すること\n",
    "            #ここでresultデータをhrクラスへ渡すために一度入れる\n",
    "            #SPI算出のために出馬表をマージする際にはresultsテーブルを必要とする\n",
    "            \"\"\"\n",
    "\n",
    "            if len(rt) != 0:\n",
    "                self.data_p.reset_index(inplace = True)\n",
    "                r_data_p = rt.copy()\n",
    "                r_data_p.reset_index(inplace = True)\n",
    "                #出馬テーブルに過去resultsをくっつける\n",
    "                #出馬テーブルと重複しているレースがある場合は、削除\n",
    "                r_data_p = r_data_p[~r_data_p['index'].isin(self.data_p['index'].unique())]\n",
    "                self.data_h = pd.concat([self.data_p,r_data_p],axis = 0)\n",
    "                self.data_h.set_index('index',inplace = True)\n",
    "                self.data_p.set_index('index',inplace = True)\n",
    "                # print(self.data_h[self.data_h.index=='202207040410'])\n",
    "                #rtを出馬テーブルに置き換え\n",
    "                rt = self\n",
    "            else:\n",
    "                self.data_h = self.data_p.copy()\n",
    "                rt=None\n",
    "\n",
    "            for n_samples in n_samples_list:\n",
    "                self.data_h = hr.merge_all(self.data_h, n_samples=n_samples,rt=rt)\n",
    "                # self.data_h = hr.merge_all(r_data_p, n_samples=n_samples,rt=rt)\n",
    "\n",
    "\n",
    "            #6/6追加： 馬の出走間隔追加\n",
    "            # self.data_h['interval'] = (self.data_h['date'] - self.data_h['latest']).dt.days\n",
    "            self.data_h.insert(21, 'interval', (self.data_h['date'] - self.data_h['latest']).dt.days)\n",
    "\n",
    "            #class変更 whereはnanだったものをnanに戻す\n",
    "            self.data_h.insert(21, 'change_class', self.data_h['class']!=self.data_h['past_class'])\n",
    "            self.data_h['change_class'].where(~self.data_h['past_class'].isna(),np.nan, inplace=True)\n",
    "            self.data_h.insert(21, 'Past_class',self.data_h['past_class'])#順序変更のため\n",
    "\n",
    "            #開催を削除\n",
    "            # self.data_h.drop(['latest','騎手','past_jokey','past_race_type','len_cange','past_course_len','past_class'], axis=1, inplace=True)\n",
    "            self.data_h.drop(['latest','騎手','past_class'], axis=1, inplace=True)\n",
    "\n",
    "            # del self.data_j\n",
    "\n",
    "        def concat_past_data(self,hr,past_num):\n",
    "\n",
    "            def merge_past_data(df,myhr,day):\n",
    "\n",
    "                #１日分のresultsとhorse_id\n",
    "                # Aday_results = df.query('date == @day')\n",
    "                Aday_results = df[df['date'] == day]\n",
    "                Aday_hid_list = Aday_results['horse_id'].unique()\n",
    "\n",
    "                day_hr = myhr[myhr['date'] < day]\n",
    "\n",
    "                speedlist=[] \n",
    "                for target_hid in Aday_hid_list:\n",
    "\n",
    "                    tardf = day_hr[day_hr['horse_id'] == target_hid].head(past_num).values\n",
    "\n",
    "                    #arrayの一次元配列に変換\n",
    "                    data_np = np.ravel(tardf)\n",
    "\n",
    "                    data_len = len(tardf)\n",
    "                    if data_len==0: #過去走データがない場合\n",
    "                        conarray=empty_nan\n",
    "                    else:\n",
    "                        empty=np.array([np.nan] * col_num * (past_num-data_len))\n",
    "                        conarray= np.concatenate([data_np,empty])\n",
    "\n",
    "                    speedlist.append(conarray)\n",
    "\n",
    "                afterdf = pd.DataFrame(speedlist,columns=suffix_list)\n",
    "                afterdf['horse_id_1p'] = afterdf['horse_id_1p'].astype(str)#nanのときにmergeエラー吐くため\n",
    "                mergdf = pd.merge(Aday_results,afterdf,how='left',left_on='horse_id',right_on = 'horse_id_1p')\n",
    "\n",
    "                return mergdf\n",
    "\n",
    "            def create_list(col_list):\n",
    "                suffix_list , all_col = [],[]\n",
    "\n",
    "                def suffix(n,m):\n",
    "                    return n+'_{}p'.format(m)\n",
    "\n",
    "                for num in range(1,past_num+1):\n",
    "                    m = [str(num)] * len(col_list)\n",
    "                    all_col.append(list(map(suffix, col_list,m)))\n",
    "\n",
    "                return np.ravel(all_col)        \n",
    "\n",
    "            df = self.data_h.copy()\n",
    "            # df.reset_index(inplace=True)\n",
    "            # df = df.rename(columns={'index': 'race_id'})\n",
    "\n",
    "            myhr = hr.horse_results_p.copy()\n",
    "            myhr.reset_index(inplace=True)\n",
    "            myhr = myhr.rename(columns={'index': 'horse_id'})\n",
    "            #category型にすることで抽出処理を高速化する\n",
    "            myhr['horse_id'] = myhr['horse_id'].astype('category')\n",
    "\n",
    "            col_list=myhr.columns\n",
    "\n",
    "            col_num=len(col_list)\n",
    "            # print(col_list)\n",
    "\n",
    "            suffix_list=create_list(col_list)\n",
    "\n",
    "            #resultsからすべての日付を取得\n",
    "            day_list = df['date'].unique()\n",
    "            empty_nan = np.array([np.nan] * col_num * past_num).astype('object')\n",
    "\n",
    "            merged_df = pd.concat([merge_past_data(df,myhr,day) for day in tqdm(day_list)])\n",
    "\n",
    "            self.data_cp = merged_df\n",
    "\n",
    "            #複数list宣言方法\n",
    "            horse_id_col, jockey_name_col , date_col = [],[],[]\n",
    "            for i in range(past_num):\n",
    "                horse_id_col.append('horse_id_{}p'.format(i+1))\n",
    "                jockey_name_col.append('騎手_{}p'.format(i+1))\n",
    "                date_col.append('date_{}p'.format(i+1))\n",
    "\n",
    "            self.data_cp.drop(horse_id_col + jockey_name_col + date_col, axis=1, inplace=True)\n",
    "\n",
    "            # del self.data_h\n",
    "\n",
    "        def merge_peds(self, peds):\n",
    "            \"\"\"\n",
    "            5世代分血統データを追加してdata_peに返す\n",
    "            Parameters:\n",
    "            ----------\n",
    "            peds : Peds.peds_e\n",
    "                Pedsクラスで加工された血統データ。\n",
    "            \"\"\"\n",
    "\n",
    "            self.data_pe = self.data_cp.merge(peds, left_on='horse_id',right_index=True,how='left')\n",
    "\n",
    "        def process_categorical(self, le_horse, le_jockey,le_class, le_place, results_m\\\n",
    "                                ,le_trainer,le_horseowner,le_producer,le_relative1,le_relative2,le_kai,le_day,past_race_num):\n",
    "\n",
    "            \"\"\"\n",
    "            カテゴリ変数を処理してdata_cに返す\n",
    "            Parameters:\n",
    "            ----------\n",
    "            le_horse : sklearn.preprocessing.LabelEncoder\n",
    "                horse_idを0始まりの整数に変換するLabelEncoderオブジェクト\n",
    "            le_jockey : sklearn.preprocessing.LabelEncoder\n",
    "                jockey_idを0始まりの整数に変換するLabelEncoderオブジェクト。\n",
    "            results_m : Results.data_pe\n",
    "                ダミー変数化のとき、ResultsクラスとShutubaTableクラスで列を合わせるためのもの\n",
    "            le_class : sklearn.preprocessing.LabelEncoder\n",
    "                classを0始まりの整数に変換するLabelEncoderオブジェクト。\n",
    "            \"\"\"\n",
    "            df = self.data_pe.copy()\n",
    "\n",
    "            #存在していないidをmask関数で抽出してclassesに追加し、エンコードする。\n",
    "            #末尾に追加するための処理\n",
    "            def masking(df,le_encoder,colname,colname2):\n",
    "                mask_horse = df[colname].isin(le_encoder.classes_)\n",
    "                new_horse_id = df[colname].mask(mask_horse).dropna().unique()\n",
    "                le_encoder.classes_ = np.concatenate([le_encoder.classes_, new_horse_id])\n",
    "                #全体がnanの場合にfloat型になりtransformでエラーになるためobject型に変換\n",
    "                df[colname2] = df[colname2].astype('object')\n",
    "                df[colname2] = le_encoder.transform(df[colname2])\n",
    "                df[colname2] = df[colname2].astype('category')\n",
    "                return le_encoder\n",
    "\n",
    "            for num in range(past_race_num):\n",
    "                masking(df,le_jockey,'jockey_id_{}p'.format(num+1),'jockey_id_{}p'.format(num+1))\n",
    "                masking(df,le_place,'place_{}p'.format(num+1),'place_{}p'.format(num+1))\n",
    "                masking(df,le_kai,'kai_{}p'.format(num+1),'kai_{}p'.format(num+1))\n",
    "                masking(df,le_day,'day_{}p'.format(num+1),'day_{}p'.format(num+1))\n",
    "\n",
    "            self.le_horse = masking(df,le_horse,'horse_id','horse_id')\n",
    "            self.le_jockey = masking(df,le_jockey,'jockey_id','jockey_id')            \n",
    "            # masking(df,le_jockey,'jockey_id','past_jockey')\n",
    "            self.le_class = masking(df,le_class,'class','class')\n",
    "            self.le_class = masking(df,le_class,'class','Past_class')\n",
    "            self.le_place = masking(df,le_place,'place','place')\n",
    "            self.le_trainer = masking(df,le_trainer,'調教師_id','調教師_id')\n",
    "            self.le_horseowner = masking(df,le_horseowner,'馬主_id','馬主_id')\n",
    "            self.le_producer = masking(df,le_producer,'生産者_id','生産者_id')\n",
    "            self.le_relative1 = masking(df,le_relative1,'近親馬_id1','近親馬_id1')\n",
    "            self.le_relative2 = masking(df,le_relative2,'近親馬_id2','近親馬_id2')\n",
    "\n",
    "            #------------------------------------------------------------------------------------------------------        \n",
    "            #そのほかのカテゴリ変数をpandasのcategory型に変換してからダミー変数化\n",
    "            #列を一定にするため\n",
    "            #nullを含んでいる場合は変換できないため\"Na\"埋め\n",
    "            def change_categorical(df,results_m,colname):\n",
    "                results_m[colname].fillna('Na',inplace =True)\n",
    "                unique_value = results_m[colname].unique()\n",
    "                df[colname] = pd.Categorical(df[colname], unique_value)\n",
    "                return df\n",
    "\n",
    "            weather_past = []\n",
    "            race_type_past = []\n",
    "            ground_state_past = []\n",
    "            for num in range(past_race_num):\n",
    "                weather_past.append('weather_{}p'.format(num+1))\n",
    "                race_type_past.append('race_type_{}p'.format(num+1))\n",
    "                ground_state_past.append('ground_state_{}p'.format(num+1))\n",
    "\n",
    "            columns_name=['weather', 'race_type', 'ground_state', '性','race_round','change_class']      \n",
    "            columns_name = columns_name+weather_past+race_type_past+ground_state_past\n",
    "\n",
    "            for colname in columns_name:\n",
    "                df = change_categorical(df,results_m,colname)\n",
    "\n",
    "            df = pd.get_dummies(df, columns=columns_name)\n",
    "\n",
    "            self.data_c = df\n",
    "    class Results(DataProcessor):\n",
    "        def __init__(self, results):\n",
    "            super(Results, self).__init__()\n",
    "            self.data = results\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        @staticmethod\n",
    "        def scrape(race_id_list):\n",
    "            \"\"\"\n",
    "            レース結果データをスクレイピングする関数\n",
    "            Parameters:\n",
    "            ----------\n",
    "            race_id_list : list\n",
    "                レースIDのリスト\n",
    "            Returns:\n",
    "            ----------\n",
    "            race_results_df : pandas.DataFrame\n",
    "                全レース結果データをまとめてDataFrame型にしたもの\n",
    "            \"\"\"\n",
    "\n",
    "            #race_idをkeyにしてDataFrame型を格納\n",
    "            race_results = {}\n",
    "            for race_id in tqdm(race_id_list):\n",
    "                try:\n",
    "                    time.sleep(1)\n",
    "                    url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                    #メインとなるテーブルデータを取得\n",
    "                    df = pd.read_html(url)[0]\n",
    "\n",
    "                    html = requests.get(url)\n",
    "                    html.encoding = \"EUC-JP\"\n",
    "                    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "                    #天候、レースの種類、コースの長さ、馬場の状態、日付をスクレイピング\n",
    "                    texts = (\n",
    "                        soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                        + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "                    )\n",
    "                    info = re.findall(r'\\w+', texts)\n",
    "                    # print(info)\n",
    "                    for text in info:\n",
    "                        if text in [\"芝\", \"ダート\"]:\n",
    "                            df[\"race_type\"] = [text] * len(df)\n",
    "                        if \"障\" in text:\n",
    "                            df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                        if \"m\" in text:\n",
    "                            df['course_len'] = [int(re.findall(r\"(\\d+)(?=m)\", text)[0])] * len(df)\n",
    "                            #回り情報の取得追加\n",
    "                            procestext = re.findall(r\"(\\D+)(?=\\d)\", text)[0]\n",
    "                            procestext = re.sub(r\"[ダ,芝]\", \"\", procestext)\n",
    "                            df[\"race_round\"] = [procestext] * len(df)\n",
    "                        if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                            df[\"ground_state\"] = [text] * len(df)\n",
    "                        if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                            df[\"weather\"] = [text] * len(df)\n",
    "                        if \"年\" in text:\n",
    "                            df[\"date\"] = [text] * len(df)\n",
    "    #独自追加--------------------------------------------------------\n",
    "                    #クラス名取得を追加\n",
    "                        if any(anytext in text for anytext in (\"新馬\",\"未出走\",\"勝\",\"オープン\",\"以上\",\"以下\",\"万下\")):\n",
    "                            df[\"class\"] = [text] * len(df)\n",
    "\n",
    "                    #レース名取得を追加\n",
    "                    race_name = soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"h1\")[0].text\n",
    "                    df[\"race_name\"] = race_name\n",
    "    #--------------------------------------------------------   \n",
    "                    #馬ID、騎手IDをスクレイピング\n",
    "                    horse_id_list = []\n",
    "                    horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                        \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                    )\n",
    "                    for a in horse_a_list:\n",
    "                        horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                        horse_id_list.append(horse_id[0])\n",
    "                    jockey_id_list = []\n",
    "                    jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                        \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                    )\n",
    "                    for a in jockey_a_list:\n",
    "                        jockey_id = re.findall(r\"recent/(\\w+)\", a[\"href\"])\n",
    "                        jockey_id_list.append(jockey_id[0])\n",
    "                    df[\"horse_id\"] = horse_id_list\n",
    "                    df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                    #インデックスをrace_idにする\n",
    "                    df.index = [race_id] * len(df)\n",
    "\n",
    "                    race_results[race_id] = df\n",
    "\n",
    "\n",
    "\n",
    "                #存在しないrace_idを飛ばす\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                #wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                #Jupyterで停止ボタンを押した時の対処\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "            race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "            return race_results_df\n",
    "\n",
    "        #前処理    \n",
    "        def preprocessing(self):\n",
    "            df = self.data_j.copy()\n",
    "\n",
    "            #障害レースを削除\n",
    "            df = df[~(df['race_type']=='障害')]\n",
    "\n",
    "            # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "            df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "            df.dropna(subset=['着順'], inplace=True)\n",
    "            df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "            # #二値分類パターン(標準3位以内)\n",
    "            # df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "\n",
    "            # # # 人気よりも着順が3以上良い馬かつ3位以内\n",
    "            # df['人気-着順']  = df['人気']-df['着順'] \n",
    "            # df.loc[(df['人気-着順'] >2)&(df['着順']<4),'着順'] = 1\n",
    "            # df.loc[(df['人気-着順'] <=2)&(df['着順']<4),'着順'] = 0\n",
    "            # df.loc[(df['人気-着順'] >0)&(df['着順']>=4),'着順'] = 0\n",
    "            # df.loc[(df['人気-着順'] <=0),'着順'] = 0\n",
    "            # df['rank'] = df['着順']\n",
    "            # df.drop(['人気-着順'],axis=1, inplace=True)\n",
    "\n",
    "            #多クラス分類パターン(rankをグループで順位付けする)\n",
    "            # df['rank'] = df['着順'].map(lambda x:1 if x<4 else (2 if x>3 and x<7 else (3 if x>6 and x<10 else (4 if x>9 and x<14 else 5))))\n",
    "\n",
    "            # # 多クラス分類パターン(着順そのまま)\n",
    "            # df['rank'] = df['着順']\n",
    "\n",
    "            # 性齢を性と年齢に分ける\n",
    "            df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "            df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "            # 馬体重を体重と体重変化に分ける\n",
    "            df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0]\n",
    "            df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1]\n",
    "\n",
    "            #errors='coerce'で、\"計不\"など変換できない時に欠損値にする\n",
    "            df['体重'] = pd.to_numeric(df['体重'], errors='coerce')\n",
    "            df['体重変化'] = pd.to_numeric(df['体重変化'], errors='coerce')\n",
    "\n",
    "            # 単勝をfloatに変換\n",
    "            df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "            # 距離は10の位を切り捨てる\n",
    "            df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "    #独自追加--------------------------------------------------------\n",
    "            # タイムは着順が漢字(中,除,取)のときにNaNになるため上記でDrop済みだが念のため\n",
    "            df.dropna(subset=['タイム'], inplace=True)\n",
    "            #独自追加--------------------------------------------------------\n",
    "            #タイムデータ(秒表示に変換)\n",
    "            def race_time(x):\n",
    "                try:\n",
    "                    if type(x) != str:\n",
    "                        return x\n",
    "                    elif  x.count(':') == 2 :\n",
    "                        m, s, l = str(x).split(':')\n",
    "                        return (int(m) * 60 + float(s) + float(l))\n",
    "                    elif  x.count('.') == 2 :\n",
    "                        m, s, l = str(x).split('.')\n",
    "                        return (int(m) * 60 + float(s) + float(l))\n",
    "                    else:\n",
    "                        m, s = str(x).split(':')\n",
    "                        return ((int(m) * 60 + float(s)))\n",
    "                except Exception as e:\n",
    "                    print(x)\n",
    "                    print(type(x))\n",
    "                    print(e)\n",
    "\n",
    "            df['time'] = df['タイム'].map(lambda x: race_time(x))\n",
    "            df.drop(['タイム'], axis=1, inplace=True)\n",
    "            #--------------------------------------------------------\n",
    "    #独自追加--------------------------------------------------------       \n",
    "\n",
    "            # 不要な列を削除\n",
    "            #'騎手'を保持に変更、hr側でjokey_idのmergeに使用するため\n",
    "            # df.drop([\"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '人気', '着順', 'race_name'],axis=1, inplace=True)\n",
    "            df.drop([\"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名','race_name'],axis=1, inplace=True)\n",
    "\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "            #月齢変換\n",
    "            def chenge_day(x):\n",
    "                Y=x[:4]\n",
    "                M=x[5:7]\n",
    "                D=x[8:10]\n",
    "                return ((((int(Y)-2009)%19)*11+int(M)+int(D))%30)\n",
    "            df['geturei'] = df['date'].map(lambda x: chenge_day(str(x)))\n",
    "\n",
    "            #日付の周期化\n",
    "            df[\"生年月日\"] = pd.to_datetime(df[\"生年月日\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "            def trigonometric(x,T):\n",
    "                if T == 'M':\n",
    "                    num=int(x[5:7])\n",
    "                    sin = np.sin(2 * np.pi * num/12)\n",
    "                    cos = np.cos(2 * np.pi * num/12)\n",
    "                elif T == 'D':\n",
    "                    num=int(x[8:10])\n",
    "                    sin = np.sin(2 * np.pi * num/31)\n",
    "                    cos = np.cos(2 * np.pi * num/31)\n",
    "                else:\n",
    "                    num = int(x.strftime ( '%j' ))\n",
    "                    sin = np.sin(2 * np.pi * num/366)\n",
    "                    cos = np.cos(2 * np.pi * num/366)\n",
    "                return sin,cos\n",
    "\n",
    "            df['sin_birth']= df['生年月日'].map(lambda x: trigonometric((x),'T')).str[0]\n",
    "            df['cos_birth']= df['生年月日'].map(lambda x: trigonometric((x),'T')).str[1]\n",
    "            df['sin_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[0]\n",
    "            df['cos_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[1]\n",
    "\n",
    "            #開催場所\n",
    "            df['place'] = df.index.map(lambda x:str(x)[4:6])\n",
    "\n",
    "        #6/6出走数追加\n",
    "            df['n_horses'] = df.index.map(df.index.value_counts())\n",
    "\n",
    "            self.data_p = df\n",
    "\n",
    "        #カテゴリ変数の処理\n",
    "        def process_categorical(self,past_race_num):\n",
    "            #複数列の値でカテゴリ変数化する場合は、concatする\n",
    "            # place_= kai_ = day_ = jockey_ = []\n",
    "            place_, kai_, day_, jockey_ = [], [], [], []\n",
    "            for i in range(past_race_num):\n",
    "                place_.append('self.data_pe[\"place_{}p\"]'.format(i+1))\n",
    "                kai_.append('self.data_pe[\"kai_{}p\"]'.format(i+1))\n",
    "                day_.append('self.data_pe[\"day_{}p\"]'.format(i+1))\n",
    "                jockey_.append('self.data_pe[\"jockey_id_{}p\"]'.format(i+1))\n",
    "\n",
    "            place_.append('self.data_pe[\"place\"]')\n",
    "            self.le_place = eval('LabelEncoder().fit(pd.concat(['+','.join(place_)+']).unique())')\n",
    "            self.le_kai = eval('LabelEncoder().fit(pd.concat(['+','.join(kai_)+']).unique())')\n",
    "            self.le_day = eval('LabelEncoder().fit(pd.concat(['+','.join(day_)+']).unique())')\n",
    "            self.le_jockey = eval('LabelEncoder().fit(pd.concat(['+','.join(jockey_)+']).unique())')\n",
    "\n",
    "            self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'].unique())\n",
    "            self.le_class = LabelEncoder().fit(pd.concat([self.data_pe['class'],self.data_pe['Past_class']]).unique())\n",
    "            # self.le_jockey = LabelEncoder().fit(pd.concat([self.data_pe['jockey_id'],self.data_pe['past_jockey']]).unique())\n",
    "            # self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'].unique())\n",
    "\n",
    "            self.le_trainer = LabelEncoder().fit(self.data_pe['調教師_id'].unique())\n",
    "            self.le_horseowner = LabelEncoder().fit(self.data_pe['馬主_id'].unique())\n",
    "            self.le_producer = LabelEncoder().fit(self.data_pe['生産者_id'].unique())\n",
    "            self.le_relative1 = LabelEncoder().fit(self.data_pe['近親馬_id1'].unique())\n",
    "            self.le_relative2 = LabelEncoder().fit(self.data_pe['近親馬_id2'].unique())\n",
    "\n",
    "            super().process_categorical(self.le_horse, self.le_jockey, self.le_class, self.le_place, self.data_pe\\\n",
    "                                       ,self.le_trainer,self.le_horseowner,self.le_producer,self.le_relative1,\\\n",
    "                                        self.le_relative2,self.le_kai,self.le_day,past_race_num)\n",
    "    class HorseInfo:\n",
    "        def __init__(self, horse_info):\n",
    "            self.horse_info = horse_info[['生年月日','調教師_id','馬主_id','生産者_id','近親馬_id1','近親馬_id2']]\n",
    "            self.horse_info_p = pd.DataFrame()\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "    class HorseResults:\n",
    "        def __init__(self, horse_results):\n",
    "            #self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過', '開催', '距離']]\n",
    "            # self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過', '開催', '距離','タイム','上り','馬場','斤量','騎手']]\n",
    "            self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過', '開催',\\\n",
    "                                                '距離','タイム','上り','馬場','斤量','騎手','天気','R','頭数',\\\n",
    "                                                '枠番','馬番','オッズ','人気','ペース','馬体重']]\n",
    "            # self.preprocessing()\n",
    "            self.horse_results_p = pd.DataFrame()\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        @staticmethod\n",
    "        def scrape(horse_id_list,flg):\n",
    "            print(\"if you want get resuts data, True. else info_data False\")\n",
    "            # inpt = input(\"if you want get resuts data, True. else info_data False(y/n)\\n\")\n",
    "            # # if inpt != 'y':\n",
    "            # #     return print('Please choise', file=sys.stderr)\n",
    "\n",
    "            \"\"\"\n",
    "            馬の過去成績データをスクレイピングする関数\n",
    "            Parameters:\n",
    "            ----------\n",
    "            horse_id_list : list\n",
    "                馬IDのリスト\n",
    "            Returns:\n",
    "            ----------\n",
    "            horse_results_df : pandas.DataFrame\n",
    "                全馬の過去成績データをまとめてDataFrame型にしたもの\n",
    "            \"\"\"\n",
    "\n",
    "            #horse_idをkeyにしてDataFrame型を格納\n",
    "            horse_results = {}\n",
    "            horse_info ={}\n",
    "            for horse_id in tqdm(horse_id_list):\n",
    "                try:\n",
    "                    time.sleep(1)\n",
    "                    url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "\n",
    "                    if flg:\n",
    "\n",
    "                        df = pd.read_html(url)[3]\n",
    "                        #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                        if df.columns[0]=='受賞歴':\n",
    "                            df = pd.read_html(url)[4]\n",
    "                        df.index = [horse_id] * len(df)\n",
    "                        horse_results[horse_id] = df\n",
    "\n",
    "                    else:\n",
    "                        #bace_info\n",
    "                        idf = pd.read_html(url)[1]\n",
    "                        Tidf = idf.T\n",
    "                        headers = Tidf.iloc[0]\n",
    "                        info_df  = pd.DataFrame(Tidf.values[1:], columns=headers)\n",
    "                        info_df.index =  [horse_id]\n",
    "                        #id henkan\n",
    "                        html = requests.get(url)\n",
    "                        html.encoding = \"EUC-JP\"\n",
    "                        soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "                        all_id = soup.find(\"table\", attrs={\"summary\": \"のプロフィール\"}).find_all(\n",
    "                        \"a\", attrs={\"href\": re.compile(\"/\\w\")})\n",
    "\n",
    "                        inf_horse_id1=inf_horse_id2=inf_owner_id=\"\"\n",
    "                        for a in all_id:\n",
    "                            if \"trainer\" in str(a):\n",
    "                                inf_trainer_id = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                if len(inf_trainer_id) ==1:\n",
    "                                     info_df['調教師_id']=np.nan\n",
    "                                else:\n",
    "                                    info_df['調教師_id']=inf_trainer_id[1]\n",
    "                            elif \"owner\" in str(a):\n",
    "                                if inf_owner_id==\"\":\n",
    "                                    inf_owner_id = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                    if len(inf_owner_id) ==1:\n",
    "                                        info_df['馬主_id']=np.nan\n",
    "                                    else:\n",
    "                                        info_df['馬主_id']=inf_owner_id[1]\n",
    "                            elif \"breeder\" in str(a):\n",
    "                                inf_breeder_id = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                if len(inf_breeder_id) ==1:\n",
    "                                    info_df['生産者_id']=np.nan\n",
    "                                else:\n",
    "                                    info_df['生産者_id']=inf_breeder_id[1]\n",
    "                            elif \"horse/result\" in str(a):\n",
    "                                inf_horse_result_id = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                if len(inf_horse_result_id) ==2:\n",
    "                                    info_df['通算成績_id']=np.nan\n",
    "                                else:\n",
    "                                    info_df['通算成績_id']=inf_horse_result_id[2]\n",
    "                            elif \"race\" in str(a):\n",
    "                                inf_race_id = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                if len(inf_race_id) ==1:\n",
    "                                    info_df['主な勝鞍_id']=np.nan\n",
    "                                else:\n",
    "                                    info_df['主な勝鞍_id']=inf_race_id[1]\n",
    "                            elif \"horse\" in str(a):\n",
    "                                if inf_horse_id1==\"\":\n",
    "                                    inf_horse_id1=re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                    if len(inf_horse_id1) ==1:\n",
    "                                        info_df['近親馬_id1']=np.nan\n",
    "                                    else:\n",
    "                                        info_df['近親馬_id1']=inf_horse_id1[1]\n",
    "                                else:\n",
    "                                    inf_horse_id2=re.findall(r\"\\w+\", a[\"href\"])\n",
    "                                    if len(inf_horse_id2) ==1:\n",
    "                                        info_df['近親馬_id2']=np.nan\n",
    "                                    else:\n",
    "                                        info_df['近親馬_id2']=inf_horse_id2[1]\n",
    "                        horse_info[horse_id] = info_df \n",
    "\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "            if flg:\n",
    "                horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "                return horse_results_df\n",
    "            else:\n",
    "                horse_info_df = pd.concat([horse_info[key] for key in horse_info])\n",
    "                return horse_info_df\n",
    "\n",
    "\n",
    "        def preprocessing(self):\n",
    "            df = self.horse_results.copy()\n",
    "\n",
    "            # 開催場所をidに変換するための辞書型\n",
    "            place_dict = {\n",
    "                '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "                '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "            }\n",
    "\n",
    "            # place_dict = {\n",
    "            #     '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "            #     '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10',\n",
    "            #     '大井':'25',  '浦和':'12',  '笠松':'13',  '名古屋':'14',  '園田':'15',\n",
    "            #     '高知':'16',  '佐賀':'17',  '川崎':'18',  '盛岡':'19',  '水沢':'20',\n",
    "            #     '船橋':'21',  '姫路':'22',  '門別':'23',  '金沢':'24'\n",
    "            # }\n",
    "\n",
    "            #レースタイプをレース結果データと整合させるための辞書型\n",
    "            race_type_dict = {\n",
    "                '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "            }\n",
    "\n",
    "            # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "            df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "            df.dropna(subset=['着順'], inplace=True)\n",
    "            df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "            df[\"date\"] = pd.to_datetime(df['日付'])\n",
    "            df.drop(['日付'], axis=1, inplace=True)\n",
    "\n",
    "            #月齢変換\n",
    "            def chenge_day(x):\n",
    "                Y=x[:4]\n",
    "                M=x[5:7]\n",
    "                D=x[8:10]\n",
    "                return ((((int(Y)-2009)%19)*11+int(M)+int(D))%30)\n",
    "\n",
    "            df['geturei'] = df['date'].map(lambda x: chenge_day(str(x)))\n",
    "\n",
    "            def trigonometric(x,T):\n",
    "                if T == 'M':\n",
    "                    num=int(x[5:7])\n",
    "                    sin = np.sin(2 * np.pi * num/12)\n",
    "                    cos = np.cos(2 * np.pi * num/12)\n",
    "                elif T == 'D':\n",
    "                    num=int(x[8:10])\n",
    "                    sin = np.sin(2 * np.pi * num/31)\n",
    "                    cos = np.cos(2 * np.pi * num/31)\n",
    "                else:\n",
    "                    num = int(x.strftime ( '%j' ))\n",
    "                    sin = np.sin(2 * np.pi * num/366)\n",
    "                    cos = np.cos(2 * np.pi * num/366)\n",
    "                return sin,cos\n",
    "\n",
    "            df['sin_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[0]\n",
    "            df['cos_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[1]\n",
    "\n",
    "            #賞金のNaNを0で埋める\n",
    "            df['賞金'].fillna(0, inplace=True)\n",
    "\n",
    "            #1着の着差を0にする\n",
    "            df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "\n",
    "            #レース展開データ\n",
    "            #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "            def corner(x, n):\n",
    "                if type(x) != str:\n",
    "                    return x\n",
    "                elif n==4:\n",
    "                    return int(re.findall(r'\\d+', x)[-1])\n",
    "                elif n==1:\n",
    "                    return int(re.findall(r'\\d+', x)[0])\n",
    "            df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "            df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "\n",
    "            df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "            df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "            df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "\n",
    "    #独自追加--------------------------------------------------------\n",
    "            def create_kai_day(x,n):\n",
    "                try:\n",
    "    #                 if x is np.nan:\n",
    "    #                     return x\n",
    "                    #任意の数字を含むかつ前方の数値を取得する場合\n",
    "                    if bool(re.search(r'\\d', x)) and n==1:\n",
    "                        return str(re.findall(r'^[0-9]+',x)[0]).zfill(2)\n",
    "                    elif bool(re.search(r'\\d', x)) and n==2:\n",
    "                        return  str(re.findall(r'[0-9]+$',x)[0]).zfill(2)\n",
    "                except Exception as e:\n",
    "                    return x\n",
    "\n",
    "            #開催場所から開催回と開催日を抽出\n",
    "            df['kai'] = df['開催'].map(lambda x: create_kai_day(x,1))\n",
    "            df['day'] = df['開催'].map(lambda x: create_kai_day(x,2))        \n",
    "\n",
    "            #カラム名の変更(スピード指数のマージのため)\n",
    "            df.rename(columns={\"馬場\": \"ground_state\"},inplace=True)\n",
    "\n",
    "    #--------------------------------------------------------\n",
    "\n",
    "            #開催場所(地方や海外データは11に変換)\n",
    "            df['place'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "            #race_type\n",
    "            df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "            #距離は10の位を切り捨てる\n",
    "            df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(int) // 100\n",
    "            #インデックス名を与える\n",
    "            df.index.name = 'horse_id'\n",
    "\n",
    "    #独自追加--------------------------------------------------------\n",
    "            #タイムデータ\n",
    "            def race_time(x):\n",
    "                try:\n",
    "                    if type(x) != str:\n",
    "                        return x\n",
    "                    elif  x.count(':') == 2 :\n",
    "                        m, s, l = str(x).split(':')\n",
    "                        return (int(m) * 60 + float(s) + float(l))\n",
    "                    elif  x.count('.') == 2 :\n",
    "                        m, s, l = str(x).split('.')\n",
    "                        return (int(m) * 60 + float(s) + float(l))\n",
    "                    else:\n",
    "                        m, s = str(x).split(':')\n",
    "                        return ((int(m) * 60 + float(s)))\n",
    "                except Exception as e:\n",
    "                    print(x)\n",
    "                    print(type(x))\n",
    "                    print(e)\n",
    "\n",
    "            df['time'] = df['タイム'].map(lambda x: race_time(x))\n",
    "\n",
    "            df[\"weather\"]=df[\"天気\"]\n",
    "\n",
    "            # 馬体重を体重と体重変化に分ける\n",
    "            df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0]\n",
    "            df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1]\n",
    "\n",
    "            #errors='coerce'で、\"計不\"など変換できない時に欠損値にする\n",
    "            df['体重'] = pd.to_numeric(df['体重'], errors='coerce')\n",
    "            df['体重変化'] = pd.to_numeric(df['体重変化'], errors='coerce')\n",
    "\n",
    "            #ペース\n",
    "            df['first_pace'] = df[\"ペース\"].str.split(\"-\", expand=True)[0]\n",
    "            df['latter_pace'] = df[\"ペース\"].str.split(\"-\", expand=True)[1]\n",
    "            df['first_pace'] = df['first_pace'].astype('float')\n",
    "            df['latter_pace'] = df['latter_pace'].astype('float')\n",
    "\n",
    "            df.drop(['開催','天気','馬体重','通過','距離','タイム','ペース'], axis=1, inplace=True)\n",
    "    #--------------------------------------------------------\n",
    "            # 障害および地方レースを削除\n",
    "            # df =  df[~(df['place']=='11')]\n",
    "\n",
    "            self.horse_results_p = df\n",
    "\n",
    "            '''\n",
    "            #target_list(horse_idごとに平均値を求めたい列を指定する)\n",
    "            #addition_list(horse_idごとに平均値を求める和条件とする列を指定する)\n",
    "            #multiplication_list(horse_idごとに平均値を求める共通条件とする列を指定する)\n",
    "\n",
    "            '''\n",
    "            self.target_list = ['着順', '賞金', '着差', 'first_corner', 'final_corner',\n",
    "                                'first_to_rank', 'first_to_final','final_to_rank','上り','time']\n",
    "            self.addition_list = ['course_len', 'race_type', 'place']\n",
    "            self.multiplication_list = ['horse_id','course_len', 'race_type', 'place']\n",
    "\n",
    "        #n_samplesレース分馬ごとに平均する\n",
    "        def average(self,horse_id_list, date, n_samples='all'):\n",
    "\n",
    "            #resultから得た日付をもとにhorse_idで成績を取り出す\n",
    "            target_df = self.horse_results_p.query('index in @horse_id_list')\n",
    "            # print('average_date:',date)\n",
    "\n",
    "            #過去何走分取り出すか指定\n",
    "            if n_samples == 'all':\n",
    "                filtered_df = target_df[target_df['date'] < date]\n",
    "            elif n_samples > 0:\n",
    "                filtered_df = target_df[target_df['date'] < date].\\\n",
    "                    sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "            else:\n",
    "                raise Exception('n_samples must be >0')\n",
    "\n",
    "            '''        \n",
    "            #集計して辞書型に入れる\n",
    "            #ここで平均されるデータはtarget_listで指定したもの\n",
    "            #non_categoryとしているのは、この馬の個別要素によらない平均のため\n",
    "            '''\n",
    "            self.average_dict = {}\n",
    "            self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list].mean()\\\n",
    "                .add_suffix('_{}R'.format(n_samples))\n",
    "\n",
    "            '''\n",
    "            #ここでaverage_dictにカテゴリ別に集計した値が代入される\n",
    "            #意味はある馬のcolumn(cource_lenなど)ごとにのtarget_listで指定した5R平均\n",
    "            #細分化したい場合はcolumnに追加する。(着順_cource_len_5Rなどになる)\n",
    "            #columnに指定した列ごとに平均を出しaverage_dictに新たに追加する\n",
    "            #指定できるのはhorse_resultsにある列だけ\n",
    "            #今はないけどjokey_id別も出しておきたい\n",
    "            '''\n",
    "            for column in self.addition_list:\n",
    "                self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                    [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples))\n",
    "\n",
    "            #組み合わせを自分で設定\n",
    "            self.average_dict['my_category'] = filtered_df.groupby(self.multiplication_list)\\\n",
    "                    [self.target_list].mean().add_suffix('_my_{}R'.format(n_samples))\n",
    "\n",
    "            #6/6追加: 馬の出走間隔追加のために、全レースの日付を変数latestに格納\n",
    "            if n_samples == 5:\n",
    "                self.latest = filtered_df.groupby('horse_id')['date'].max().rename('latest')\n",
    "\n",
    "        def merge(self, results, date, n_samples='all'):\n",
    "\n",
    "            '''\n",
    "            リークについて\n",
    "                resultの全日程から一意の日付でhorse_resultsを抽出する\n",
    "                抽出したから過去走をn_samples分さかのぼり平均する\n",
    "                その値をconcatでresultsを一から再構築している\n",
    "                リークした情報ではなく過去走の平均をとれている\n",
    "            '''\n",
    "            #日付でresultsを絞り込み、出走馬のhorse_idを取り出し関数に入れる\n",
    "            df = results[results['date']==date]\n",
    "            horse_id_list = df['horse_id']\n",
    "            self.average(horse_id_list, date, n_samples)\n",
    "            # print('merge_date:',date)\n",
    "\n",
    "            if n_samples == 5:\n",
    "            #merge処理する際にindex振りなおしてしまうので避難\n",
    "                df.reset_index(inplace= True)  \n",
    "                df = df.rename(columns={'index': 'race_id'})\n",
    "\n",
    "                '''\n",
    "                スピード指数を追加\n",
    "                指定した日付から過去全体の平均タイムを算出し、各resultsごとに計算する\n",
    "                '''\n",
    "                # r_past_df = results.query('date < @date')\n",
    "                r_past_df = results[results['date']<date]\n",
    "\n",
    "                # print('margelen:',len(r_past_df))\n",
    "\n",
    "                r_past_df1 = pd.DataFrame(r_past_df.groupby\\\n",
    "                                                (['place','race_type','course_len','ground_state'])['time'].mean())\n",
    "\n",
    "                r_past_df1['Distance_index'] = 1/r_past_df1['time']*100\n",
    "\n",
    "                r_past_df1.rename(columns={'time': 'mean_time'},inplace=True)\n",
    "\n",
    "                r_past_df2=pd.merge(r_past_df,r_past_df1, how='left',on= \\\n",
    "                                               [\"place\",\"race_type\",\"ground_state\",\"course_len\"])\n",
    "                #スピード指数計算\n",
    "                r_past_df2['Speed_index'] = (r_past_df2['mean_time']-r_past_df2['time'])\\\n",
    "                                    *r_past_df2['Distance_index']+(r_past_df2['斤量']-55)*0.2 \n",
    "\n",
    "                #過去走のみになっているため、ここで平均値をとり指定した日付のスピード指数とする\n",
    "                horse_id_SPI = r_past_df2.groupby(['horse_id'])['Speed_index'].mean()\n",
    "                # print(horse_id_SPI)\n",
    "\n",
    "                merged_df = pd.merge(df,horse_id_SPI, on=['horse_id'], how='left')\n",
    "\n",
    "                #個別要素によらない平均値をマージ\n",
    "                merged_df = merged_df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                                     right_index=True, how='left')\n",
    "                #複数個別要素のand条件による平均値をマージ\n",
    "                merged_df = merged_df.merge(self.average_dict['my_category'],\n",
    "                                            on=self.multiplication_list, how='left')       \n",
    "                #個別要素別の平均値をマージ\n",
    "                for column in self.addition_list:\n",
    "                        merged_df = merged_df.merge(self.average_dict[column], left_on=['horse_id', column],\n",
    "                                                    right_index=True, how='left')\n",
    "\n",
    "                #6/6追加：馬の出走間隔追加のために、前レースの日付を変数latestに格納\n",
    "                merged_df = merged_df.merge(self.latest, left_on='horse_id',\n",
    "                                            right_index=True, how='left')\n",
    "\n",
    "                #前走class\n",
    "                past_class = r_past_df.sort_values('date', ascending=False).groupby('horse_id').head(1)\n",
    "                past_class.rename(columns={'class': 'past_class'},inplace=True)\n",
    "                merged_df = merged_df.merge(past_class[['horse_id','past_class']], on='horse_id', how='left')\n",
    "            else:\n",
    "                #個別要素によらない平均値をマージ\n",
    "                merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                                     right_index=True, how='left')\n",
    "                #複数個別要素のand条件による平均値をマージ\n",
    "                merged_df = merged_df.merge(self.average_dict['my_category'],\n",
    "                                            on=self.multiplication_list, how='left')       \n",
    "                #個別要素別の平均値をマージ\n",
    "                for column in self.addition_list:\n",
    "                        merged_df = merged_df.merge(self.average_dict[column], left_on=['horse_id', column],\n",
    "                                                    right_index=True, how='left')\n",
    "\n",
    "            return merged_df\n",
    "\n",
    "        def merge_all(self, results, n_samples='all',rt=None):\n",
    "\n",
    "            if rt == None:\n",
    "                date_list = results['date'].unique()\n",
    "\n",
    "            else:\n",
    "                #ここでのdata_pは出馬テーブルのみのデータ\n",
    "                #resultsについては、出馬テーブルと過去resultsがくっついたデータになっている\n",
    "                date_list = rt.data_p['date'].unique()\n",
    "                # date_list = rt.data_p.sort_values('date',ascending = True)['date'].unique()\n",
    "                # print('date_list_date:',date_list)\n",
    "                # print('results過去全レース:',results.index.nunique())\n",
    "\n",
    "            # jockey_idをresultから取得。hrのprossesingの時のみ実行する        \n",
    "            if n_samples == 5:\n",
    "                self.horse_results_p = self.horse_results_p.reset_index()\n",
    "                jockey_df = results[['騎手','jockey_id']].drop_duplicates()\n",
    "                # print(jockey_df[jockey_df.index=='202207040410'])\n",
    "                self.horse_results_p = self.horse_results_p.merge(jockey_df, how='left', on = '騎手')\n",
    "                self.horse_results_p = self.horse_results_p.set_index('horse_id')\n",
    "                # print(set(self.horse_results_p.columns.tolist()))\n",
    "\n",
    "            merged_df = pd.concat([self.merge(results, date, n_samples) for date in tqdm(date_list)])\n",
    "\n",
    "            return merged_df\n",
    "    class jockey_results:\n",
    "        def __init__(self, jockey_results):\n",
    "            self.jockey_results = jockey_results\\\n",
    "            [['年度', '順位', '1着', '2着', '3着', '着外', '重賞_出走', '重賞_勝利', '特別_出走', '特別_勝利',\\\n",
    "              '平場_出走', '平場_勝利', '芝_出走', '芝_勝利', 'ダート_出走', 'ダート_勝利', '勝率', '連対率',\\\n",
    "              '複勝率', '収得賞金(万円)']]\n",
    "            self.jockey_results_p = pd.DataFrame()\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        def converted_multi_columns(df):\n",
    "            return [col[0]  if col[0] == col[1] else col[0]+'_'+col[1] for col in df.columns.values]\n",
    "\n",
    "        @classmethod\n",
    "        def scrape(self,jockey_id_list):\n",
    "            jockey_results ={}\n",
    "\n",
    "            for jockey_id in tqdm(jockey_id_list):\n",
    "                try:\n",
    "\n",
    "                    time.sleep(1)\n",
    "                    url = 'https://db.netkeiba.com/jockey/result/'+ jockey_id\n",
    "                    df = pd.read_html(url)[0]\n",
    "                    #multi＿columを変換\n",
    "                    df.columns = self.converted_multi_columns(df)\n",
    "                    df.index = [jockey_id]* len(df)\n",
    "\n",
    "                    #一旦辞書型に保存する\n",
    "                    jockey_results[jockey_id] = df \n",
    "\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                except ValueError:\n",
    "                    print('No tables found')\n",
    "                    df=pd.DataFrame(index=[jockey_id],columns=\\\n",
    "                    ['年度', '順位', '1着', '2着', '3着', '着外', '重賞_出走', '重賞_勝利', '特別_出走', '特別_勝利',\\\n",
    "                     '平場_出走', '平場_勝利', '芝_出走', '芝_勝利', 'ダート_出走', 'ダート_勝利', '勝率', '連対率',\\\n",
    "                     '複勝率', '収得賞金(万円)', '代表馬'])\n",
    "                    df.fillna(0, inplace=True)\n",
    "                    jockey_results[jockey_id]=df\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "            jockey_results_df = pd.concat([jockey_results[key] for key in jockey_results])\n",
    "\n",
    "            return jockey_results_df\n",
    "    class ShutubaTable(DataProcessor):\n",
    "        def __init__(self, shutuba_tables):\n",
    "            super(ShutubaTable, self).__init__()\n",
    "            self.data = shutuba_tables\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        @classmethod\n",
    "        # def scrape(cls, race_id_list, date):\n",
    "        def scrape(cls, race_id_day_dict,checkflg=True):\n",
    "\n",
    "            data = pd.DataFrame()\n",
    "            today = datetime.now().strftime('%Y年%m月%d日')\n",
    "            # for race_id in tqdm(race_id_list):\n",
    "            for race_id,date in tqdm(race_id_day_dict.items()):\n",
    "                try:\n",
    "                    # 今日よりも未来の日付の場合、レース情報が出そろっていないためスキップ\n",
    "                    if checkflg:\n",
    "                        if datetime.strptime(date, '%Y年%m月%d日')>datetime.strptime(today, '%Y年%m月%d日'):\n",
    "                            print('skip_date_id',date,race_id)\n",
    "                            continue\n",
    "                    # print(race_id,date)\n",
    "                    url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "                    df = pd.read_html(url)[0]\n",
    "                    df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "                    if checkflg:\n",
    "                    #馬体重の発表がまたの場合\n",
    "                        if df['馬体重(増減)'].isnull().any():\n",
    "                            print('skip race id for not wight',date,race_id)\n",
    "                            continue\n",
    "\n",
    "                    html = requests.get(url)\n",
    "                    html.encoding = \"EUC-JP\"\n",
    "                    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "                    texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "                    texts = re.findall(r'\\w+', texts)\n",
    "                    texts2 = soup.find('div', attrs={'class': 'RaceData02'}).text\n",
    "                    texts2 = re.findall(r'\\w+', texts2)\n",
    "                    for text in texts:\n",
    "                        if 'm' in text:\n",
    "                            df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                        #回り情報の取得追加_resultsとは異なる   \n",
    "                        if text in ['左', '右', '外', '内', '直', '直線']:\n",
    "                            df[\"race_round\"] = [text] * len(df)\n",
    "                        if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                            df[\"weather\"] = [text] * len(df)\n",
    "                        if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                            df[\"ground_state\"] = [text] * len(df)\n",
    "                        if '不' in text:\n",
    "                            df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                        # 2020/12/13追加\n",
    "                        if '稍' in text:\n",
    "                            df[\"ground_state\"] = ['稍重'] * len(df)\n",
    "                        if '芝' in text:\n",
    "                            df['race_type'] = ['芝'] * len(df)\n",
    "                        if '障' in text:\n",
    "                            df['race_type'] = ['障害'] * len(df)\n",
    "                        if 'ダ' in text:\n",
    "                            df['race_type'] = ['ダート'] * len(df)\n",
    "                    df['date'] = [date] * len(df)\n",
    "            #独自追加--------------------------------------------------------\n",
    "                    bftext = aftext =np.nan\n",
    "                    anytext =np.nan\n",
    "                    for text2 in texts2:\n",
    "                        if any(anytext in text2 for anytext in (\"歳\")):\n",
    "                            bftext = text2\n",
    "                        if any(anytext in text2 for anytext in (\"新馬\",\"未出走\",\"勝\",\"オープン\",\"以上\",\"以下\",\"万下\")):\n",
    "                            aftext = text2 \n",
    "                    classtext = bftext+aftext\n",
    "                    df[\"class\"] = [classtext] * len(df)\n",
    "\n",
    "                    #レース名取得を追加\n",
    "                    race_name = soup.find('div', attrs={'class': 'RaceName'}).text\n",
    "                    race_name = re.findall(r'\\w+', race_name)\n",
    "                    # df[\"race_name\"] = [race_name][0] * len(df)\n",
    "                    #変更　レース名に\"-\"がある場合indexエラーとなるため\n",
    "                    race_name = \"-\".join(race_name)\n",
    "                    df[\"race_name\"] = [race_name] * len(df)\n",
    "            #--------------------------------------------------------\n",
    "\n",
    "                    # horse_id\n",
    "                    horse_id_list = []\n",
    "                    horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "                    for td in horse_td_list:\n",
    "                        horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                        horse_id_list.append(horse_id)\n",
    "                    # jockey_id\n",
    "                    jockey_id_list = []\n",
    "                    jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "                    for td in jockey_td_list:\n",
    "                        jockey_id = re.findall(r\"recent/(\\w+)\", td.find('a')['href'])[0]\n",
    "                        # print(jockey_id)\n",
    "                        jockey_id_list.append(jockey_id)\n",
    "                    df['horse_id'] = horse_id_list\n",
    "                    df['jockey_id'] = jockey_id_list\n",
    "\n",
    "                    df.index = [race_id] * len(df)\n",
    "                    # data = data.append(df)\n",
    "                    data = pd.concat([data, df])\n",
    "                    time.sleep(1)\n",
    "\n",
    "                #存在しないrace_idを飛ばす\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                #wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                #Jupyterで停止ボタンを押した時の対処\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            return cls(data)\n",
    "\n",
    "        #前処理            \n",
    "        def preprocessing(self):\n",
    "            df = self.data_j.copy()\n",
    "\n",
    "            df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "            df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "            # 馬体重を体重と体重変化に分ける\n",
    "            # 馬体重未発表の場合の処理\n",
    "            if any(df['馬体重(増減)'].isnull()):\n",
    "                df[\"体重\"] = np.nan\n",
    "                df[\"体重変化\"] = np.nan\n",
    "                print('not found ''horse wight''')\n",
    "            else:\n",
    "                df = df[df[\"馬体重(増減)\"] != '--']\n",
    "                df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "                # df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0]\n",
    "                df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].str[:-1]\n",
    "                # 2020/12/13追加：増減が「前計不」などのとき欠損値にする\n",
    "                # df['体重'] = pd.to_numeric(df['体重'], errors='coerce')\n",
    "                df['体重変化'] = pd.to_numeric(df['体重変化'], errors='coerce')\n",
    "\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "            # 枠未決定の場合の処理(重賞レースは決定が早いのでanyで判定)\n",
    "            if any(df['枠'].isnull()):\n",
    "                df['枠'] = np.nan\n",
    "                df['馬番'] = np.nan\n",
    "                print('not found ''waku'' and ''horse number''')\n",
    "            else:\n",
    "                df['枠'] = df['枠'].astype(int)\n",
    "                df['馬番'] = df['馬番'].astype(int)\n",
    "            df['斤量'] = df['斤量'].astype(int)\n",
    "\n",
    "            df['place'] = df.index.map(lambda x:str(x)[4:6])\n",
    "\n",
    "            #6/6出走数追加\n",
    "            df['n_horses'] = df.index.map(df.index.value_counts())\n",
    "            # 距離は10の位を切り捨てる\n",
    "            df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "    #独自追加--------------------------------------------------------        \n",
    "            #classの数字を半角にして頭の文字を取り除く\n",
    "            #st前日取得の際にclassが未確定のため追加\n",
    "            df['class'].fillna('9未確定',inplace=True)\n",
    "            df = df[~df['class'].str.contains('障害')]\n",
    "            trans_table = str.maketrans({\"１\":\"1\", \"２\":\"2\", \"３\":\"3\", \"４\":\"4\", \"５\":\"5\"})\n",
    "            df['class'] = df['class'].map(lambda x: x.translate(trans_table))\n",
    "            df['class'] = df['class'].map(lambda x: x[x.index(re.findall(r'\\d',x)[0]):])\n",
    "\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "            #月齢変換\n",
    "            def chenge_day(x):\n",
    "                Y=x[:4]\n",
    "                M=x[5:7]\n",
    "                D=x[8:10]\n",
    "                return ((((int(Y)-2009)%19)*11+int(M)+int(D))%30)\n",
    "            df['geturei'] = df['date'].map(lambda x: chenge_day(str(x)))\n",
    "\n",
    "            #日付の周期化\n",
    "            df[\"生年月日\"] = pd.to_datetime(df[\"生年月日\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "            def trigonometric(x,T):\n",
    "                if T == 'M':\n",
    "                    num=int(x[5:7])\n",
    "                    sin = np.sin(2 * np.pi * num/12)\n",
    "                    cos = np.cos(2 * np.pi * num/12)\n",
    "                elif T == 'D':\n",
    "                    num=int(x[8:10])\n",
    "                    sin = np.sin(2 * np.pi * num/31)\n",
    "                    cos = np.cos(2 * np.pi * num/31)\n",
    "                else:\n",
    "                    num = int(x.strftime ( '%j' ))\n",
    "                    sin = np.sin(2 * np.pi * num/366)\n",
    "                    cos = np.cos(2 * np.pi * num/366)\n",
    "                return sin,cos\n",
    "\n",
    "            df['sin_birth']= df['生年月日'].map(lambda x: trigonometric((x),'T')).str[0]\n",
    "            df['cos_birth']= df['生年月日'].map(lambda x: trigonometric((x),'T')).str[1]\n",
    "            df['sin_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[0]\n",
    "            df['cos_date']= df[\"date\"].map(lambda x: trigonometric((x),'T')).str[1]\n",
    "\n",
    "            #発走中止や除外を除く\n",
    "            df = df[df['印'].isnull()]\n",
    "            df.drop(['Unnamed: 9_level_1', '厩舎', '印', 'メモ', '登録','race_name', '馬体重(増減)', '馬名', '性齢'], axis=1, inplace=True)\n",
    "\n",
    "            self.data_p = df.rename(columns={'枠': '枠番'})\n",
    "    class Peds:\n",
    "        def __init__(self, peds):\n",
    "            self.peds = peds\n",
    "            self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        @staticmethod\n",
    "        def scrape(horse_id_list):\n",
    "\n",
    "            # inpt = input(\"Have you set two receiving variables?(y/n)\\n\")\n",
    "            # if inpt != 'y':\n",
    "            #     return print('Please set two receiving variables', file=sys.stderr)\n",
    "\n",
    "            p_name_df = pd.DataFrame()\n",
    "            p_id_df = pd.DataFrame()\n",
    "            for horse_id in tqdm(horse_id_list):\n",
    "                try:\n",
    "                    url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "                    #メインとなるテーブルデータを取得\n",
    "                    peds_df = pd.read_html(url)[0]\n",
    "\n",
    "                    html = requests.get(url)\n",
    "                    html.encoding = \"EUC-JP\"\n",
    "                    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "                    horse_id_list = []\n",
    "                    idlist = []\n",
    "                    peds_list = soup.find(\"table\", attrs={\"summary\": \"5代血統表\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse/\\d\")})\n",
    "                    peds_id_df = peds_df\n",
    "\n",
    "                    for a in peds_list:\n",
    "                        horse_param = re.findall(r\"\\w+\", a[\"href\"])\n",
    "                        #改行箇所で切り取り任意の文字列を取得する、改行コードがない場合-1が返され末尾一文字が消える\n",
    "                        #horse,id,horsenameがそれぞれindexに入る\n",
    "                        horse_param.extend(re.findall(r\".*\\w\", a.text[:a.text.find('\\n')]))\n",
    "                        #dfから部分一致でidに置換\n",
    "                        peds_id_df = peds_id_df.replace(\".*\"+horse_param[2]+\".*\", horse_param[1], regex=True)\n",
    "                        idlist.append(horse_param)\n",
    "\n",
    "                    def generater(peds_df):\n",
    "                        get_peds_list = []\n",
    "                        #dfから1~5代目のidと取得する\n",
    "                        for i in range(2):\n",
    "                            get_peds_list.append(peds_df.iloc[i*16][0])\n",
    "                        for i in range(4):\n",
    "                            get_peds_list.append(peds_df.iloc[i*8][1])\n",
    "                        for i in range(8):\n",
    "                            get_peds_list.append(peds_df.iloc[i*4][2])\n",
    "                        for i in range(16):\n",
    "                            get_peds_list.append(peds_df.iloc[i*2][3])\n",
    "                        for i in range(32):\n",
    "                            get_peds_list.append(peds_df.iloc[i][4])\n",
    "\n",
    "                        return get_peds_list\n",
    "\n",
    "                    peds_name_list = generater(peds_df)\n",
    "                    peds_list = generater(peds_id_df)\n",
    "\n",
    "                    #英数字以外の文字列の場合はnanに変換\n",
    "                    for index, value in enumerate(peds_list):\n",
    "                        if type(value) == str:\n",
    "                            if re.compile('\\W').search(value):\n",
    "                                peds_list[index] = np.nan\n",
    "\n",
    "                    pedsnamedf = pd.DataFrame(peds_name_list,columns=[horse_id]).T.add_prefix('peds_')\n",
    "                    pedsdf = pd.DataFrame(peds_list,columns=[horse_id]).T.add_prefix('peds_')\n",
    "\n",
    "                    p_name_df = pd.concat([p_name_df,pedsnamedf])\n",
    "                    p_id_df = pd.concat([p_id_df,pedsdf])\n",
    "\n",
    "                    time.sleep(1)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            return p_name_df,p_id_df\n",
    "\n",
    "        def encode(self,st=None):\n",
    "            df = self.peds.copy()\n",
    "\n",
    "            if st!=None:\n",
    "                no_peds = st.data_cp[~st.data_cp['horse_id'].isin(df.index)]['horse_id']\n",
    "                if len(no_peds)>0:\n",
    "                    print('scrape peds at horse_id_list \"no_peds\"')\n",
    "                    print(no_peds)\n",
    "                    no_peds_name,no_peds_id = self.scrape(no_peds)\n",
    "                    no_peds_name.to_pickle('pickle/syutuba/new_peds/peds_name_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "                    no_peds_id.to_pickle('pickle/syutuba/new_peds/peds_id_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "                    df = pd.concat([df,no_peds_id])\n",
    "                    df.to_pickle('pickle/syutuba/latest/peds_id_latest.pickle')\n",
    "\n",
    "            for column in df.columns:\n",
    "                df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "            self.peds_e = df.astype('category')\n",
    "    class Return:\n",
    "        def __init__(self, return_tables):\n",
    "            self.return_tables = return_tables\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(cls, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path))\n",
    "            return cls(df)\n",
    "\n",
    "        @staticmethod\n",
    "        def scrape(race_id_day_dict):\n",
    "        # def scrape(race_id_list):\n",
    "            return_tables = {}\n",
    "            # for race_id in tqdm(race_id_list):\n",
    "\n",
    "            data = pd.DataFrame()\n",
    "            today = datetime.now().strftime('%Y年%m月%d日')\n",
    "            # for race_id in tqdm(race_id_list):\n",
    "            for race_id,date in tqdm(race_id_day_dict.items()):\n",
    "                try:\n",
    "                    # 今日よりも未来の日付の場合、レース情報が出そろっていないためスキップ\n",
    "                    #月曜には更新はいると考えて-2を指定\n",
    "                    if datetime.strptime(date, '%Y年%m月%d日')\\\n",
    "                    >datetime.strptime(today, '%Y年%m月%d日')-timedelta(days=2):\n",
    "                        print('skip_date_id',date,race_id)\n",
    "                        continue\n",
    "\n",
    "                    url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                    #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                    #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                    f = urlopen(url)\n",
    "                    html = f.read()\n",
    "                    html = html.replace(b'<br />', b'br')\n",
    "                    dfs = pd.read_html(html)\n",
    "\n",
    "                    #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                    df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                    df.index = [race_id] * len(df)\n",
    "                    return_tables[race_id] = df\n",
    "                    time.sleep(1)\n",
    "                except IndexError:\n",
    "                    print(race_id)\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(race_id)\n",
    "                    break\n",
    "                except:\n",
    "                    print(race_id)\n",
    "                    break\n",
    "\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "            return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "            return return_tables_df\n",
    "\n",
    "        @property\n",
    "        def fukusho(self):\n",
    "            fukusho = self.return_tables[self.return_tables[0]=='複勝'][[1,2]]\n",
    "            wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "\n",
    "            wins.columns = ['win_0', 'win_1', 'win_2']\n",
    "            returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "            returns.columns = ['return_0', 'return_1', 'return_2']\n",
    "\n",
    "            df = pd.concat([wins, returns], axis=1)\n",
    "            for column in df.columns:\n",
    "                df[column] = df[column].str.replace(',', '')\n",
    "            return df.fillna(0).astype(int)\n",
    "\n",
    "        @property\n",
    "        def tansho(self):\n",
    "            tansho = self.return_tables[self.return_tables[0]=='単勝'][[1,2]]\n",
    "\n",
    "            # if tansho[1].str.contains('br').bool():\n",
    "            #     splitdf = tansho[1].str.split('br', expand=True)[[0,1]]\n",
    "\n",
    "            tansho.columns = ['win', 'return']\n",
    "\n",
    "            for column in tansho.columns:\n",
    "                tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "\n",
    "            return tansho\n",
    "\n",
    "        @property\n",
    "        def umaren(self):\n",
    "            umaren = self.return_tables[self.return_tables[0]=='馬連'][[1,2]]\n",
    "            wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix('win_')\n",
    "            return_ = umaren[2].rename('return')  \n",
    "            df = pd.concat([wins, return_], axis=1)        \n",
    "            return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "        @property\n",
    "        def umatan(self):\n",
    "            umatan = self.return_tables[self.return_tables[0]=='馬単'][[1,2]]\n",
    "            wins = umatan[1].str.split('→', expand=True)[[0,1]].add_prefix('win_')\n",
    "            return_ = umatan[2].rename('return')  \n",
    "            df = pd.concat([wins, return_], axis=1)        \n",
    "            return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "        @property\n",
    "        def wide(self):\n",
    "            wide = self.return_tables[self.return_tables[0]=='ワイド'][[1,2]]\n",
    "            wins = wide[1].str.split('br', expand=True)[[0,1,2]]\n",
    "            wins = wins.stack().str.split('-', expand=True).add_prefix('win_')\n",
    "            return_ = wide[2].str.split('br', expand=True)[[0,1,2]]\n",
    "            return_ = return_.stack().rename('return')\n",
    "            df = pd.concat([wins, return_], axis=1)\n",
    "            return df.apply(lambda x: pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "\n",
    "        @property\n",
    "        def sanrentan(self):\n",
    "            rentan = self.return_tables[self.return_tables[0]=='三連単'][[1,2]]\n",
    "            wins = rentan[1].str.split('→', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "            return_ = rentan[2].rename('return')\n",
    "            df = pd.concat([wins, return_], axis=1) \n",
    "            return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "        @property\n",
    "        def sanrenpuku(self):\n",
    "            renpuku = self.return_tables[self.return_tables[0]=='三連複'][[1,2]]\n",
    "            wins = renpuku[1].str.split('-', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "            return_ = renpuku[2].rename('return')\n",
    "            df = pd.concat([wins, return_], axis=1) \n",
    "            return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    class ModelEvaluator:\n",
    "        def __init__(self, model, return_tables_path_list):\n",
    "            self.model = model\n",
    "            self.rt = Return.read_pickle(return_tables_path_list)\n",
    "            self.fukusho = self.rt.fukusho\n",
    "            self.tansho = self.rt.tansho\n",
    "            self.umaren = self.rt.umaren\n",
    "            self.umatan = self.rt.umatan\n",
    "            self.wide = self.rt.wide\n",
    "            self.sanrentan = self.rt.sanrentan\n",
    "            self.sanrenpuku = self.rt.sanrenpuku\n",
    "            #処理速度改善のために追加\n",
    "            self.y_pred = pd.DataFrame()\n",
    "\n",
    "        #3着以内に入る確率を予測\n",
    "        def predict_proba(self, X, train=True, std=True, minmax=False):\n",
    "            if train:\n",
    "                proba = pd.Series(\n",
    "                    self.model.predict_proba(X.drop(['単勝'], axis=1))[:, 1], index=X.index\n",
    "                )\n",
    "            else:\n",
    "                proba = pd.Series(\n",
    "                    self.model.predict_proba(X)[:, 1], index=X.index\n",
    "                )\n",
    "            if std:\n",
    "                #レース内で標準化して、相対評価する。「レース内偏差値」みたいなもの。\n",
    "                standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "                proba = proba.groupby(level=0).transform(standard_scaler)\n",
    "            if minmax:\n",
    "                #データ全体を0~1にする\n",
    "                proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "            return proba\n",
    "\n",
    "        #0か1かを予測\n",
    "        def predict(self, X, threshold=0.5):\n",
    "            #一度probaを求めたらあとは実行しない\n",
    "            if len(self.y_pred)==0:\n",
    "                print(\"y_pred_none\")\n",
    "                y_pred = self.predict_proba(X)\n",
    "                self.y_pred = y_pred\n",
    "                self.proba = self.y_pred\n",
    "            else:\n",
    "                # print(\"y_pred_exist\")\n",
    "                self.proba = self.y_pred\n",
    "                y_pred = self.y_pred\n",
    "            return [0 if p<threshold else 1 for p in y_pred]\n",
    "\n",
    "        def score(self, y_true, X, train=True):\n",
    "            return roc_auc_score(y_true, self.predict_proba(X,train))\n",
    "\n",
    "        def feature_importance(self, X, n_display=20):\n",
    "            importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                        \"importance\": self.model.feature_importances_})\n",
    "            return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "\n",
    "        def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "            pred_table = X.copy()[['馬番', '単勝']]\n",
    "            pred_table['pred'] = self.predict(X, threshold)\n",
    "            pred_table['score'] = self.proba\n",
    "            if bet_only:\n",
    "                # return pred_table[pred_table['pred']==1][['馬番', '単勝', 'score']]\n",
    "                #馬連馬単のシミュレーション時のエラー回避\n",
    "                return pred_table[pred_table['pred']==1]\n",
    "            else:\n",
    "                return pred_table[['馬番', '単勝', 'score', 'pred']]\n",
    "\n",
    "        def bet(self, race_id, kind, umaban, amount):\n",
    "            if kind == 'fukusho':\n",
    "                rt_1R = self.fukusho.loc[race_id]\n",
    "                return_ = (rt_1R[['win_0', 'win_1', 'win_2']]==umaban).values * \\\n",
    "                    rt_1R[['return_0', 'return_1', 'return_2']].values * amount/100\n",
    "                return_ = np.sum(return_)\n",
    "            if kind == 'tansho':\n",
    "                rt_1R = self.tansho.loc[race_id]\n",
    "                return_ = (rt_1R['win']==umaban) * rt_1R['return'] * amount/100\n",
    "            if kind == 'umaren':\n",
    "                rt_1R = self.umaren.loc[race_id]\n",
    "                return_ = (set(rt_1R[['win_0', 'win_1']]) == set(umaban)) \\\n",
    "                    * rt_1R['return']/100 * amount\n",
    "            if kind == 'umatan':\n",
    "                rt_1R = self.umatan.loc[race_id]\n",
    "                return_ = (list(rt_1R[['win_0', 'win_1']]) == list(umaban))\\\n",
    "                    * rt_1R['return']/100 * amount\n",
    "            if kind == 'wide':\n",
    "                rt_1R = self.wide.loc[race_id]\n",
    "                return_ = (rt_1R[['win_0', 'win_1']].\\\n",
    "                               apply(lambda x: set(x)==set(umaban), axis=1)) \\\n",
    "                    * rt_1R['return']/100 * amount\n",
    "                return_ = return_.sum()\n",
    "            if kind == 'sanrentan':\n",
    "                rt_1R = self.sanrentan.loc[race_id]\n",
    "                return_ = (list(rt_1R[['win_0', 'win_1', 'win_2']]) == list(umaban)) * \\\n",
    "                    rt_1R['return']/100 * amount\n",
    "            if kind == 'sanrenpuku':\n",
    "                rt_1R = self.sanrenpuku.loc[race_id]\n",
    "                return_ = (set(rt_1R[['win_0', 'win_1', 'win_2']]) == set(umaban)) \\\n",
    "                    * rt_1R['return']/100 * amount\n",
    "            if not (return_ >= 0):\n",
    "                    return_ = amount\n",
    "            return return_\n",
    "\n",
    "        def fukusho_return(self, X, threshold=0.5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            n_bets = len(pred_table)\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_list.append(np.sum([\n",
    "                    self.bet(race_id, 'fukusho', umaban, 1) for umaban in preds['馬番']\n",
    "                ]))\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def tansho_return(self, X, threshold=0.5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            # self.sample = pred_table\n",
    "            n_bets = len(pred_table)\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_list.append(\n",
    "                    np.sum([self.bet(race_id, 'tansho', umaban, 1) for umaban in preds['馬番']])\n",
    "                )\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def tansho_return_proper(self, X, threshold=0.5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            n_bets = len(pred_table)\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_list.append(\n",
    "                    np.sum(preds.apply(lambda x: self.bet(\n",
    "                        race_id, 'tansho', x['馬番'], 1/x['単勝']), axis=1)))\n",
    "\n",
    "            bet_money = (1 / pred_table['単勝']).sum()\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / bet_money\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / bet_money\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def umaren_box(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    continue\n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def umatan_box(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    continue   \n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def wide_box(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                #予想結果が１である馬が2頭以上いる場合に成り立つ\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    continue\n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std  \n",
    "\n",
    "        def sanrentan_box(self, X, threshold=0.5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                if len(preds)<3:\n",
    "                    continue\n",
    "                else:\n",
    "                    for umaban in permutations(preds['馬番'], 3):\n",
    "                        return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def sanrenpuku_box(self, X, threshold=0.5):\n",
    "            pred_table = self.pred_table(X, threshold)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                if len(preds)<3:\n",
    "                    continue\n",
    "                else:\n",
    "                    for umaban in combinations(preds['馬番'], 3):\n",
    "                        return_ += self.bet(race_id, 'sanrenpuku', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def umaren_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                        .iloc[1:(n_aite+1)]['馬番']\n",
    "                    return_ = preds_aite.map(\n",
    "                        lambda x: self.bet(\n",
    "                            race_id, 'umaren', [preds_jiku['馬番'].values[0], x], 1\n",
    "                        )\n",
    "                    ).sum()\n",
    "                    n_bets += n_aite\n",
    "                    return_list.append(return_)\n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def umatan_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                        .iloc[1:(n_aite+1)]['馬番']\n",
    "                    return_ = preds_aite.map(\n",
    "                        lambda x: self.bet(\n",
    "                            race_id, 'umatan', [preds_jiku['馬番'].values[0], x], 1\n",
    "                        )\n",
    "                    ).sum()\n",
    "                    n_bets += n_aite\n",
    "\n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def wide_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                return_ = 0\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                        .iloc[1:(n_aite+1)]['馬番']\n",
    "                    return_ = preds_aite.map(\n",
    "                        lambda x: self.bet(\n",
    "                            race_id, 'wide', [preds_jiku['馬番'].values[0], x], 1\n",
    "                        )\n",
    "                    ).sum()\n",
    "                    n_bets += len(preds_aite)\n",
    "                    return_list.append(return_)\n",
    "                elif len(preds_jiku) >= 2:\n",
    "                    for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                        return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        def sanrentan_nagashi(self, X, threshold = 1.5, n_aite=7):\n",
    "            pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "            n_bets = 0\n",
    "            return_list = []\n",
    "            for race_id, preds in pred_table.groupby(level=0):\n",
    "                preds_jiku = preds.query('pred == 1')\n",
    "                if len(preds_jiku) == 1:\n",
    "                    continue\n",
    "                elif len(preds_jiku) == 2:\n",
    "                    preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                        .iloc[2:(n_aite+2)]['馬番']\n",
    "                    return_ = preds_aite.map(\n",
    "                        lambda x: self.bet(\n",
    "                            race_id, 'sanrentan',\n",
    "                            np.append(preds_jiku['馬番'].values, x),\n",
    "                            1\n",
    "                        )\n",
    "                    ).sum()\n",
    "                    n_bets += len(preds_aite)\n",
    "                    return_list.append(return_)\n",
    "                elif len(preds_jiku) >= 3:\n",
    "                    return_ = 0\n",
    "                    for umaban in permutations(preds_jiku['馬番'], 3):\n",
    "                        return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                        n_bets += 1\n",
    "                    return_list.append(return_)\n",
    "\n",
    "            std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "\n",
    "            n_hits = np.sum([x>0 for x in return_list])\n",
    "            return_rate = np.sum(return_list) / n_bets\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "    class ST_results:\n",
    "        def __init__(self,STresults):\n",
    "            self.data = STresults\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(self, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path),False)\n",
    "            return self(df)\n",
    "\n",
    "        @classmethod\n",
    "        def scrape(self,race_id_list):\n",
    "            data = pd.DataFrame()\n",
    "            for race_id in tqdm(race_id_list):\n",
    "                time.sleep(1)\n",
    "                url = 'https://race.netkeiba.com/race/result.html?race_id=' + race_id\n",
    "                # print(url)\n",
    "                df = pd.read_html(url)[0]\n",
    "                df['race_id'] = [race_id] * len(df)\n",
    "                df = df[['race_id','着順','馬番','単勝オッズ']]\n",
    "                data = pd.concat([data, df])\n",
    "            return self(data)\n",
    "    class ST_odds:\n",
    "        def __init__(self,STresults):\n",
    "            self.data = STresults\n",
    "\n",
    "        @classmethod\n",
    "        def read_pickle(self, path_list):\n",
    "            df = pd.read_pickle(path_list[0])\n",
    "            for path in path_list[1:]:\n",
    "                df = update_data(df, pd.read_pickle(path),True)\n",
    "            return self(df)\n",
    "\n",
    "        @classmethod\n",
    "        def scrape(self,race_id_list):\n",
    "            df = pd.DataFrame()\n",
    "            data = pd.DataFrame()\n",
    "\n",
    "            #ブラウザのオプション設定\n",
    "            #IPとポート番号を指定することで、既に開かれているブラウザをつかむキャッチする\n",
    "            #seleniumの保存先　C:\\Windows\\System32\n",
    "            options = Options()\n",
    "            # options.add_argument('--headless')\n",
    "            \n",
    "            driver = webdriver.Chrome(options=options)\n",
    "            #バージョンをその都度確認して更新する場合\n",
    "            # driver = webdriver.Chrome(ChromeDriverManager().install(),options=options)\n",
    "\n",
    "            for race_id in tqdm(race_id_list):\n",
    "                driver.get('https://race.netkeiba.com/odds/index.html?type=b1&race_id=' + race_id + '&rf=shutuba_submenu')\n",
    "                time.sleep(0.5)\n",
    "                url = driver.current_url\n",
    "                table= pd.read_html(url, header = 0)\n",
    "\n",
    "                odds = []\n",
    "                for getelement in driver.find_elements_by_css_selector(\".Odds.transition-color\"):\n",
    "                    text = getelement.text\n",
    "                    odds.append(text)\n",
    "\n",
    "                i=0\n",
    "                df = table[0]\n",
    "\n",
    "                if len(df[~df['選択'].isna()])==0:#取消なしの場合\n",
    "                    for num in df.index:\n",
    "                        df.loc[num,'オッズ']=odds[i]\n",
    "                        i+=1\n",
    "                    for num in df.index:\n",
    "                        df.loc[num,'複勝オッズ']=odds[i]\n",
    "                        i+=1\n",
    "                else:\n",
    "                    for num in df.index:\n",
    "                        if df.loc[num,'選択'] is np.nan:\n",
    "                            df.loc[num,'オッズ']=odds[i]\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            continue\n",
    "                    for num in df.index:\n",
    "                        if df.loc[num,'選択'] is np.nan:\n",
    "                            df.loc[num,'複勝オッズ']=odds[i]\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                df['複勝オッズ_min'] =df['複勝オッズ'].str.split('-', expand=True)[0]\n",
    "                df['複勝オッズ_max'] = df['複勝オッズ'].str.split('-', expand=True)[1]\n",
    "                df.drop(['枠','印','選択','複勝オッズ'], axis=1, inplace=True)\n",
    "                df.rename(columns={'オッズ': '単勝オッズ'}, inplace=True)\n",
    "                df.index = [race_id] * len(df)\n",
    "\n",
    "                data = pd.concat([data, df])\n",
    "            driver.quit()\n",
    "            return self(data)\n",
    "\n",
    "    #関数\n",
    "    def update_data(old, new,index=True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        old : pandas.DataFrame\n",
    "            古いデータ\n",
    "        new : pandas.DataFrame\n",
    "            新しいデータ\n",
    "        \"\"\"\n",
    "        if index:\n",
    "            filtered_old = old[~old.index.isin(new.index)]\n",
    "        else:\n",
    "            #更新されたことになっていないのでは？\n",
    "            filtered_old = old[~old['race_id'].isin(new['race_id'])]\n",
    "\n",
    "        return pd.concat([filtered_old, new])\n",
    "    def split_data(df, test_size=0.3):\n",
    "        sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "        train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "        test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "        train = df.loc[train_id_list]\n",
    "        test = df.loc[test_id_list]\n",
    "        return train, test\n",
    "    def gain(return_func, X, n_samples=100, t_range=[0.5, 2.5]):\n",
    "        gain = {}\n",
    "        for i in tqdm(range(n_samples)):\n",
    "        # for i in range(n_samples):\n",
    "            #min_thresholdから1まで、n_samples等分して、thresholdをfor分で回す\n",
    "            threshold = t_range[1] * i / n_samples + t_range[0] * (1-(i/n_samples))\n",
    "            n_bets, return_rate, n_hits, std = return_func(X, threshold)\n",
    "            if n_bets > 2:\n",
    "                gain[threshold] = {'return_rate': return_rate, \n",
    "                                'n_hits': n_hits,\n",
    "                                'std': std,\n",
    "                                'n_bets': n_bets}\n",
    "        return pd.DataFrame(gain).T\n",
    "    def plot(df, label=' '):\n",
    "        #標準偏差で幅をつけて薄くプロット\n",
    "        plt.fill_between(df.index, y1=df['return_rate']-df['std'],\n",
    "                     y2=df['return_rate']+df['std'],\n",
    "                     alpha=0.3) #alphaで透明度を設定\n",
    "        #回収率を実線でプロット\n",
    "        plt.plot(df.index, df['return_rate'], label=label)\n",
    "        plt.legend() #labelで設定した凡例を表示させる\n",
    "        plt.grid(True) #グリッドをつける\n",
    "    def time_protcol():\n",
    "        #使用する際は事前に下記を実行\n",
    "        #t = time.time()\n",
    "        global t\n",
    "        s = time.time()\n",
    "        print(s-t)\n",
    "        t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63911422-3d43-4092-9346-f9b19eeb4a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pdの行列表示数の設定\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',850)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e6453-34a8-4fb8-8dd8-3b1a579469f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 前日作業"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa122117-25e2-48fb-8c93-d570c9b14e35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データ更新済み確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130d101-92f8-422a-b29c-a11ccc2908c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPI算出用にresultsの先週分まで更新されているか\n",
    "#ShutubaTableの更新確認\n",
    "#LabelEncorderの更新確認\n",
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])\n",
    "print('st.data\\n',pd.to_datetime(st.data['date'], format='%Y年%m月%d日').sort_values(ascending=False).head(1))\n",
    "r22_data_p= pd.read_pickle('pickle/r_data19_21/r_data_p22.pickle')\n",
    "print('\\nr22_data_p\\n',r22_data_p.sort_values(by=['date'],ascending=False)['date'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f58fc-a3a3-4ed2-a8d1-56b371190ae1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 各種スクレイピング作業を事前に行っておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea03213-80f3-4fef-8e36-6836cf5f43de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "#その日に開催されるレースIDと日付けを指定する\n",
    "#日付は予測値に影響を与えるので注意(hrのマージの日付になる)\n",
    "\"\"\"\n",
    "date = '2022年12月4日'\n",
    "#開催場所に合わせて設定\n",
    "racenum = 12\n",
    "race_id_list1 = ['2022060502{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = ['2022090602{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list3 = ['2022070602{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list = race_id_list1 + race_id_list2 + race_id_list3\n",
    "# race_id_list = race_id_list1 + race_id_list2\n",
    "\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b1a8d-f00e-45e6-a1d4-58c75e614571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #前日オッズを取得\n",
    "# odds = ST_odds.scrape(race_id_day_dict.keys())\n",
    "# odds.data.to_pickle('pickle/syutuba/race/odds/the_day_befor_odds/odds_{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7c016-4b52-439f-a4cb-24ccc325e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#スクレイピングして保存(馬体重なしになる)(前日情報として別で保存)\n",
    "st = ShutubaTable.scrape(race_id_day_dict,False)\n",
    "st.data.to_pickle('pickle/syutuba/race/day_before/syutuba_{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636891e-8891-49f6-b412-fab741693966",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/day_before/syutuba_{}.pickle'.format(date)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e495bce-0647-4b60-bad7-ffae5aff0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d67779-58fe-41dd-a547-7c058daa0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#horse_info,jockey_idを取得する\n",
    "st.merge_horse_info(hi)\n",
    "st.merge_jockey_info(jr,5)\n",
    "st.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d02cb-c840-49a6-a7ea-e66d578e43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#海外jockeyなどの新しいジョッキーが出てきた場合にデータが存在しなく、\n",
    "#エラーとなった場合に手動でデータを追加する手順\n",
    "#no text parsed from document (line 0)\n",
    "# test = pd.read_pickle('pickle/syutuba/latest/jockey_id_latest.pickle')\n",
    "# test.loc['05628'] = 0#更新\n",
    "# test[test.index.isin(['a0436','05628','05464'])]#確認\n",
    "# test.to_pickle('pickle/syutuba/latest/jockey_id_latest.pickle')#保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa5993-16cc-4096-a8ab-eb14033046ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#出走馬のhorse_resulsを取得する\n",
    "horse_id_list = st.data[st.data.index.isin(list(race_id_day_dict))]['horse_id'].unique()\n",
    "h_results = HorseResults.scrape(horse_id_list,True)\n",
    "h_results.to_pickle('pickle/syutuba/new_h_results/h_results_'+datetime.now().strftime('%m_%d')+'.pickle')\n",
    "hr = HorseResults.read_pickle(['pickle/syutuba/latest/horse_results_latest.pickle',\\\n",
    "                              'pickle/syutuba/new_h_results/h_results_'+datetime.now().strftime('%m_%d')+'.pickle'])\n",
    "hr.horse_results.to_pickle('pickle/syutuba/latest/horse_results_latest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c177f-d1e4-427c-878f-d402de624f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#マージ用にrの作成\n",
    "r = Results.read_pickle(['pickle/syutuba/r_data/r_data_latest.pickle'])\n",
    "jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "hr = HorseResults.read_pickle(['pickle/syutuba/latest/horse_results_latest.pickle'])\n",
    "hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "\n",
    "past_race_num=10\n",
    "t = time.time()\n",
    "r.merge_horse_info(hi)\n",
    "r.merge_jockey_info(jr,5)\n",
    "time_protcol()\n",
    "r.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b69d1-b3b4-46c1-9d8b-e6cec6b17537",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.preprocessing()\n",
    "past_race_num=10\n",
    "st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "st.concat_past_data(hr,past_race_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e198a-e10d-4a1d-b0df-9c76a9d75764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pedsが存在しない場合は自動更新\n",
    "p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "p.encode(st)\n",
    "st.merge_peds(p.peds_e)\n",
    "st.data_pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b9f28-50fd-4dd7-8237-7c305b134394",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 当日自動実行プログラム"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa055a1a-b17d-405c-ba89-cd900309adb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a59dbe-aa68-4528-bee0-df89e4061eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1_予測値の保存先ディレクトリの作成\n",
    "def making_dir(date):\n",
    "    os.makedirs('pickle/syutuba/race/'+date)\n",
    "    os.makedirs('pickle/syutuba/race/'+date+'/std')\n",
    "    os.makedirs('pickle/syutuba/race/'+date+'/first_result')\n",
    "    os.makedirs('pickle/syutuba/race/'+date+'/latest_odds')\n",
    "    os.makedirs('pickle/syutuba/生予測値/stdata_c/'+date)\n",
    "#2_JRAからレース時刻一覧を取得してrace_scheduleを作成する\n",
    "def get_racetime(date):\n",
    "    #レースページから１R目の開始時間を取得する\n",
    "    options = Options()\n",
    "    # options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    year,month,day,tmp = re.split('\\D+', date)\n",
    "    # year,month,day = date[:4],date[5:7],date[8:10]\n",
    "    # 取得するWEBページのURL(urlの作成を自動にする)\n",
    "    url=\"https://www.jra.go.jp/keiba/calendar\"\\\n",
    "    +year+\"/\"+year+\"/\"+month.zfill(2)+\"/\"+month.zfill(2)+day.zfill(2)+\".html\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # HTTPリクエストヘッダにユーザーエージェントを設定\n",
    "    headers = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "    # WEBページデータを取得\n",
    "    response = requests.get(url=url, headers=headers)\n",
    "    response.encoding = response.apparent_encoding\n",
    "\n",
    "    #開催場の取得\n",
    "    place = []\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "    texts = soup.find_all(class_=\"inner\")\n",
    "    for text in texts:\n",
    "        if '回' in text.text and '日' in text.text:\n",
    "            # print(text.text)\n",
    "            place.append(text.text.replace('\\n', ''))\n",
    "\n",
    "    # タイムスケジュールを取得\n",
    "    df = pd.read_html(response.text,header = 0)\n",
    "    #タイムスケジュールに開催場を追加\n",
    "    race_timedf = pd.DataFrame()\n",
    "    df = pd.read_html(response.text,header = 0)\n",
    "    for i in range(0,len(df)):\n",
    "        df[i].insert(0, '開催', place[i])\n",
    "        race_timedf = pd.concat([race_timedf,df[i]])\n",
    "    driver.quit()\n",
    "    return race_timedf\n",
    "#3_race_scheduleの加工\n",
    "def create_day_schedule(race_id_list,race_schedulen,num=3,bet_time=2):\n",
    "    maindf = pd.DataFrame()\n",
    "    #レースIDと開催場の対応dataframe作成\n",
    "    def create_raceid_df(race_id_list):\n",
    "        place_list =[]\n",
    "        place_dict = {\n",
    "            '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "            '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "        }\n",
    "        place_dict = { place_dict[ i ] : i for i in place_dict.keys() }#keyとvalueの転換\n",
    "\n",
    "        for race_id in race_id_list:\n",
    "            place_list.append(place_dict[race_id[4:6]])\n",
    "        return pd.DataFrame([race_id_list,place_list],index=['race_id','place']).T\n",
    "    race_id_df = create_raceid_df(race_id_list)\n",
    "\n",
    "    #タイムスケジュールにrace_idを追加\n",
    "    def con_race_id_df(race_schedule,race_id_df,place):\n",
    "        temp1 = race_schedule[race_schedule['開催'].str.contains(place)]\n",
    "        temp2 = race_id_df[race_id_df['place'].str.contains(place)]\n",
    "        temp2.reset_index(inplace=True, drop=True)\n",
    "        concatdf = pd.concat([temp1,temp2],axis=1)\n",
    "        return concatdf\n",
    "    maindf = pd.concat([con_race_id_df(race_schedule,race_id_df,place) for place in race_id_df['place'].unique()],axis=0)\n",
    "    maindf['R'] = maindf['レース番号'].map(lambda x :re.sub(r\"\\D\", \"\", x))#レース番号を番号のみに変換\n",
    "    maindf[\"time\"] = pd.to_datetime(race_schedule[\"発走時刻\"],format=\"%H時%M分\")#時刻をdatetime型に変換\n",
    "    maindf['get_odds_time']  = maindf['time'].map(lambda x: str(x + timedelta(minutes=-bet_time))[11:16])\n",
    "\n",
    "    #各レース回の初回レース10分前に設定\n",
    "    scrape_times,scrape_time = [],[]\n",
    "    for i in range(1,13):\n",
    "        one_rtime = maindf[maindf['レース番号']=='{}レース'.format(i)]['time'].min()\n",
    "        scrape_times.append(one_rtime + timedelta(minutes=-10))\n",
    "\n",
    "    #各レース回のレイピングタイミング\n",
    "    for i in range(0,12):\n",
    "        scrape_time.append(str(scrape_times[i])[11:16])\n",
    "    maindf['get_race_time'] = scrape_time*num\n",
    "    return maindf.iloc[:,4:]\n",
    "#4_予測値の算出\n",
    "def create_race_pred(race_id_day_dict,date,hr_p_backup,r):\n",
    "    \n",
    "    start_text = 'Start scraping ShutubaTable.',list(race_id_day_dict.keys())\n",
    "    with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "        print(start_text,file=f)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    st = ShutubaTable.scrape(race_id_day_dict,False)\n",
    "    for rid,date in race_id_day_dict.items():\n",
    "        st.data[st.data.index==rid].to_pickle('pickle/syutuba/race/{0}/syutuba_{1}.pickle'.format(date,rid))\n",
    "    \n",
    "    #不足データがある場合、スクレイピングされ常に更新されていく\n",
    "    hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "    st.merge_horse_info(hi)\n",
    "    jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "    st.merge_jockey_info(jr,5)\n",
    "    st.preprocessing()\n",
    "    hr.horse_results_p = hr_p_backup.copy()\n",
    "    past_race_num=10\n",
    "    st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "    st.concat_past_data(hr,past_race_num)\n",
    "    p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "    p.encode(st)\n",
    "    st.merge_peds(p.peds_e)\n",
    "    \n",
    "    #最新ラベルエンコーダーの読み込み\n",
    "    def Read_Label_Encorder(r):\n",
    "        with open('pickle/LabelEncoder/le_horse.pickle', 'rb') as f:\n",
    "            r.le_horse = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_jockey.pickle', 'rb') as f:\n",
    "            r.le_jockey = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_class.pickle', 'rb') as f:\n",
    "            r.le_class = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_place.pickle', 'rb') as f:\n",
    "            r.le_place = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_trainer.pickle', 'rb') as f:\n",
    "            r.le_trainer = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_horseowner.pickle', 'rb') as f:\n",
    "            r.le_horseowner = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_producer.pickle', 'rb') as f:\n",
    "            r.le_producer = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_relative1.pickle', 'rb') as f:\n",
    "            r.le_relative1 = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_relative2.pickle', 'rb') as f:\n",
    "            r.le_relative2 = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_kai.pickle', 'rb') as f:\n",
    "            r.le_kai = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_day.pickle', 'rb') as f:\n",
    "            r.le_day = pickle.load(f)\n",
    "    Read_Label_Encorder(r)\n",
    "    \n",
    "    #カテゴリデータへ変換\n",
    "    st.process_categorical\\\n",
    "    (r.le_horse,r.le_jockey,r.le_class,r.le_place,r.data_pe,r.le_trainer,r.le_horseowner,\\\n",
    "     r.le_producer,r.le_relative1,r.le_relative2,r.le_kai,r.le_day,past_race_num)\n",
    "\n",
    "    #カテゴリデータの順番整理\n",
    "    # latest_colcategory = pd.read_pickle('pickle/st_data/category_std/st_data20220827.pickle')\n",
    "    latest_colcategory = pd.read_pickle('pickle/st_data/st_data_c_latest_categories.pickle')\n",
    "    for index ,name in latest_colcategory.head(0).dtypes.iteritems():\n",
    "        if name=='category':\n",
    "            # print(index)\n",
    "            new = list(st.data_c[index].cat.categories)\n",
    "            moto = list(latest_colcategory[index].cat.categories)\n",
    "            number = 0\n",
    "            befor = 0\n",
    "            changeFLG=False\n",
    "            A,B,C,D=[],[],[],[]\n",
    "            D = list(set(new)-set(moto))#完全に新しく出てきたもの\n",
    "            # if len(D)>0:\n",
    "            #     print('new_label_encode',index,D)\n",
    "            for i in moto:\n",
    "                if befor <= i:\n",
    "                    befor = i\n",
    "                    number+=1\n",
    "                else:\n",
    "                    changeFLG = True\n",
    "                    A = moto[:number]#前半 直前まで出たもの\n",
    "                    B = moto[number:]#後半 2021まで出ていたもの\n",
    "                    C = list(set(B)&set(new))#今回新たに出ているが過去にも出たことのあるもの\n",
    "                    # for s in C:\n",
    "                    #     B.remove(s)\n",
    "                    # B = [s for s in B if s not in C]\n",
    "                    list(map(lambda x: B.remove(x), C))\n",
    "            if changeFLG==False:\n",
    "                A = moto[:number]#前半 直前まで出たもの\n",
    "                B = moto[number:]#後半 2021まで出ていたもの\n",
    "                C = list(set(B)&set(new))#今回新たに出ているが過去にも出たことのあるもの\n",
    "                list(map(lambda x: B.remove(x), C))\n",
    "    \n",
    "            setlist = (sorted(A+C)+sorted(D)+(B))\n",
    "            # time_protcol()\n",
    "\n",
    "            if len(setlist)==0:#何も更新がなかった場合\n",
    "                # print('更新なし',index)\n",
    "                st.data_c[index] =st.data_c[index].cat.set_categories((moto))\n",
    "            else:\n",
    "                #前半部分に新しいリストを合わせて昇順にする\n",
    "                st.data_c[index] =st.data_c[index].cat.set_categories((setlist))\n",
    "\n",
    "    #標準偏差列を追加して特徴量を合わせる\n",
    "    def std_data_proccesing(st):\n",
    "        #並び替えとindexのsetとタイトル削除\n",
    "        st.data_c=st.data_c.sort_values(['race_id','馬番'])\n",
    "        st.data_c.set_index('race_id',inplace = True)\n",
    "        st.data_c =st.data_c.rename_axis(index=None)\n",
    "\n",
    "        #特徴量を削除\n",
    "        # st.data_c.drop(columns =['time','final_to_rank_my_allR','jockey_id'],inplace = True)\n",
    "        st.data_c.drop(columns =['time'],inplace = True)\n",
    "\n",
    "        #レースIDごとに標準偏差に変更する\n",
    "        std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R', 'final_to_rank_8p', '体重_8p']\n",
    "        # std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R']\n",
    "        standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "        st.data_c[list(map(lambda x:  x+'_std', std_tar_col))] = st.data_c[std_tar_col].groupby(level=0).transform(standard_scaler)\n",
    "\n",
    "        #学習モデルの特徴量を合わせるために、保存したデータを読み込み\n",
    "        col_df = pd.read_pickle('pickle/syutuba/columns/r_columns.pickle')\n",
    "        if len(set(col_df.columns.tolist())-set(st.data_c.columns.tolist())) != 0:\n",
    "            print(set(col_df.columns.tolist())-set(st.data_c.columns.tolist()))\n",
    "        elif len(set(st.data_c.columns.tolist())-set(col_df.columns.tolist())) != 0:\n",
    "            print(set(st.data_c.columns.tolist())-set(col_df.columns.tolist()))\n",
    "\n",
    "        #不足分をリスト化して追加する\n",
    "        col = set(col_df.columns)-set(st.data_c.columns)\n",
    "        st.data_c[list(col)]=0\n",
    "    std_data_proccesing(st)\n",
    "    \n",
    "    #予測前データの保存\n",
    "    for rid,date in race_id_day_dict.items():\n",
    "        st.data_c[st.data_c.index==rid].to_pickle('pickle/syutuba/生予測値/stdata_c/{0}/stdata_c_std{1}.pickle'.format(date,rid))\n",
    "    \n",
    "    #カテゴリデータのnullチェック\n",
    "    def check_null_category(stdata_c):\n",
    "        nullcheck = False\n",
    "        for index ,name in stdata_c.head(0).dtypes.iteritems():\n",
    "            if name=='category':\n",
    "                if len(stdata_c[stdata_c[index].isna()==True])>0:\n",
    "                    nullcheck = True\n",
    "                    print(index,len(stdata_c[stdata_c[index].isna()==True]))\n",
    "        if nullcheck==False:\n",
    "            print('not exist null in category data.')\n",
    "        else:\n",
    "            print('exist null in category data.')   \n",
    "    check_null_category(st.data_c)\n",
    "    \n",
    "    #学習モデルに予測させる\n",
    "    def Created_predscore(st, r, returnModel, top4Model):\n",
    "        stX_test = st.data_c.drop(['着順', '人気','date','生年月日'], axis=1)\n",
    "        # stX_test = test.drop(['着順', '人気','date','生年月日'], axis=1)\n",
    "\n",
    "        #学習モデルの読み込み\n",
    "        lgb_clf_return = pickle.load(open('./pickle/syutuba/学習モデル/'+returnModel+'.pkl', 'rb'))\n",
    "        lgb_clf_top4 = pickle.load(open('./pickle/syutuba/学習モデル/'+top4Model+'.pkl', 'rb'))\n",
    "\n",
    "        #ModelEvaluatorクラスのオブジェクトを作成\n",
    "        #予想時にはreturn情報はないので、適当によみこむ\n",
    "        me_st_return = ModelEvaluator(lgb_clf_return, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "        me_st_top4 = ModelEvaluator(lgb_clf_top4, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "\n",
    "        #predの算出\n",
    "        scores = me_st_return.predict_proba(stX_test)\n",
    "        pred = stX_test[['馬番','horse_id','class','place']].copy()\n",
    "        #ラベルデコード\n",
    "        pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "        pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "        pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "        pred['score'] = scores\n",
    "        pred_return = pred.copy()\n",
    "        #predの算出\n",
    "        scores = me_st_top4.predict_proba(stX_test)\n",
    "        pred = stX_test[['馬番','horse_id','class','place']].copy()\n",
    "        #ラベルデコード\n",
    "        pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "        pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "        pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "        pred['score'] = scores\n",
    "        pred_top4 = pred.copy()\n",
    "\n",
    "        #mergeするためにindexをカラムにして、merge後元に戻す\n",
    "        st.data.reset_index(inplace=True)\n",
    "        st.data.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        pred_return.reset_index(inplace=True)\n",
    "        pred_return.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        pred_top4.reset_index(inplace=True)\n",
    "        pred_top4.rename(columns={'index': 'race_id'},inplace=True)\n",
    "\n",
    "        AI_return = pred_return.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "        AI_top4 = pred_top4.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "        AI_top4 = AI_top4.merge(st.data[['race_id','date']].drop_duplicates(),how='left',left_on=['race_id'],right_on=['race_id'])\n",
    "\n",
    "        st.data.set_index('race_id',inplace = True)\n",
    "        st.data.index.name = None\n",
    "        pred_return.set_index('race_id',inplace = True)\n",
    "        pred_return.index.name = None\n",
    "        pred_top4.set_index('race_id',inplace = True)\n",
    "        pred_top4.index.name = None\n",
    "\n",
    "        AI_return.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "        AI_return = AI_return.reindex(columns=['race_id','le_place','馬番','馬名','le_class','score'])\n",
    "\n",
    "        AI_top4.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "        AI_top4 = AI_top4.reindex(columns=['race_id','date','le_place','馬番','馬名','le_class','score'])\n",
    "\n",
    "        place_dict = {\n",
    "        '01':'札幌',  '02':'函館',  '03':'福島',  '04':'新潟',  '05':'東京', \n",
    "        '06':'中山',  '07':'中京',  '08':'京都',  '09':'阪神',  '10':'小倉'\n",
    "        }\n",
    "        AI_return = AI_return.replace(place_dict)\n",
    "        AI_top4 = AI_top4.replace(place_dict)\n",
    "\n",
    "        AI = AI_top4.merge(AI_return[['race_id','馬名','score']],how='left',left_on=['race_id','馬名'],right_on=['race_id','馬名'])\n",
    "        AI.rename(columns={'score_x': 'score_top4','score_y': 'score_return',},inplace=True)\n",
    "        AI.insert(loc=3,column='R',value=AI['race_id'].str[-2:])\n",
    "        return AI\n",
    "    returnModel = '19-21学習モデル_750'\n",
    "    top4Model = '19-21的中型上位4位モデル'\n",
    "    AI = Created_predscore(st, r, returnModel, top4Model)\n",
    "    \n",
    "    #オッズを結合する\n",
    "    def concate_odds(race_id_day_dict,current_time,AI):\n",
    "        st_odds = ST_odds.scrape(race_id_day_dict.keys())\n",
    "        st_odds.data.to_pickle('pickle/syutuba/race/odds/st_odds_{}.pickle'.format(current_time))\n",
    "        STR=ST_odds.read_pickle(['pickle/syutuba/race/odds/st_odds_latest.pickle','pickle/syutuba/race/odds/st_odds_{}.pickle'.format(current_time)])\n",
    "        STR.data.to_pickle('pickle/syutuba/race/odds/st_odds_latest.pickle')\n",
    "        STR.data.reset_index(inplace=True)\n",
    "        STR.data.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        add_odds = AI.merge(STR.data,how='left',left_on=['race_id','馬番'],right_on=['race_id','馬番'])\n",
    "        add_odds.drop(columns = '馬名_y' ,inplace = True)\n",
    "        rankdf = add_odds.copy()\n",
    "        rankdf['score_rank'] = add_odds.groupby(by = 'race_id')['score_top4'].rank(ascending=False)\n",
    "        rankdf['return_rank'] = add_odds.groupby(by = 'race_id')['score_return'].rank(ascending=False)\n",
    "        first_result = rankdf.sort_values(['le_place','R','馬番'], ascending=True).copy()\n",
    "        return first_result\n",
    "    first_result = concate_odds(race_id_day_dict, current_time, AI)\n",
    "    \n",
    "    #予測値の保存\n",
    "    for rid,date in race_id_day_dict.items():\n",
    "        first_result[first_result['race_id']==rid].to_pickle('pickle/syutuba/race/{0}/first_result/first_result_{1}.pickle'.format(date,rid))\n",
    "    \n",
    "    clear_output(True)#出力の削除\n",
    "    \n",
    "    end_text = 'create_race_pred finished.'\n",
    "    print(end_text)\n",
    "    with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "        print(end_text,file=f)\n",
    "\n",
    "    return first_result\n",
    "#5_1ネット投票ログイン\n",
    "def login_netkeiba(JRA_type):\n",
    "    options = Options()\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    if JRA_type == \"tyuuou\":\n",
    "        url=\"https://www.ipat.jra.go.jp/sp/\"#中央競馬\n",
    "        btnname = \"btnGreen\"\n",
    "    else:\n",
    "        url=\"https://n.ipat.jra.go.jp/sp/\"#地方競馬\n",
    "        btnname = \"btnBrown\"\n",
    "    driver.get(url)\n",
    "    driver.find_element(By.ID,\"userid\").send_keys(\"\")\n",
    "    driver.find_element(By.ID,\"password\").send_keys(\"\")\n",
    "    driver.find_element(By.ID,\"pars\").send_keys(\"\")\n",
    "    time.sleep(2)\n",
    "    # driver.find_element(By.CLASS_NAME, 'btnGreen').click()#中央競馬\n",
    "    driver.find_element(By.CLASS_NAME, btnname).click()#地方競馬\n",
    "    time.sleep(2)\n",
    "    if (len(driver.find_elements(By.CLASS_NAME, 'ico_regular'))) ==0:\n",
    "        driver.find_element(By.CLASS_NAME, btnname).click()#OKボタンが挟まれるとき必要\n",
    "    # print(driver.window_handles[-1])\n",
    "    return driver\n",
    "#5_2ネット投票サイトから最新オッズの取得\n",
    "def get_latest_odds(kaisai,kai,driver,date=\"hoge\",race_id=\"test\"):\n",
    "    sec=2#ブラウザ遷移の待機時間\n",
    "    time.sleep(sec)\n",
    "    driver.find_element(By.CLASS_NAME, 'ico_regular').click()#通常投票\n",
    "    driver.find_element(By.PARTIAL_LINK_TEXT,kaisai).click()#競馬場\n",
    "    time.sleep(sec)\n",
    "    driver.find_element(By.PARTIAL_LINK_TEXT,str(kai)+'R').click()#何Rか\n",
    "    time.sleep(sec)\n",
    "    driver.find_element(By.PARTIAL_LINK_TEXT,'単勝').click()\n",
    "    time.sleep(sec)\n",
    "    b=driver.find_element(By.CLASS_NAME,'selectHorse').find_elements(By.CLASS_NAME,'ui-link')\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    odds_df = pd.DataFrame()\n",
    "    horseNumber=[]#馬番\n",
    "    horseName=[]#馬名\n",
    "    odds=[]#オッズ\n",
    "    torikeshi=False#出走取り消しが存在するか\n",
    "\n",
    "    for n in range(len(b)):\n",
    "        x=b[n].text.split('\\n')\n",
    "        horseNumber.append(x[0])\n",
    "        horseName.append(x[1])\n",
    "        if x[2]!='取消':\n",
    "            odds.append(x[2])\n",
    "        else:\n",
    "            odds.append('-')\n",
    "            torikeshi=True\n",
    "    \n",
    "    # driver.find_element(By.LINK_TEXT,'トップメニュー').click()#通常投票画面に返る\n",
    "    \n",
    "    odds_df = pd.DataFrame([horseNumber,horseName,odds],index=[\"馬番\", \"馬名\", \"単勝オッズ\"] ).T\n",
    "    odds_df.to_pickle('pickle/syutuba/race/{0}/latest_odds/{1}_{2}_{3}.pickle'.format(date,race_id,kaisai,kai))\n",
    "    \n",
    "    return odds_df\n",
    "#5_取得した最新オッズで購入対象馬を選定して購入する\n",
    "def Forecast_calculation(race_id,kaisai,R,date):\n",
    "    start_text = race_id,kaisai,R+'R','Get the latest odds and decide which horses to buy.'\n",
    "    print(start_text)\n",
    "    with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "        print(start_text,file=f)\n",
    "    sec=2#ブラウザ遷移の待機時間\n",
    "    #race_idによる予測値表の読み込み\n",
    "    pred_df=pd.DataFrame()\n",
    "    path_list=[]\n",
    "    path = 'pickle/syutuba/race/'+date+'/first_result/first_result_{}.pickle'.format(race_id)\n",
    "    pred_df = pd.read_pickle(path)\n",
    "    \n",
    "    if len(pred_df) != 0:#障害レース以外の時\n",
    "        \n",
    "        #開催とRによる最新オッズの取得\n",
    "        driver = login_netkeiba('tyuuou')#tyuuouに変更\n",
    "        odds = get_latest_odds(kaisai,R,driver,date,race_id)#kaisaiとRを使用する\n",
    "\n",
    "        #オッズの入れ替え\n",
    "        pred_df.loc[:,'単勝オッズ']=odds[odds['単勝オッズ']!='-']['単勝オッズ'].values\n",
    "        pred_df.loc[:,'単勝オッズ'] = pred_df['単勝オッズ'].astype(str)\n",
    "\n",
    "        #各モデルでの予測値の算出\n",
    "        range_exp = 0 #期待値のレンジ幅\n",
    "        return_money = 90000 #払い戻し金額設定\n",
    "        return_pred = return_model(pred_df, range_exp, return_money)#期待値範囲０にすること\n",
    "        top_pred = top_model(pred_df, range_exp, return_money)\n",
    "        hybrid = hybrid_model(pred_df,return_pred,top_pred,range_exp)\n",
    "        index = index_model(pred_df)\n",
    "        hybrid2 = hybrid2_model(pred_df)\n",
    "        \n",
    "        #購入対象の決定\n",
    "        buyList = []#購入する馬番リストを作る\n",
    "        buyList.extend(return_pred['馬番'].values)\n",
    "        with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "            print('return_pred',buyList,file=f)\n",
    "\n",
    "        buyList.extend(hybrid['馬番'].values)#index対象馬の追加\n",
    "        with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "            print('hybrid',hybrid['馬番'].values,file=f)\n",
    "\n",
    "        buyList.extend(index['馬番'].values)#index対象馬の追加\n",
    "        with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "            print('index',index['馬番'].values,file=f)\n",
    "        \n",
    "        # buyList.extend(hybrid2['馬番'].values)#index対象馬の追加\n",
    "        with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "            print('hybrid2',hybrid2['馬番'].values,file=f)\n",
    "        \n",
    "        buyList = list(set(buyList))#購入馬番の重複を除く\n",
    "        \n",
    "        #取消が存在する場合の処理はどうなっていたかサイト確認\n",
    "        if len(buyList) == 0:\n",
    "            output_text = kaisai + R + 'R'+\"は購入しない\"\n",
    "            print(output_text)\n",
    "            with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "                print(output_text,file=f)\n",
    "        else:\n",
    "            for n in range(len(buyList)):#buyListの中身を購入する\n",
    "                umaban = buyList[n]\n",
    "                output_text = kaisai + R + 'R '+str(umaban) + \"番、\" +str(odds['馬名'][umaban-1]) + \"、オッズ\" + str(odds['単勝オッズ'][umaban-1])\n",
    "                print(output_text)\n",
    "                with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "                    print(output_text,file=f)\n",
    "                driver.find_element(By.CLASS_NAME,'selectHorse').find_elements(By.CLASS_NAME,'ui-link')[umaban-1].click()\n",
    "                time.sleep(sec)\n",
    "                driver.find_element(By.CLASS_NAME, 'ui-input-text').send_keys(\"10\")\n",
    "                time.sleep(sec)\n",
    "                driver.find_element(By.LINK_TEXT,'セット').click()\n",
    "                time.sleep(sec)\n",
    "                driver.find_element(By.PARTIAL_LINK_TEXT,'番から').click()\n",
    "                time.sleep(sec)\n",
    "            driver.find_element(By.LINK_TEXT,'取消').click()\n",
    "            time.sleep(sec)\n",
    "            driver.find_element(By.LINK_TEXT,'入力終了').click()\n",
    "            time.sleep(sec)\n",
    "            driver.find_element(By.ID,'sum').send_keys(str(len(buyList)*1000))\n",
    "            time.sleep(sec)\n",
    "            driver.find_element(By.LINK_TEXT,'投票').click()\n",
    "            time.sleep(sec)\n",
    "            Alert(driver).accept()\n",
    "            time.sleep(sec)\n",
    "            driver.find_element(By.LINK_TEXT,'続けて通常投票').click()#通常投票画面に返る\n",
    "            time.sleep(sec)\n",
    "        driver.quit()\n",
    "            \n",
    "    else:#障害レースの時(スクレイピングファイルはあるが、中身がない)\n",
    "        syogai_text = race_id,kaisai,R+'R','This race is Obstacle race.'\n",
    "        print(syogai_text)\n",
    "        with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "            print(syogai_text,file=f)\n",
    "    \n",
    "    end_text = race_id,kaisai,R+'R','Forecast_calculation finished.'\n",
    "    with open('pickle/syutuba/race/'+date+'/console_log.txt', 'a', encoding='sjis') as f:\n",
    "        print(end_text,file=f)\n",
    "        \n",
    "#5_3穴馬モデル\n",
    "def return_model(first_result, range_exp, return_money):\n",
    "    top3 = first_result[first_result['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "    top3 = top3[~(top3['単勝オッズ'].str.contains('-', na=False))]\n",
    "    top3 = top3.astype({'単勝オッズ': float})\n",
    "    top3['期待値'] = top3['score_return']*top3['単勝オッズ']\n",
    "    top3 = top3.sort_values('期待値', ascending=True)\n",
    "    # ['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "    dropcol = ['score_rank','return_rank','複勝オッズ_min','複勝オッズ_max']\n",
    "    top3.drop(columns=dropcol,inplace=True)\n",
    "\n",
    "    #開催場別に期待値を設定する\n",
    "    top3.loc[top3['le_place'] == '札幌', 'min_exp'] = 8.4\n",
    "    top3.loc[top3['le_place'] == '札幌', 'max_exp'] = 11.4\n",
    "    top3.loc[top3['le_place'] == '小倉', 'min_exp'] = 9.4\n",
    "    top3.loc[top3['le_place'] == '小倉', 'max_exp'] = 12.4\n",
    "    top3.loc[top3['le_place'] == '新潟', 'min_exp'] = 7.5\n",
    "    top3.loc[top3['le_place'] == '新潟', 'max_exp'] = 10.5\n",
    "    top3.loc[top3['le_place'] == '阪神', 'min_exp'] = 10.2\n",
    "    top3.loc[top3['le_place'] == '阪神', 'max_exp'] = 13.2\n",
    "    top3.loc[top3['le_place'] == '中京', 'min_exp'] = 12.2\n",
    "    top3.loc[top3['le_place'] == '中京', 'max_exp'] = 15.2\n",
    "    top3.loc[top3['le_place'] == '中山', 'min_exp'] = 11.1\n",
    "    top3.loc[top3['le_place'] == '中山', 'max_exp'] = 14.1\n",
    "    top3.loc[top3['le_place'] == '東京', 'min_exp'] = 11.8\n",
    "    top3.loc[top3['le_place'] == '東京', 'max_exp'] = 14.8\n",
    "    top3.loc[top3['le_place'] == '福島', 'min_exp'] = 14.9\n",
    "    top3.loc[top3['le_place'] == '福島', 'max_exp'] = 17.9\n",
    "    top3.loc[top3['le_place'] == '函館', 'min_exp'] = 5.2\n",
    "    top3.loc[top3['le_place'] == '函館', 'max_exp'] = 8.2\n",
    "\n",
    "    top3=top3[(top3['期待値']>top3['min_exp']-range_exp) & (top3['期待値']<top3['max_exp']+range_exp)]\n",
    "    top3=top3[top3['score_return']>0.7]#足きりスコア\n",
    "    top3['minオッズ']=round(top3['min_exp']/top3['score_return'],2)\n",
    "    top3['maxオッズ']=round(top3['max_exp']/top3['score_return'],2)\n",
    "    top3['max_bet'] = round(1/top3['minオッズ']*return_money,-2)\n",
    "    top3['min_bet'] = round(1/top3['maxオッズ']*return_money,-2)\n",
    "    top3['期待値'] = round(top3['期待値'],1)\n",
    "    top3.drop(columns=['min_exp','max_exp','期待値'],inplace=True)\n",
    "    return top3.sort_values(['le_place','R','馬番'], ascending=True)\n",
    "#5_4本命モデルttps://db.netkeiba.com/jockey/result/recent/05621p\n",
    "def top_model(first_result, range_exp, return_money):\n",
    "    top2 = first_result[first_result['score_rank'] <= 2].sort_values(by = ['race_id','score_top4'], ascending=False)\n",
    "    top2 = top2[~(top2['単勝オッズ'].str.contains('-', na=False))]\n",
    "    top2 = top2.astype({'単勝オッズ': float})\n",
    "    top2['期待値'] = (top2['score_top4'])*top2['単勝オッズ']\n",
    "    top2 = top2.sort_values('期待値', ascending=True)\n",
    "    dropcol = ['score_rank','return_rank','複勝オッズ_min','複勝オッズ_max']\n",
    "    top2.drop(columns=dropcol,inplace=True)\n",
    "\n",
    "    #開催場別に期待値を設定する\n",
    "    top2.loc[top2['le_place'] == '札幌', 'min_exp'] = 8.4\n",
    "    top2.loc[top2['le_place'] == '札幌', 'max_exp'] = 10.4\n",
    "    top2.loc[top2['le_place'] == '小倉', 'min_exp'] = 10.6\n",
    "    top2.loc[top2['le_place'] == '小倉', 'max_exp'] = 12.6\n",
    "    top2.loc[top2['le_place'] == '新潟', 'min_exp'] = 9.1\n",
    "    top2.loc[top2['le_place'] == '新潟', 'max_exp'] = 11.1\n",
    "    top2.loc[top2['le_place'] == '阪神', 'min_exp'] = 9.6\n",
    "    top2.loc[top2['le_place'] == '阪神', 'max_exp'] = 11.6\n",
    "    top2.loc[top2['le_place'] == '中京', 'min_exp'] = 7.5\n",
    "    top2.loc[top2['le_place'] == '中京', 'max_exp'] = 9.5\n",
    "    top2.loc[top2['le_place'] == '中山', 'min_exp'] = 8\n",
    "    top2.loc[top2['le_place'] == '中山', 'max_exp'] = 10\n",
    "    top2.loc[top2['le_place'] == '東京', 'min_exp'] = 8.2\n",
    "    top2.loc[top2['le_place'] == '東京', 'max_exp'] = 10.2\n",
    "    top2.loc[top2['le_place'] == '福島', 'min_exp'] = 7.6\n",
    "    top2.loc[top2['le_place'] == '福島', 'max_exp'] = 9.6\n",
    "    top2.loc[top2['le_place'] == '函館', 'min_exp'] = 12.6\n",
    "    top2.loc[top2['le_place'] == '函館', 'max_exp'] = 14.6\n",
    "\n",
    "    top2=top2[(top2['期待値']>top2['min_exp']-range_exp) & (top2['期待値']<top2['max_exp']+range_exp)]\n",
    "    top2['minオッズ']=round(top2['min_exp']/top2['score_top4'],2)\n",
    "    top2['maxオッズ']=round(top2['max_exp']/top2['score_top4'],2)\n",
    "    top2['max_bet'] = round(1/top2['minオッズ']*return_money,-2)\n",
    "    top2['min_bet'] = round(1/top2['maxオッズ']*return_money,-2)\n",
    "    top2['期待値'] = round(top2['期待値'],1)\n",
    "    top2.drop(columns=['min_exp','max_exp'],inplace=True)\n",
    "    return top2.sort_values(['le_place','R','馬番'], ascending=True)\n",
    "#5_5ハイブリットモデル\n",
    "def hybrid_model(first_result,return_pred,top_pred,range_exp):\n",
    "    df = first_result[~first_result['race_id'].isin(return_pred['race_id'])]\n",
    "    df2 = df[df['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "    df2 = df2.astype({'単勝オッズ': float})\n",
    "    df3 = df2[df2['単勝オッズ']>20].value_counts('race_id')==1\n",
    "    target_race_id = df3[df3].index\n",
    "    target = first_result[first_result['race_id'].isin(target_race_id)]\n",
    "    target = target[target['score_rank'] <= 2]\n",
    "    target = target.astype({'単勝オッズ': float})\n",
    "    target['期待値'] = target['単勝オッズ']*target['score_top4']\n",
    "    kekka = target[(target['期待値']>8-range_exp)&(target['期待値']<10+range_exp)].copy()\n",
    "    kekka['minオッズ']=round(8/kekka['score_top4'],2)\n",
    "    kekka['maxオッズ']=round(10/kekka['score_top4'],2)\n",
    "    kekka = kekka[kekka['score_top4']>=1.2]\n",
    "    # kekka.drop(columns=['min_bet','max_bet','期待値'],inplace=True)\n",
    "    return kekka.sort_values(['le_place','R','馬番'], ascending=True)\n",
    "#5_6指数モデル\n",
    "def index_model(index_df):\n",
    "    def make3(first_result):\n",
    "        top3 = first_result[first_result['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "        top3 = top3[~(top3['単勝オッズ'].str.contains('-', na=False))]\n",
    "        top3 = top3.astype({'単勝オッズ': float})\n",
    "        top3['期待値'] = top3['score_return']*top3['単勝オッズ']\n",
    "        top3 = top3.sort_values('期待値', ascending=True)\n",
    "        # ['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "        dropcol = ['複勝オッズ_min','複勝オッズ_max']\n",
    "        top3.drop(columns=dropcol,inplace=True)\n",
    "        return top3\n",
    "    def make2(first_result):\n",
    "        top2 = first_result[first_result['score_rank'] <= 2].sort_values(by = ['race_id','score_top4'], ascending=False)\n",
    "        top2 = top2[~(top2['単勝オッズ'].str.contains('-', na=False))]\n",
    "        top2 = top2.astype({'単勝オッズ': float})\n",
    "        top2['期待値'] = (top2['score_top4'])*top2['単勝オッズ']\n",
    "        top2 = top2.sort_values('期待値', ascending=True)\n",
    "        dropcol = ['複勝オッズ_min','複勝オッズ_max']\n",
    "        top2.drop(columns=dropcol,inplace=True)\n",
    "        return top2\n",
    "    sumdf = pd.DataFrame()\n",
    "    top3 = make3(index_df)\n",
    "    group_re = top3.groupby('race_id').sum()\n",
    "    mergedf_re = top3.merge(group_re[['単勝オッズ','score_top4','score_return','score_rank','期待値']],on='race_id',how = 'left')\n",
    "    top2 = make2(index_df)\n",
    "    group_top = top2.groupby('race_id').sum()\n",
    "    mergedf = top2.merge(group_top[['単勝オッズ','score_top4','score_return','score_rank','期待値']],on='race_id',how = 'left')\n",
    "    sumdf = group_re.merge(group_top,how='outer',right_index=True,left_index=True,suffixes=['_re','_top'])\n",
    "    race_id = sumdf[(sumdf['score_return_re']>sumdf['score_top4_top'])].index\n",
    "    hits = top3[top3['race_id'].isin(race_id)].sort_values(['race_id','le_place','R','score_return']).copy()\n",
    "    target = hits[hits['単勝オッズ']<=20].copy()\n",
    "    target = target[target['score_return'].isin(target.groupby('race_id')['score_return'].max())]\n",
    "    target = target[(target['score_rank']>=8)&(target['score_rank']<=10)]\n",
    "    return target.sort_values(['le_place','R','馬番'], ascending=True)\n",
    "#5_7ハイブリットモデル2(not_use_odds)\n",
    "def hybrid2_model(first_result):\n",
    "    def make_return(df,rank):\n",
    "        rank_df = first_result[first_result['return_rank'] == rank].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "        rank_df = rank_df[~(rank_df['単勝オッズ'].str.contains('-', na=False))]\n",
    "        rank_df = rank_df.astype({'単勝オッズ': float})\n",
    "        # rank_df['期待値'] = rank_df['score_return']*rank_df['単勝オッズ']\n",
    "        # rank_df = rank_df.sort_values('期待値', ascending=True)\n",
    "        # ['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "        dropcol = ['複勝オッズ_min','複勝オッズ_max']\n",
    "        rank_df.drop(columns=dropcol,inplace=True)\n",
    "        return rank_df\n",
    "    return_top4 = pd.DataFrame()\n",
    "    return6 = make_return(first_result,6)\n",
    "    return7 = make_return(first_result,7)\n",
    "    return8 = make_return(first_result,8)\n",
    "    return9 = make_return(first_result,20)\n",
    "    return6 = return6[return6['score_top4']>1.6]\n",
    "    return7 = return7[return7['score_top4']>1.4]\n",
    "    return8 = return8[return8['score_top4']>1.7]\n",
    "    return9 = return9[return9['score_top4']>1.6]\n",
    "    return_top4=pd.concat([return_top4,return6])\n",
    "    return_top4=pd.concat([return_top4,return7])\n",
    "    return_top4=pd.concat([return_top4,return8])\n",
    "    return_top4=pd.concat([return_top4,return9])\n",
    "    return return_top4\n",
    "\n",
    "#6_スケジューラーの終了処理\n",
    "def end():\n",
    "    print(\"テスト終わり\")\n",
    "    global isWorking\n",
    "    isWorking = False\n",
    "#7_すべての最新オッズを取得する\n",
    "def get_all_race_odds(driver,date):\n",
    "    \n",
    "    new_path = 'pickle/test/{0}/'.format(date)\n",
    "    if not os.path.exists(new_path):#ディレクトリがなかったら\n",
    "        os.mkdir(new_path)#作成したいフォルダ名を作成\n",
    "    else:\n",
    "        print('既に \"'+new_path+'\" は存在します。')\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, 'ico_regular').click()#通常投票\n",
    "    time.sleep(2)\n",
    "\n",
    "    #開催選択画面\n",
    "    places = []\n",
    "    place_element = driver.find_elements(By.CLASS_NAME,'ui-link')\n",
    "    for place_obj in place_element:\n",
    "        if place_obj != place_element[0] and place_obj != place_element[-1]:\n",
    "            print(place_obj.text)\n",
    "            places.append(place_obj.text)\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.find_element(By.PARTIAL_LINK_TEXT,places[-1]).click()#競馬場\n",
    "            # driver.find_element(By.PARTIAL_LINK_TEXT,place_obj.text).click()#競馬場\n",
    "            time.sleep(2)\n",
    "\n",
    "            #開催回がない場合の処理\n",
    "            try:\n",
    "                Alert(driver).accept()\n",
    "                continue\n",
    "            except NoAlertPresentException:\n",
    "                pass\n",
    "\n",
    "            # レース選択画面\n",
    "            race_nums = []\n",
    "            race_element = driver.find_elements(By.CLASS_NAME,'raceNum')\n",
    "            for racenum_obj in race_element:\n",
    "                print(racenum_obj.text)\n",
    "                race_nums.append(racenum_obj.text)\n",
    "\n",
    "                time.sleep(2)\n",
    "                driver.find_element(By.PARTIAL_LINK_TEXT,race_nums[-1]).click()#何Rか\n",
    "                # driver.find_element(By.PARTIAL_LINK_TEXT,racenum_obj.text).click()#何Rか\n",
    "                time.sleep(2)\n",
    "                driver.find_element(By.PARTIAL_LINK_TEXT,'単勝').click()\n",
    "                time.sleep(2)\n",
    "                b=driver.find_element(By.CLASS_NAME,'selectHorse').find_elements(By.CLASS_NAME,'ui-link')\n",
    "                time.sleep(2)\n",
    "\n",
    "                odds_df = pd.DataFrame()\n",
    "                horseNumber=[]#馬番\n",
    "                horseName=[]#馬名\n",
    "                odds=[]#オッズ\n",
    "                torikeshi=False#出走取り消しが存在するか\n",
    "\n",
    "                for n in range(len(b)):\n",
    "                    x=b[n].text.split('\\n')\n",
    "                    horseNumber.append(x[0])\n",
    "                    horseName.append(x[1])\n",
    "                    if x[2]!='取消':\n",
    "                        odds.append(x[2])\n",
    "                    else:\n",
    "                        odds.append('-')\n",
    "                        torikeshi=True\n",
    "\n",
    "                odds_df = pd.DataFrame([horseNumber,horseName,odds],index=[\"馬番\", \"馬名\", \"単勝オッズ\"] ).T\n",
    "                odds_df.to_pickle('pickle/test/{0}/latest_odds_{1}_{2}.pickle'.format(date,places[-1],race_nums[-1]))\n",
    "\n",
    "                driver.find_element(By.PARTIAL_LINK_TEXT,'式別').click()\n",
    "                time.sleep(2)\n",
    "                driver.find_element(By.PARTIAL_LINK_TEXT,'レース').click()\n",
    "                time.sleep(2)\n",
    "\n",
    "            driver.find_element(By.PARTIAL_LINK_TEXT,'競馬場名').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "    driver.find_element(By.LINK_TEXT,'トップメニュー').click()#通常投票画面に返る\n",
    "    print('完了しました。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7a5ad-00ff-4b91-ac7b-463e476d3b49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## resultの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89d550-0cda-4f39-b2e7-cf50ba90ab33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rdataの作成19-22最新まで(常に直前まで更新が望ましい)\n",
    "SPI算出にr.data_pを使用\n",
    "カテゴリデータ作成にr.data_peを使用\n",
    "\"\"\"\n",
    "r = Results.read_pickle(['pickle/results/results_2021.pickle'])\n",
    "r.data_p = pd.read_pickle('pickle/r_data19_21/r_data_p.pickle')\n",
    "r.data_pe = pd.read_pickle('pickle/r_data19_21/r_data_pe.pickle')\n",
    "r22_data_p= pd.read_pickle('pickle/r_data19_21/r_data_p22.pickle')\n",
    "r22_data_pe  = pd.read_pickle('pickle/r_data19_21/r_data_pe22.pickle')\n",
    "r.data_p= pd.concat([r.data_p,r22_data_p])\n",
    "r.data_pe= pd.concat([r.data_pe,r22_data_pe])\n",
    "del r22_data_p\n",
    "del r22_data_pe\n",
    "hr = HorseResults.read_pickle(['pickle/syutuba/latest/horse_results_latest.pickle'])\n",
    "hr.preprocessing()\n",
    "hr_p_backup = hr.horse_results_p.copy() #毎回作成する必要がないようにbuckupとして保持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e94bae-2ebf-4553-841a-e89fbb5321cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 開始前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653fe90-2d68-4dac-9860-7f6cf7e589c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_idの作成(自動取得検討)\n",
    "date = '2022年12月4日'\n",
    "racenum = 12\n",
    "race_id_list1 = ['2022060502'+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = ['2022090602'+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list3 = ['2022070602'+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "all_race_id = race_id_list1 + race_id_list2 + race_id_list3\n",
    "# all_race_id = race_id_list1 + race_id_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ece351-57bc-4adc-80f8-86f15ac7bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "making_dir(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c4866-016f-4746-8036-da2ba1ddac8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "race_schedule = get_racetime(date)\n",
    "day_schedule = create_day_schedule(all_race_id,race_schedule,3)\n",
    "day_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c9c43-f1ea-425b-ada7-43930e724db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_time = day_schedule['get_race_time'].unique()\n",
    "get_odds_time = day_schedule['get_odds_time'].unique()\n",
    "print(scrape_time)\n",
    "print(get_odds_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8abd99b-cdbd-4e88-9451-3c549b83333a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 実行メイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddc907-74a4-40b0-8870-1af5bf040686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule.clear()\n",
    "endTime = \"16:30\"\n",
    "isWorking = True\n",
    "#レース情報のスクレイピング\n",
    "for n in range(len(scrape_time)):\n",
    "    try:\n",
    "        race_id_list = day_schedule[day_schedule.index==n]['race_id']\n",
    "        date_list = [date]*len(race_id_list)\n",
    "        race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "        schedule.every().day.at(scrape_time[n]).do(create_race_pred,race_id_day_dict,date,hr_p_backup,r)\n",
    "    except  Exception as e:\n",
    "        print(e)\n",
    "        ws.PlaySound( 'SystemExclamation', ws.SND_ALIAS )\n",
    "#最新オッズの取得と購入\n",
    "for i in range(len(get_odds_time)):\n",
    "    try:\n",
    "        race_id = day_schedule[day_schedule['get_odds_time']==get_odds_time[i]]['race_id'].values[0]\n",
    "        kaisai = day_schedule[day_schedule['get_odds_time']==get_odds_time[i]]['place'].values[0]\n",
    "        R = day_schedule[day_schedule['get_odds_time']==get_odds_time[i]]['R'].values[0]\n",
    "        schedule.every().day.at(get_odds_time[i]).do(Forecast_calculation,race_id,kaisai,R,date)\n",
    "    except  Exception as e:\n",
    "        print(e)\n",
    "        ws.PlaySound( 'SystemExclamation', ws.SND_ALIAS )\n",
    "schedule.every().day.at(endTime).do(end)\n",
    "while isWorking:\n",
    "    time.sleep(3)\n",
    "    schedule.run_pending()\n",
    "    time.sleep(10)#何秒ごとに処理を実行するかを入力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06732e4f-b390-4f33-8d96-a0b2dfd777c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 当日運用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1de48e-c775-4d70-a65a-76801f8d31ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 保存先ディレクトリの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83ec0-c5e4-4fb1-bb7e-f06d0da6e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = '2022年10月29日'\n",
    "# race_num1 = '2022050408'\n",
    "# race_num2 = '2022090408'\n",
    "# race_num3 = '2022040405'\n",
    "# os.makedirs('pickle/syutuba/race/'+date)\n",
    "# os.makedirs('pickle/syutuba/race/'+date+'/std')\n",
    "# os.makedirs('pickle/syutuba/race/'+date+'/first_result')\n",
    "# os.makedirs('pickle/syutuba/生予測値/stdata_c/'+date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b39fbc-7299-49e6-9f81-7541db92e92a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## レースIDの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374dfff-c6af-4425-9cd9-a122a2cb6ae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 複数レースの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d9359-2410-41a9-88e8-3802fd366584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#開催場所に合わせて設定\n",
    "racenum = 12\n",
    "race_id_list1 = [race_num1+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = [race_num2+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list3 = [race_num3+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list = race_id_list1 + race_id_list2 + race_id_list3\n",
    "# race_id_list =  race_id_list1 + race_id_list2\n",
    "\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab8df5-8b07-470c-b2fd-b9751e3b6ec4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 中間レースから複数レースを対象とする場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cad5f6-cf22-4454-b9ae-e76e47729e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "race_id_day_dict=[]\n",
    "race_id_list=[]\n",
    "start = 8\n",
    "end = 12\n",
    "for i in range(start,end+1,1):\n",
    "    print(i)\n",
    "    race_id_list.append(race_num1+str(i).zfill(2))\n",
    "    race_id_list.append(race_num2+str(i).zfill(2))\n",
    "    race_id_list.append(race_num3+str(i).zfill(2))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe9c16-aeb6-40bd-9295-12884daab7af",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1レースの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17f1b3-6cf5-4954-bff3-6d1951785290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#日付とレースIDと何レース目か\n",
    "# date = '2022年10月23日'\n",
    "race_num1 = '2022060501'\n",
    "race_num2 = '2022090601'\n",
    "race_num3 = '2022070601'\n",
    "num = '10'\n",
    "# race_id_list = [race_num1+num,race_num2+num,race_num3+num]\n",
    "race_id_list = [race_num1+num,race_num2+num]\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709dd73-fa7f-4dd1-b58c-cc0f9ca787dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## レーススクレイピングと予想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd62c56-c148-43e5-a3c7-efd7fd783871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "first_result = create_race_pred(race_id_day_dict,date,hr_p_backup,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f510a8-0c59-4c83-aece-5ecfc4605fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d764640-e84f-4721-be18-8ae35ac6b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_pred = return_model(first_result, 0, 90000)\n",
    "return_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa42055-3af5-4467-ba51-71be81d86618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_pred = top_model(first_result, 0, 90000)\n",
    "top_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afa568-a978-4fe5-a91d-9150fa5f6331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybrid_model(first_result,return_pred,top_pred,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce763b7-9d50-4baa-beb9-1a8f3bbaab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_model(first_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94aa7d-ecd0-4626-b2bd-e258e0733a86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 予想表のオッズを直近オッズに入れ替える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07613baa-dca9-438b-a738-560c92418166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_result=pd.DataFrame()\n",
    "path_list=[]\n",
    "#指定したレースのみの場合\n",
    "# for num in race_id_day_dict.keys():\n",
    "#     path_list.append('pickle/syutuba/race/'+date+'/first_result/first_result_{}.pickle'.format(num))\n",
    "#全体の場合\n",
    "files = glob.glob('pickle/syutuba/race/'+date+'/first_result/*.pickle')\n",
    "for file in files:\n",
    "    path_list.append(file)    \n",
    "first_result = pd.read_pickle(path_list[0])\n",
    "for path in path_list[1:]:\n",
    "    first_result = pd.concat([first_result, pd.read_pickle(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cb6b4-95bb-4a11-87f6-896c563ed5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list=[]\n",
    "files = glob.glob('pickle/syutuba/race/'+date+'/latest_odds/*.pickle')\n",
    "for file in files:\n",
    "    path_list.append(file)\n",
    "latest_odds = pd.read_pickle(path_list[0])\n",
    "for path in path_list[1:]:\n",
    "    latest_odds = pd.concat([latest_odds, pd.read_pickle(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bea838-3613-4945-b3d8-ab3293fa193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_odds[latest_odds['馬名']=='オーソレミオ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fd61b-f5e6-49fd-8dfd-4a278e311699",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result.rename(columns = {'馬名_x':'馬名'},inplace=True)\n",
    "first_result['馬番'] = first_result['馬番'].astype(str)\n",
    "first_result = first_result.merge(latest_odds,how='left',on=['馬番','馬名'])#マージする場合\n",
    "first_result.drop(columns='単勝オッズ_x',inplace=True)\n",
    "first_result.rename(columns = {'単勝オッズ_y':'単勝オッズ'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e72ee-9da7-4042-aea0-695c84c04a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12R終了後全レースを一括でスクレイプして予測値を保存する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4eb7ba-8c06-4be0-b592-cae70b7a6542",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654100b2-0694-4d92-8b58-95a8b97917b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(date)\n",
    "os.makedirs('pickle/syutuba/race/'+date+'/total')\n",
    "os.makedirs('pickle/syutuba/race/'+date+'/total/first_result')\n",
    "os.makedirs('pickle/syutuba/生予測値/Label_Encoder/'+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8c711-4375-4bc1-b344-c847cbabfee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rdataの作成19-22最新まで(常に直前まで更新が望ましい)\n",
    "SPI算出にr.data_pを使用\n",
    "カテゴリデータ作成にr.data_peを使用\n",
    "\"\"\"\n",
    "r = Results.read_pickle(['pickle/results/results_2021.pickle'])\n",
    "r.data_p = pd.read_pickle('pickle/r_data19_21/r_data_p.pickle')\n",
    "r.data_pe = pd.read_pickle('pickle/r_data19_21/r_data_pe.pickle')\n",
    "r22_data_p= pd.read_pickle('pickle/r_data19_21/r_data_p22.pickle')\n",
    "r22_data_pe  = pd.read_pickle('pickle/r_data19_21/r_data_pe22.pickle')\n",
    "r.data_p= pd.concat([r.data_p,r22_data_p])\n",
    "r.data_pe= pd.concat([r.data_pe,r22_data_pe])\n",
    "del r22_data_p\n",
    "del r22_data_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691c3c7-e13e-435d-80ae-7400670cc646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#開催場所に合わせて設定\n",
    "racenum = 12\n",
    "race_num1 = '2022060502'\n",
    "race_num2 = '2022090602'\n",
    "race_num3 = '2022070602'\n",
    "race_id_list1 = [race_num1+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = [race_num2+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list3 = [race_num3+'{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list = race_id_list1 + race_id_list2 + race_id_list3\n",
    "# race_id_list =  race_id_list1 + race_id_list2\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e95c5a-0496-49e6-815f-404d70e1bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#学習モデル更新済み\n",
    "def day_after_create_race_pred(race_id_day_dict,date,hr_p_backup,r,already=False):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    #初めての時はスクレイピングを実行\n",
    "    if already==False:\n",
    "        st = ShutubaTable.scrape(race_id_day_dict)\n",
    "        for rid,date in race_id_day_dict.items():\n",
    "            st.data[st.data.index==rid].to_pickle('pickle/syutuba/race/{0}/total/syutuba_{1}.pickle'.format(date,rid))\n",
    "    else:\n",
    "        path_list=[]\n",
    "        files = glob.glob('pickle/syutuba/race/'+date+'/total/*.pickle')\n",
    "        # files = glob.glob('pickle/syutuba/race/'+date+'/*.pickle')#検証のために実施path\n",
    "        for file in files:\n",
    "            path_list.append(file)\n",
    "        path_list\n",
    "        st = ShutubaTable.read_pickle(path_list)\n",
    "        \n",
    "    #不足データがある場合、スクレイピングされ常に更新されていく\n",
    "    hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "    st.merge_horse_info(hi)\n",
    "    jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "    st.merge_jockey_info(jr,5)\n",
    "    st.preprocessing()\n",
    "    hr.horse_results_p = hr_p_backup.copy()\n",
    "    past_race_num=10\n",
    "    st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "    st.concat_past_data(hr,past_race_num)\n",
    "    p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "    p.encode(st)\n",
    "    st.merge_peds(p.peds_e)\n",
    "\n",
    "    def Read_Label_Encorder(r):\n",
    "        with open('pickle/LabelEncoder/le_horse.pickle', 'rb') as f:\n",
    "            r.le_horse = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_jockey.pickle', 'rb') as f:\n",
    "            r.le_jockey = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_class.pickle', 'rb') as f:\n",
    "            r.le_class = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_place.pickle', 'rb') as f:\n",
    "            r.le_place = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_trainer.pickle', 'rb') as f:\n",
    "            r.le_trainer = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_horseowner.pickle', 'rb') as f:\n",
    "            r.le_horseowner = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_producer.pickle', 'rb') as f:\n",
    "            r.le_producer = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_relative1.pickle', 'rb') as f:\n",
    "            r.le_relative1 = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_relative2.pickle', 'rb') as f:\n",
    "            r.le_relative2 = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_kai.pickle', 'rb') as f:\n",
    "            r.le_kai = pickle.load(f)\n",
    "        with open('pickle/LabelEncoder/le_day.pickle', 'rb') as f:\n",
    "            r.le_day = pickle.load(f)\n",
    "    Read_Label_Encorder(r)\n",
    "\n",
    "    st.process_categorical\\\n",
    "    (r.le_horse, r.le_jockey, r.le_class, r.le_place, r.data_pe, r.le_trainer, r.le_horseowner,\\\n",
    "     r.le_producer, r.le_relative1, r.le_relative2, r.le_kai, r.le_day, past_race_num)\n",
    "\n",
    "    latest_colcategory = pd.read_pickle('pickle/st_data/st_data_c_latest_categories.pickle')\n",
    "    # latest_colcategory = pd.read_pickle('pickle/st_data/category_std/st_data20220903.pickle')\n",
    "\n",
    "    for index ,name in latest_colcategory.head(0).dtypes.iteritems():\n",
    "        if name=='category':\n",
    "            # print(index)\n",
    "            new = list(st.data_c[index].cat.categories)\n",
    "            moto = list(latest_colcategory[index].cat.categories)\n",
    "            number = 0\n",
    "            befor = 0\n",
    "            changeFLG=False\n",
    "            A,B,C,D=[],[],[],[]\n",
    "            D = list(set(new)-set(moto))#完全に新しく出てきたもの\n",
    "            # if len(D)>0:\n",
    "            #     print('new_label_encode',index,D)\n",
    "            for i in moto:\n",
    "                if befor <= i:\n",
    "                    befor = i\n",
    "                    number+=1\n",
    "                else:\n",
    "                    changeFLG = True\n",
    "                    A = moto[:number]#前半 直前まで出たもの\n",
    "                    B = moto[number:]#後半 2021まで出ていたもの\n",
    "                    C = list(set(B)&set(new))#今回新たに出ているが過去にも出たことのあるもの\n",
    "                    # for s in C:\n",
    "                    #     B.remove(s)\n",
    "                    # B = [s for s in B if s not in C]\n",
    "                    list(map(lambda x: B.remove(x), C))\n",
    "            if changeFLG==False:\n",
    "                A = moto[:number]#前半 直前まで出たもの\n",
    "                B = moto[number:]#後半 2021まで出ていたもの\n",
    "                C = list(set(B)&set(new))#今回新たに出ているが過去にも出たことのあるもの\n",
    "                list(map(lambda x: B.remove(x), C))\n",
    "    \n",
    "            setlist = (sorted(A+C)+sorted(D)+(B))\n",
    "            # time_protcol()\n",
    "\n",
    "            if len(setlist)==0:#何も更新がなかった場合\n",
    "                # print('更新なし',index)\n",
    "                st.data_c[index] =st.data_c[index].cat.set_categories((moto))\n",
    "            else:\n",
    "                #前半部分に新しいリストを合わせて昇順にする\n",
    "                st.data_c[index] =st.data_c[index].cat.set_categories((setlist))\n",
    "\n",
    "    def std_data_proccesing(st):\n",
    "        #並び替えとindexのsetとタイトル削除\n",
    "        st.data_c=st.data_c.sort_values(['race_id','馬番'])\n",
    "        st.data_c.set_index('race_id',inplace = True)\n",
    "        st.data_c =st.data_c.rename_axis(index=None)\n",
    "\n",
    "        #特徴量を削除\n",
    "        # st.data_c.drop(columns =['time','final_to_rank_my_allR','jockey_id'],inplace = True)\n",
    "        st.data_c.drop(columns =['time'],inplace = True)\n",
    "\n",
    "        #レースIDごとに標準偏差に変更する\n",
    "        std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R', 'final_to_rank_8p', '体重_8p']\n",
    "        # std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R']\n",
    "        standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "        st.data_c[list(map(lambda x:  x+'_std', std_tar_col))] = st.data_c[std_tar_col].groupby(level=0).transform(standard_scaler)\n",
    "\n",
    "        #学習モデルの特徴量を合わせるために、保存したデータを読み込み\n",
    "        col_df = pd.read_pickle('pickle/syutuba/columns/r_columns.pickle')\n",
    "        print(set(col_df.columns.tolist())-set(st.data_c.columns.tolist()))\n",
    "        print(set(st.data_c.columns.tolist())-set(col_df.columns.tolist()))\n",
    "\n",
    "        #不足分をリスト化して追加する\n",
    "        col = set(col_df.columns)-set(st.data_c.columns)\n",
    "        st.data_c[list(col)]=0\n",
    "    std_data_proccesing(st)\n",
    "    \n",
    "    if already==False:\n",
    "        st.data_c.to_pickle('pickle/syutuba/生予測値/stdata_c/{}/stdata_c_std.pickle'.format(date))\n",
    "    # else:#検証のために実施\n",
    "    #     st.data_c.to_pickle('pickle/syutuba/生予測値/stdata_c/{}/stdata_c_std_実施値.pickle'.format(date))\n",
    "\n",
    "    def Created_predscore(st, r, returnModel, top4Model):\n",
    "        stX_test = st.data_c.drop(['着順', '人気','date','生年月日'], axis=1)\n",
    "        # stX_test = test.drop(['着順', '人気','date','生年月日'], axis=1)\n",
    "\n",
    "        #学習モデルの読み込み\n",
    "        lgb_clf_return = pickle.load(open('./pickle/syutuba/学習モデル/'+returnModel+'.pkl', 'rb'))\n",
    "        lgb_clf_top4 = pickle.load(open('./pickle/syutuba/学習モデル/'+top4Model+'.pkl', 'rb'))\n",
    "\n",
    "        #ModelEvaluatorクラスのオブジェクトを作成\n",
    "        #予想時にはreturn情報はないので、適当によみこむ\n",
    "        me_st_return = ModelEvaluator(lgb_clf_return, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "        me_st_top4 = ModelEvaluator(lgb_clf_top4, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "\n",
    "        #predの算出\n",
    "        scores = me_st_return.predict_proba(stX_test)\n",
    "        pred = stX_test[['馬番','horse_id','class','place','jockey_id']].copy()\n",
    "        #ラベルデコード\n",
    "        pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "        pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "        pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "        pred['le_jockey_id']=r.le_jockey.inverse_transform(pred['jockey_id'])\n",
    "        pred['score'] = scores\n",
    "        pred_return = pred.copy()\n",
    "        #predの算出\n",
    "        scores = me_st_top4.predict_proba(stX_test)\n",
    "        pred = stX_test[['馬番','horse_id','class','place','jockey_id']].copy()\n",
    "        #ラベルデコード\n",
    "        pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "        pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "        pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "        pred['le_jockey_id']=r.le_jockey.inverse_transform(pred['jockey_id'])\n",
    "        pred['score'] = scores\n",
    "        pred_top4 = pred.copy()\n",
    "\n",
    "        #mergeするためにindexをカラムにして、merge後元に戻す\n",
    "        st.data.reset_index(inplace=True)\n",
    "        st.data.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        pred_return.reset_index(inplace=True)\n",
    "        pred_return.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        pred_top4.reset_index(inplace=True)\n",
    "        pred_top4.rename(columns={'index': 'race_id'},inplace=True)\n",
    "\n",
    "        AI_return = pred_return.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "        AI_top4 = pred_top4.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "        AI_top4 = AI_top4.merge(st.data[['race_id','date']].drop_duplicates(),how='left',left_on=['race_id'],right_on=['race_id'])\n",
    "\n",
    "        st.data.set_index('race_id',inplace = True)\n",
    "        st.data.index.name = None\n",
    "        pred_return.set_index('race_id',inplace = True)\n",
    "        pred_return.index.name = None\n",
    "        pred_top4.set_index('race_id',inplace = True)\n",
    "        pred_top4.index.name = None\n",
    "\n",
    "        AI_return.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "        AI_return = AI_return.reindex(columns=['race_id','le_place','馬番','馬名','le_jockey_id','le_class','score'])\n",
    "\n",
    "        AI_top4.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "        AI_top4 = AI_top4.reindex(columns=['race_id','le_place','馬番','馬名','le_jockey_id','le_class','score'])\n",
    "\n",
    "        place_dict = {\n",
    "        '01':'札幌',  '02':'函館',  '03':'福島',  '04':'新潟',  '05':'東京', \n",
    "        '06':'中山',  '07':'中京',  '08':'京都',  '09':'阪神',  '10':'小倉'\n",
    "        }\n",
    "        AI_return = AI_return.replace(place_dict)\n",
    "        AI_top4 = AI_top4.replace(place_dict)\n",
    "\n",
    "        AI = AI_top4.merge(AI_return[['race_id','馬名','score']],how='left',left_on=['race_id','馬名'],right_on=['race_id','馬名'])\n",
    "        AI.rename(columns={'馬名_x':'馬名', 'score_x': 'score_top4', 'score_y': 'score_return'},inplace=True)\n",
    "        AI.insert(loc=3,column='R',value=AI['race_id'].str[-2:])\n",
    "        return AI\n",
    "    \n",
    "    # returnModel = '19-21学習モデル_750'\n",
    "    # top4Model = '19-21的中型上位4位モデル'\n",
    "    returnModel = '221101return_model'\n",
    "    top4Model = '221101top4_model'\n",
    "    AI = Created_predscore(st, r, returnModel, top4Model)\n",
    "    \n",
    "    def concate_odds(race_id_day_dict,current_time,AI):\n",
    "        if already==False:\n",
    "            st_odds = ST_odds.scrape(race_id_day_dict.keys())\n",
    "            st_odds.data.to_pickle('pickle/syutuba/race/odds/st_odds_{}.pickle'.format(current_time))\n",
    "            STR=ST_odds.read_pickle(['pickle/syutuba/race/odds/st_odds_latest.pickle','pickle/syutuba/race/odds/st_odds_{}.pickle'.format(current_time)])\n",
    "            STR.data.to_pickle('pickle/syutuba/race/odds/st_odds_latest.pickle')\n",
    "        else:\n",
    "            STR=ST_odds.read_pickle(['pickle/syutuba/race/odds/st_odds_latest.pickle'])\n",
    "        STR.data.reset_index(inplace=True)\n",
    "        STR.data.rename(columns={'index': 'race_id'},inplace=True)\n",
    "        add_odds = AI.merge(STR.data,how='left',left_on=['race_id','馬番'],right_on=['race_id','馬番'])\n",
    "        add_odds.drop(columns = '馬名_y' ,inplace = True)\n",
    "        rankdf = add_odds.copy()\n",
    "        rankdf['score_rank'] = add_odds.groupby(by = 'race_id')['score_top4'].rank(ascending=False)\n",
    "        rankdf['return_rank'] = add_odds.groupby(by = 'race_id')['score_return'].rank(ascending=False)\n",
    "        first_result = rankdf.sort_values(['le_place','R','馬番'], ascending=True).copy()\n",
    "        return first_result\n",
    "    first_result = concate_odds(race_id_day_dict, current_time, AI)\n",
    "    \n",
    "    #予測値の保存\n",
    "    if already==False:\n",
    "        for rid,date in race_id_day_dict.items():\n",
    "            first_result[first_result['race_id']==rid].to_pickle('pickle/syutuba/race/{0}/total/first_result/first_result_{1}.pickle'.format(date,rid))\n",
    "    return first_result\n",
    "# first_result = day_after_create_race_pred(race_id_day_dict, date, hr_p_backup, r ,False)\n",
    "# return_pred = return_model(first_result, 0, 90000)\n",
    "# top_pred = top_model(first_result, 0, 90000)\n",
    "# hybrid = hybrid_model(first_result,return_pred,top_pred,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec39f8a-8860-48c3-9e66-82a0aba2a5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_result = day_after_create_race_pred(race_id_day_dict, date, hr_p_backup, r ,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b286394-55c8-4cc7-a28c-aab6a06e3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルエンコーディングを保存\n",
    "def Save_Label_Encoder(r,date):\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_horse.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_horse , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_jockey.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_jockey , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_class.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_class , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_place.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_place , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_trainer.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_trainer , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_horseowner.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_horseowner , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_producer.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_producer , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_relative1.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_relative1 , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_relative2.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_relative2 , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_kai.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_kai , f)\n",
    "    with open('pickle/syutuba/生予測値/Label_Encoder/{}/le_day.pickle'.format(date), 'wb') as f:\n",
    "        pickle.dump(r.le_day , f)\n",
    "Save_Label_Encoder(r,date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb6068-9cd5-468e-9a01-4f44c684d97e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 予測値の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6a88e-3852-4af2-946d-a9d39fae212b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "return_pred = return_model(first_result, 0, 90000)\n",
    "return_pred.sort_values(by = ['le_place','R'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38bc97-736a-41eb-99ed-f725d967d250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_pred = top_model(first_result, 0, 0)\n",
    "top_pred.sort_values(by = ['le_place','R'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269aa8ad-6877-43b8-80b3-eab937013c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model(first_result,return_pred,top_pred,0)\n",
    "# hybrid.sort_values(by = ['le_place','R'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684db981-3373-4f6c-aab3-3ee754d3ba55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_model(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0d6e2-5e3e-444c-8aaa-3f3b963deba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybrid2_model(first_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04c27a-222e-4ea3-a486-6f007018c1b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 生データでの対象馬確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcff51-977b-4a19-aee9-5d7a83ceb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022年11月27日'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398afe4-a493-4653-94d3-6564dad3c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#毎レーススクレイピング時のpred\n",
    "raw_pred=pd.DataFrame()\n",
    "path_list=[]\n",
    "#指定したレースのみの場合\n",
    "# for num in race_id_day_dict.keys():\n",
    "#     path_list.append('pickle/syutuba/race/'+date+'/first_result/first_result_{}.pickle'.format(num))\n",
    "#全体の場合\n",
    "files = glob.glob('pickle/syutuba/race/'+date+'/first_result/*.pickle')\n",
    "for file in files:\n",
    "    path_list.append(file)    \n",
    "raw_pred = pd.read_pickle(path_list[0])\n",
    "for path in path_list[1:]:\n",
    "    raw_pred = pd.concat([raw_pred, pd.read_pickle(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008c294-5473-4d34-83dd-98adecd81fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#毎レースの直前オッズ\n",
    "latest_odds=pd.DataFrame()\n",
    "path_list=[]\n",
    "files = glob.glob('pickle/syutuba/race/'+date+'/latest_odds/*.pickle')\n",
    "for file in files:\n",
    "    path_list.append(file)    \n",
    "latest_odds = pd.read_pickle(path_list[0])\n",
    "for path in path_list[1:]:\n",
    "    latest_odds = pd.concat([latest_odds, pd.read_pickle(path)])\n",
    "latest_odds['馬番'] = latest_odds['馬番'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943db072-8007-4fb5-92a5-e04bfaf8b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw_pred.merge(latest_odds,how = 'left',left_on=['馬番','馬名_x'],right_on=['馬番','馬名'])\n",
    "raw = raw.drop(['馬名','単勝オッズ_x'],axis=1)\n",
    "raw = raw.rename(columns={\"単勝オッズ_y\": \"単勝オッズ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70b11d-fe2e-450b-a9a2-3dadccf3d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model(raw, 0, 90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3c82b-d4dd-4a8d-9c9e-3f9a82c4fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model(raw, 0, 90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ee96c-2d56-41ec-968b-d29e5eea75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model(raw,return_pred,top_pred,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f672d2-502a-4e9c-93e4-e69689647d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_model(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237047a-47f3-489e-8ead-869e541738e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid2_model(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb42f56-6d61-4270-af8f-6922d943d954",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 当日終了後、出馬表の結果からシミュレーションする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3896b-0bf7-4d07-aac8-4cfbc812d8c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 出馬表の再更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5995e3-c2cb-47f7-89c2-4642e13bfc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d35c5e-2e36-46bd-baec-7a43703c4956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "#その日に開催されるレースIDと日付けを指定する\n",
    "#日付は予測値に影響を与えるので注意(hrのマージの日付になる)\n",
    "#レース終了後日付に注意して再取得し、latestを更新する\n",
    "\"\"\"\n",
    "date = '2022年11月27日'\n",
    "#開催場所に合わせて設定\n",
    "racenum = 12\n",
    "race_id_list1 = ['2022050508{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = ['2022090508{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "# race_id_list3 = ['2022030306{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "# race_id_list = race_id_list1 + race_id_list2 + race_id_list3\n",
    "race_id_list = race_id_list1 + race_id_list2\n",
    "\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77747ae1-9ba6-4a66-a477-2b84c413dd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#スクレイピングして保存\n",
    "st = ShutubaTable.scrape(race_id_day_dict,False)\n",
    "st.data.to_pickle('pickle/syutuba/race/syutuba_{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3426bd-3e3a-4057-8007-87773c93224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latestを更新\n",
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle','pickle/syutuba/race/syutuba_{}.pickle'.format(date)])\n",
    "st.data.to_pickle('pickle/syutuba/race/syutuba_latest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea8d93-b587-477e-81a4-99cbd703d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f690a1-7913-4048-8e9c-70b7a6f33b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st.data['date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71240fe5-a2c8-422e-a6c5-1d3fab731129",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 結果表の再更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d567d12-9145-4779-bd15-b314cc3daa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])\n",
    "STR=ST_results.read_pickle(['pickle/syutuba/race/STR/STR_latest.pickle'])\n",
    "diff_race_id = set(st.data.index.unique())-set(STR.data['race_id'].unique())\n",
    "print(len(diff_race_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c58c54-be4a-4cff-a146-50685a6d9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#日付はSTRにないため関係ないが保存名になる\n",
    "# date = '2022年11月20日'\n",
    "print(date)\n",
    "#出馬表からのオッズの取得\n",
    "STR = ST_results.scrape(diff_race_id)\n",
    "#STRの保存\n",
    "STR.data.to_pickle('pickle/syutuba/race/STR/STR_{}.pickle'.format(date))\n",
    "STR=ST_results.read_pickle(['pickle/syutuba/race/STR/STR_latest.pickle','pickle/syutuba/race/STR/STR_{}.pickle'.format(date)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66bbc7-3dbb-4d02-9d2d-45a800814799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STRの更新\n",
    "STR.data.to_pickle('pickle/syutuba/race/STR/STR_latest.pickle')\n",
    "STR=ST_results.read_pickle(['pickle/syutuba/race/STR/STR_latest.pickle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a772406-df92-4053-aa5e-4d46c94618e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AIの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a6079-8255-43bf-8afd-a308186faaad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2021まででカテゴリデータを作成すること\n",
    "#22以降はstで1日ずつ作成する必要があるため\n",
    "r = Results.read_pickle(['pickle/results/results_2021.pickle'])\n",
    "r.data_p = pd.read_pickle('pickle/r_data19_21/r_data_p.pickle')\n",
    "r.data_pe = pd.read_pickle('pickle/r_data19_21/r_data_pe.pickle')\n",
    "past_race_num=10\n",
    "r.process_categorical(past_race_num)\n",
    "\n",
    "r22_data_p= pd.read_pickle('pickle/r_data19_21/r_data_p22.pickle')\n",
    "r22_data_pe  = pd.read_pickle('pickle/r_data19_21/r_data_pe22.pickle')\n",
    "r.data_p= pd.concat([r.data_p,r22_data_p])\n",
    "r.data_pe= pd.concat([r.data_pe,r22_data_pe])\n",
    "del r22_data_p\n",
    "del r22_data_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde4805-51a7-4146-9f2b-7981cf0f66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = HorseResults.read_pickle(['pickle/syutuba/latest/horse_results_latest.pickle'])\n",
    "hr.preprocessing()\n",
    "hr_p_backup = hr.horse_results_p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa5abd-043f-4f21-bc3d-b360be1dabee",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])#26/18hukumu\n",
    "#不足データがある場合、スクレイピングされ常に更新されていく\n",
    "hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "st.merge_horse_info(hi)\n",
    "jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "st.merge_jockey_info(jr,5)\n",
    "st.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ddcd-8c33-4bfd-8206-e1aa1d9f52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stのスクレイプで日にちを間違えた場合にrとの整合性が取れずデータが\n",
    "重複してしまっている可能性があるためチェックする\"\"\"\n",
    "for i in st.data[['date','horse_id','馬番']].value_counts().tolist():\n",
    "    if i != 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f0d4e-2f3a-4169-930e-4de6563e20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.data['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bea97-e57b-43b4-b9a6-cef6245d154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copydf = st.data_p.copy()\n",
    "backup = st.data_p.copy()\n",
    "hr_p_backup = hr.horse_results_p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a6143-6d40-47ca-99a3-925d0a99cbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#一日ごとにSPIを算出する\n",
    "#stのその日以前のrを使用してSPI算出している\n",
    "stdata_days = pd.DataFrame()\n",
    "daylist = copydf.sort_values('date',ascending = True)['date'].unique()\n",
    "for day in daylist:\n",
    "    st.data_p = copydf[copydf['date']==day]\n",
    "    st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "    hr.horse_results_p = hr_p_backup\n",
    "    st.data_h[st.data_h['date']==day].to_pickle('pickle/syutuba/SPI/st_data_h_{}.pickle'.format(day.astype('M8[D]')))\n",
    "    stdata_days = pd.concat([stdata_days,st.data_h[st.data_h['date']==day]])\n",
    "clear_output()\n",
    "print(len(st.data_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c402150-b57a-4e89-8b0b-7fd58334fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spidatas = pd.DataFrame()\n",
    "# daylist = copydf.sort_values('date',ascending = True)['date'].unique()\n",
    "# for day in daylist[:-1]:\n",
    "#     spidata = pd.read_pickle('pickle/syutuba/SPI/st_data_h_{}.pickle'.format(day.astype('M8[D]')))\n",
    "#     spidatas = pd.concat([spidatas,spidata])\n",
    "# #最新日のみ計算して結合\n",
    "# st.data_p = copydf[copydf['date']==daylist[-1]]\n",
    "# st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "# hr.horse_results_p = hr_p_backup\n",
    "# st.data_h[st.data_h['date']==daylist[-1]].to_pickle('pickle/syutuba/SPI/st_data_h_{}.pickle'.format(daylist[-1].astype('M8[D]')))\n",
    "# spidatas = pd.concat([spidatas,st.data_h[st.data_h['date']==daylist[-1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67556959-75ba-4984-a31b-ff94d36b0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#日ごとに作成した場合バックアップでhrがリセットされているため下記処理実行\n",
    "hr.horse_results_p = hr.horse_results_p.reset_index()\n",
    "jockey_df = r.data_p[['騎手','jockey_id']].drop_duplicates()\n",
    "hr.horse_results_p = hr.horse_results_p.merge(jockey_df, how='left', on = '騎手')\n",
    "hr.horse_results_p = hr.horse_results_p.set_index('horse_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974a7fc-71e7-4557-b224-94a9227da27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "past_race_num=10\n",
    "# st.merge_horse_results(hr, n_samples_list=[5,9,'all'] ,rt = r.data_p)\n",
    "st.data_h = stdata_days.copy()\n",
    "st.concat_past_data(hr,past_race_num)\n",
    "\n",
    "#5世代分の血統データの追加\n",
    "#pedsが存在しない場合は自動更新\n",
    "p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "p.encode(st)\n",
    "st.merge_peds(p.peds_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd9eef-fc97-47df-b8b8-28809920e1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#カテゴリデータ更新の時に行う\n",
    "#日ごとにカテゴライズしてラベルエンコーダーを作成する\n",
    "#古い日から一日ごとにエンコードしないとカテゴリに振られる採番が異なってしまう\n",
    "#ラベルエンコーディングとは、アルゴリズムに基づいて全データを順に並べ0から採番して識別すること\n",
    "# date = '2022年11月27日'#ここが必要か確認すること\n",
    "print(date)\n",
    "def create_dir(date,mainday=True):\n",
    "    if mainday==True:\n",
    "        path = 'pickle/LabelEncoder/backup/'+date\n",
    "    else:\n",
    "        path = 'pickle/LabelEncoder/backup/'+mainday+'/'+date\n",
    "    os.makedirs(path)\n",
    "mainday = date#更新日\n",
    "create_dir(mainday)\n",
    "def Backup_Label_Encoder(r,mainday,date):\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_horse.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_horse , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_jockey.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_jockey , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_class.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_class , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_place.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_place , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_trainer.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_trainer , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_horseowner.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_horseowner , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_producer.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_producer , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_relative1.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_relative1 , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_relative2.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_relative2 , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_kai.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_kai , f)\n",
    "    with open('pickle/LabelEncoder/backup/'+mainday+'/'+date+'/le_day.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_day , f)\n",
    "st_data_pe_bk = st.data_pe.copy()\n",
    "condf = pd.DataFrame()\n",
    "past_race_num=10\n",
    "print('le_horse',len(r.le_horse.classes_))\n",
    "for date in tqdm(st_data_pe_bk.sort_values('date',ascending = True)['date'].dt.strftime(\"%Y%m%d\").unique()):\n",
    "    st.data_pe=st_data_pe_bk[st_data_pe_bk['date']<=date]\n",
    "    # print(len(st.data_pe))\n",
    "    # print('le_horse',len(r.le_horse.classes_))\n",
    "    st.process_categorical\\\n",
    "    (r.le_horse,r.le_jockey,r.le_class,r.le_place,r.data_pe,r.le_trainer,r.le_horseowner,\\\n",
    "     r.le_producer,r.le_relative1,r.le_relative2,r.le_kai,r.le_day,past_race_num)\n",
    "    # print('st_le_horse',len(st.le_horse.classes_))\n",
    "    #concatする場合\n",
    "    # condf = pd.concat([condf,st.data_c[st.data_c['date']==date]])\n",
    "    #一日ごとに保存\n",
    "    st.data_c[st.data_c['date']==date].to_pickle('pickle/st_data/category/st_data{}.pickle'.format(date))\n",
    "    create_dir(date,mainday)\n",
    "    Backup_Label_Encoder(r,mainday,date)\n",
    "print('st_le_horse',len(st.le_horse.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc5dd9-9a18-4f00-8d1c-4acbe39783fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('le_horse',len(r.le_horse.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb32ed-b1ac-44d5-835a-99348121dd94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ラベルエンコーダーの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd009cd-9ead-4741-b125-4842b5331085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Label_Encoder(r):\n",
    "    with open('pickle/LabelEncoder/le_horse.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_horse , f)\n",
    "    with open('pickle/LabelEncoder/le_jockey.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_jockey , f)\n",
    "    with open('pickle/LabelEncoder/le_class.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_class , f)\n",
    "    with open('pickle/LabelEncoder/le_place.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_place , f)\n",
    "    with open('pickle/LabelEncoder/le_trainer.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_trainer , f)\n",
    "    with open('pickle/LabelEncoder/le_horseowner.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_horseowner , f)\n",
    "    with open('pickle/LabelEncoder/le_producer.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_producer , f)\n",
    "    with open('pickle/LabelEncoder/le_relative1.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_relative1 , f)\n",
    "    with open('pickle/LabelEncoder/le_relative2.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_relative2 , f)\n",
    "    with open('pickle/LabelEncoder/le_kai.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_kai , f)\n",
    "    with open('pickle/LabelEncoder/le_day.pickle', 'wb') as f:\n",
    "        pickle.dump(r.le_day , f)\n",
    "Save_Label_Encoder(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5c4d2-bfc9-459a-bdf0-a6bb0061687d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## for文によるカテゴリデータの作成とAIの作成\n",
    "　これで作るとカテゴリデータの順番が一定になりpredがぶれなくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70c943-4b5e-483a-9da5-a9d36fbba390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#上記stデータで2022年データのカテゴリデータを作成したので\n",
    "#それに2021年のカテゴリデータをくっつける作業\n",
    "from pandas.api.types import CategoricalDtype\n",
    "# std_df = st.data_c.copy()\n",
    "#21年までのカテゴリデータ情報\n",
    "col_data = pd.read_pickle('pickle/st_data/st_data_c_19-21_categories.pickle')\n",
    "#学習モデルの特徴量(カラム数)を合わせるために、保存したデータを読み込み\n",
    "col_df = pd.read_pickle('pickle/syutuba/columns/r_columns.pickle')\n",
    "\n",
    "for date in tqdm(st_data_pe_bk.sort_values('date',ascending = True)['date'].dt.strftime(\"%Y%m%d\").unique()):\n",
    "    std_df = pd.read_pickle('pickle/st_data/category/st_data{}.pickle'.format(date))\n",
    "    #並び替えとindexのsetとタイトル削除\n",
    "    std_df=std_df.sort_values(['race_id','馬番'])\n",
    "    std_df.set_index('race_id',inplace = True)\n",
    "    std_df =std_df.rename_axis(index=None)\n",
    "\n",
    "    #特徴量を削除\n",
    "    # st0618.drop(columns =['time','final_to_rank_my_allR','jockey_id'],inplace = True)\n",
    "    std_df.drop(columns =['time'],inplace = True)\n",
    "\n",
    "    #レースIDごとに標準偏差に変更する\n",
    "    std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R', 'final_to_rank_8p', '体重_8p']\n",
    "    # std_tar_col =['枠番', 'first_to_final_course_len_5R', 'first_corner_race_type_9R']\n",
    "    standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "    std_df[list(map(lambda x:  x+'_std', std_tar_col))] = std_df[std_tar_col].groupby(level=0).transform(standard_scaler)\n",
    "\n",
    "    #不足分をリスト化して追加する\n",
    "    col = set(col_df.columns)-set(std_df.columns)\n",
    "    std_df[list(col)]=0\n",
    "    \n",
    "    #21年のカテゴリデータを追加して統一する\n",
    "    for index ,name in col_data.head(0).dtypes.iteritems():\n",
    "        if name=='category':\n",
    "            diff_category = list(set(col_data[index].cat.categories)-set(std_df[index].cat.categories))\n",
    "            std_df[index] = std_df[index].cat.add_categories(diff_category)\n",
    "            #ソートしてカテゴリを作成する場合\n",
    "            # std_df[index] = std_df[index].cat.set_categories(sorted(list(std_df[index].cat.categories)))\n",
    "    \n",
    "    std_df.to_pickle('pickle/st_data/category_std/st_data{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1f347-3c84-4ab1-91d5-a2ff0540df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#最新日のカテゴリデータ順で当日カテゴリデータの順を合わせるため保存\n",
    "print(date)\n",
    "no = pd.read_pickle('pickle/st_data/category_std/st_data{}.pickle'.format(date))\n",
    "no.head(0).to_pickle('pickle/st_data/st_data_c_latest_categories.pickle')\n",
    "no.head(0)['horse_id'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5b674-336a-4156-b31e-7148415f57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習モデルの読み込み\n",
    "lgb_clf_return = pickle.load(open('./pickle/syutuba/学習モデル/19-21学習モデル_750.pkl', 'rb'))\n",
    "lgb_clf_top4 = pickle.load(open('./pickle/syutuba/学習モデル/19-21的中型上位4位モデル.pkl', 'rb'))\n",
    "me_st_return = ModelEvaluator(lgb_clf_return, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "me_st_top4 = ModelEvaluator(lgb_clf_top4, ['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "\n",
    "for date in tqdm(st_data_pe_bk.sort_values('date',ascending = True)['date'].dt.strftime(\"%Y%m%d\").unique()):\n",
    "    std_df = pd.read_pickle('pickle/st_data/category_std/st_data{}.pickle'.format(date))\n",
    "    #テストデータの作成と保存\n",
    "    stX_test = std_df.drop(['着順', '人気','date','生年月日'], axis=1)\n",
    "    scores = me_st_return.predict_proba(stX_test)\n",
    "    pred = stX_test[['馬番','horse_id','class','place']].copy()\n",
    "    #ラベルデコード\n",
    "    pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "    pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "    pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "    pred['score'] = scores\n",
    "    pred_return = pred.copy()\n",
    "    #predの算出\n",
    "    scores = me_st_top4.predict_proba(stX_test)\n",
    "    pred = stX_test[['馬番','horse_id','class','place']].copy()\n",
    "    #ラベルデコード\n",
    "    pred['le_horse_id']=r.le_horse.inverse_transform(pred['horse_id'])\n",
    "    pred['le_class']=r.le_class.inverse_transform(pred['class'])\n",
    "    pred['le_place']=r.le_place.inverse_transform(pred['place'])\n",
    "    pred['score'] = scores\n",
    "    pred_top4 = pred.copy()\n",
    "    #mergeするためにindexをカラムにして、merge後元に戻す\n",
    "    st.data.reset_index(inplace=True)\n",
    "    st.data.rename(columns={'index': 'race_id'},inplace=True)\n",
    "    pred_return.reset_index(inplace=True)\n",
    "    pred_return.rename(columns={'index': 'race_id'},inplace=True)\n",
    "    pred_top4.reset_index(inplace=True)\n",
    "    pred_top4.rename(columns={'index': 'race_id'},inplace=True)\n",
    "    AI_return = pred_return.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "    AI_top4 = pred_top4.merge(st.data[['horse_id','馬名']].drop_duplicates(),how='left',left_on=['le_horse_id'],right_on=['horse_id'])\n",
    "    # AI_top4 = AI_top4.merge(st.data[['race_id','date']].drop_duplicates(),how='left',left_on=['race_id'],right_on=['race_id'])\n",
    "    AI_top4 = AI_top4.merge(st.data[['race_id','date','course_len','race_type','race_round','weather','ground_state']].drop_duplicates(),how='left',left_on=['race_id'],right_on=['race_id'])\n",
    "\n",
    "    st.data.set_index('race_id',inplace = True)\n",
    "    st.data.index.name = None\n",
    "    pred_return.set_index('race_id',inplace = True)\n",
    "    pred_return.index.name = None\n",
    "    pred_top4.set_index('race_id',inplace = True)\n",
    "    pred_top4.index.name = None\n",
    "\n",
    "    AI_return.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "    AI_return = AI_return.reindex(columns=['race_id','le_place','馬番','馬名','le_class','score'])\n",
    "    AI_top4.drop(columns=['horse_id_x','class','le_horse_id','horse_id_y'],inplace=True)\n",
    "    # AI_top4 = AI_top4.reindex(columns=['race_id','date','le_place','馬番','馬名','le_class','score'])\n",
    "    AI_top4 = AI_top4.reindex(columns=['race_id','date','le_place','馬番','馬名','le_class','score','course_len','race_type','race_round','weather','ground_state'])\n",
    "\n",
    "    place_dict = {\n",
    "    '01':'札幌',  '02':'函館',  '03':'福島',  '04':'新潟',  '05':'東京', \n",
    "    '06':'中山',  '07':'中京',  '08':'京都',  '09':'阪神',  '10':'小倉'\n",
    "    }\n",
    "    AI_return = AI_return.replace(place_dict)\n",
    "    AI_top4 = AI_top4.replace(place_dict)\n",
    "    AI = AI_top4.merge(AI_return[['race_id','馬名','score']],how='left',left_on=['race_id','馬名'],right_on=['race_id','馬名'])\n",
    "    AI.rename(columns={'score_x': 'score_top4','score_y': 'score_return',},inplace=True)\n",
    "    AI.insert(loc=3,column='R',value=AI['race_id'].str[-2:])\n",
    "    \n",
    "    AI.to_pickle('pickle/st_data/AI/AI{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0623ea-4dd1-4b92-8276-6a7086fd036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AIデータの結合処理\n",
    "AI = pd.DataFrame()\n",
    "for date in tqdm(st_data_pe_bk.sort_values('date',ascending = True)['date'].dt.strftime(\"%Y%m%d\").unique()):\n",
    "    read = pd.read_pickle('pickle/st_data/AI/AI{}.pickle'.format(date))\n",
    "    AI = pd.concat([AI,read])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fedea8-1a91-4032-8f7f-d0de9405398a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 回収率の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bfb84-8768-4d34-87e7-5a546a4aa15d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 前処理済みのAIを結合する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7379f-cab6-48d2-9501-dcc452a5e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])\n",
    "aist.data[\"date\"] = pd.to_datetime(aist.data[\"date\"], format=\"%Y年%m月%d日\")\n",
    "#AIデータの結合処理\n",
    "\n",
    "AI = pd.DataFrame()\n",
    "for date in tqdm(aist.data.sort_values('date',ascending = True)['date'].dt.strftime(\"%Y%m%d\").unique()):\n",
    "    read = pd.read_pickle('pickle/st_data/AI/AI{}.pickle'.format(date))\n",
    "    AI = pd.concat([AI,read])\n",
    "del aist    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb50e8-e2b1-4663-a99d-2623f591586f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 確定オッズによる回収率の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd5814-ad9c-4a8c-b98c-7d871c618e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR=ST_results.read_pickle(['pickle/syutuba/race/STR/STR_latest.pickle'])\n",
    "add_odds = AI.merge(STR.data,how='left',left_on=['race_id','馬番'],right_on=['race_id','馬番'])\n",
    "rankdf = add_odds.copy()\n",
    "rankdf['score_rank'] = add_odds.groupby(by = 'race_id')['score_top4'].rank(ascending=False)\n",
    "rankdf['return_rank'] = add_odds.groupby(by = 'race_id')['score_return'].rank(ascending=False)\n",
    "first_result = rankdf.copy()\n",
    "first_result['着順'] = pd.to_numeric(first_result['着順'], errors='coerce')\n",
    "first_result.dropna(subset=['着順'], inplace=True)\n",
    "first_result['着順'] = first_result['着順'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504dbff6-f9ae-447e-a691-b93cf1c868f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 回収値保存先の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616cd7d-f447-40ac-b5ba-e074e0f1c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "date='20221204'\n",
    "def make_dir(date):\n",
    "    dir_path1 = 'note/回収率推移/'+date+'/score_return'\n",
    "    dir_path2 = 'note/回収率推移/'+date+'/score_top4'\n",
    "    dir_path3 = 'note/回収率推移/'+date+'/score_return/期待値変動型'\n",
    "    dir_path4 = 'note/回収率推移/'+date+'/score_top4/期待値変動型'\n",
    "    path_list = [dir_path1,dir_path2,dir_path3,dir_path4]\n",
    "    for path in path_list:\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as ex:\n",
    "            print(ex)\n",
    "            continue\n",
    "    return [dir_path1,dir_path2,dir_path3,dir_path4]\n",
    "path_list = make_dir(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f0c89-349a-49df-8312-e5bd7fc2c8aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## returnモデル期待値変動型での回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29425115-9c16-4bc4-83be-12ac0e9b5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_top3(first_result,flg=True):\n",
    "    top3 = first_result[first_result['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "    top3['期待値'] = top3['score_return']*top3['単勝オッズ']\n",
    "    top3 = top3.sort_values('期待値', ascending=True)\n",
    "    dropcol =['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "    # dropcol = ['score_rank','return_rank','複勝オッズ_min','複勝オッズ_max']\n",
    "    if flg:\n",
    "        top3.drop(columns=dropcol,inplace=True)\n",
    "    return top3\n",
    "def set_expreturn(top3):\n",
    "    #開催場別に期待値を設定する\n",
    "    top3.loc[top3['le_place'] == '札幌', 'min_exp'] = 8.4\n",
    "    top3.loc[top3['le_place'] == '札幌', 'max_exp'] = 11.4\n",
    "    top3.loc[top3['le_place'] == '小倉', 'min_exp'] = 9.4\n",
    "    top3.loc[top3['le_place'] == '小倉', 'max_exp'] = 12.4\n",
    "    top3.loc[top3['le_place'] == '新潟', 'min_exp'] = 7.5\n",
    "    top3.loc[top3['le_place'] == '新潟', 'max_exp'] = 10.5\n",
    "    top3.loc[top3['le_place'] == '阪神', 'min_exp'] = 10.2\n",
    "    top3.loc[top3['le_place'] == '阪神', 'max_exp'] = 13.2\n",
    "    \n",
    "    # top3.loc[top3['le_place'] == '中京', 'min_exp'] = 9.6\n",
    "    # top3.loc[top3['le_place'] == '中京', 'max_exp'] = 11.6\n",
    "    # top3.loc[top3['le_place'] == '中山', 'min_exp'] = 12.3\n",
    "    # top3.loc[top3['le_place'] == '中山', 'max_exp'] = 14.3\n",
    "    \n",
    "    top3.loc[top3['le_place'] == '中京', 'min_exp'] = 12.2\n",
    "    top3.loc[top3['le_place'] == '中京', 'max_exp'] = 15.2\n",
    "    top3.loc[top3['le_place'] == '中山', 'min_exp'] = 11.1\n",
    "    top3.loc[top3['le_place'] == '中山', 'max_exp'] = 14.1\n",
    "    top3.loc[top3['le_place'] == '東京', 'min_exp'] = 11.8\n",
    "    top3.loc[top3['le_place'] == '東京', 'max_exp'] = 14.8\n",
    "    top3.loc[top3['le_place'] == '福島', 'min_exp'] = 14.9\n",
    "    top3.loc[top3['le_place'] == '福島', 'max_exp'] = 17.9\n",
    "    top3.loc[top3['le_place'] == '函館', 'min_exp'] = 5.2\n",
    "    top3.loc[top3['le_place'] == '函館', 'max_exp'] = 8.2\n",
    "    return top3\n",
    "def return_expmodel(top3,return_money=10000):\n",
    "    top3 = set_expreturn(top3)\n",
    "    top3=top3[(top3['期待値']>=top3['min_exp']) & (top3['期待値']<=top3['max_exp'])].copy()\n",
    "    top3=top3[top3['score_return']>0.7]#足きりスコア\n",
    "    top3['minオッズ']=round(top3['min_exp']/top3['score_return'],2)\n",
    "    top3['maxオッズ']=round(top3['max_exp']/top3['score_return'],2)\n",
    "    top3['賭け金']=1/top3['単勝オッズ']*return_money\n",
    "    top3['期待値'] = round(top3['期待値'],1)\n",
    "    return top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf04edd-2f5c-4d5a-b584-9cc024f98bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "return_money=10000\n",
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3,return_money)\n",
    "print('回収率',top3[top3['着順']<=1]['単勝オッズ'].sum()/len(top3))\n",
    "print('対象レース',len(top3))\n",
    "print('的中レース',len(top3[top3['着順']<=1]))\n",
    "print('全レース',first_result['race_id'].nunique())\n",
    "print('対象レース割合',top3['race_id'].nunique()/first_result['race_id'].nunique())\n",
    "print('的中率',(len(top3[top3['着順']<=1])/len(top3)))\n",
    "print('単勝適正回収値',len(top3[top3['着順']==1])*return_money/top3['賭け金'].sum())\n",
    "print(top3[top3['着順']==1]['単勝オッズ'].std())\n",
    "with open(path_list[2]+'/overview.txt', 'w', encoding='sjis') as f:\n",
    "    print('回収率',top3[top3['着順']<=1]['単勝オッズ'].sum()/len(top3),file=f)\n",
    "    print('対象レース',len(top3),file=f)\n",
    "    print('的中レース',len(top3[top3['着順']<=1]),file=f)\n",
    "    print('全レース',first_result['race_id'].nunique(),file=f)\n",
    "    print('対象レース割合',top3['race_id'].nunique()/first_result['race_id'].nunique(),file=f)\n",
    "    print('的中率',(len(top3[top3['着順']<=1])/len(top3)),file=f)\n",
    "    print('単勝適正回収値',len(top3[top3['着順']==1])*return_money/top3['賭け金'].sum(),file=f)\n",
    "    seting_exp = top3[['le_place','min_exp','max_exp']]\n",
    "    print('設定オッズ',seting_exp[~seting_exp.duplicated()],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9353a-298f-4ff8-9796-3262826e37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率が１/１００の場合は、\n",
    "# 　・１万回行えば、１/８０～１/１２０の誤差\n",
    "# 的中率10%は1/10\n",
    "# その100倍は1000回つまり、1000レースの予想を行うと95%の確率で±20%以内の確立になる\n",
    "#よって1/8～1/12の確率(12.5％～0.83%)\n",
    "# 母数の400倍の試行回数をこなすと95%の確率で誤差±10%以内の確率になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55e8d4-2ca6-4a93-b233-5a06969a2fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scoreによる回収値\n",
    "first_result['賭け金']=1/first_result['単勝オッズ']\n",
    "a,x,y,z = [],[],[],[]\n",
    "score_name = 'score_return'\n",
    "smin = int(round(first_result[score_name].min(),1)*10)\n",
    "smax = int(round(first_result[score_name].max(),1)*10)\n",
    "min_odds = 5\n",
    "max_odds = 30\n",
    "for score in range(smin,smax):\n",
    "    try:\n",
    "        score = score/10\n",
    "        df = first_result[first_result[score_name]>score]\n",
    "        df = df[df['単勝オッズ']>=min_odds]\n",
    "        df = df[df['単勝オッズ']<=max_odds]\n",
    "        recovery_rate = round(df[df['着順']==1]['単勝オッズ'].sum()/len(df),2)\n",
    "        hit_rate = round(len(df[df['着順']==1])/len(df),2)\n",
    "        odds_std = round(df[df['着順']==1]['単勝オッズ'].std(),2)\n",
    "        odds_max = round(df[df['着順']==1]['単勝オッズ'].max(),2)\n",
    "        race_num = len(df)\n",
    "        s_odds = len(df[df['着順']==1])/df['賭け金'].sum()\n",
    "        x.append(score)\n",
    "        y.append(recovery_rate)\n",
    "        z.append(len(df)/35000)\n",
    "        a.append(hit_rate)\n",
    "        # if recovery_rate >1.2 and odds_std <20 and race_num>10 and hit_rate>0.1:\n",
    "        if recovery_rate >1.2:\n",
    "            print('score',score,'----------------------')\n",
    "            print('回収率',recovery_rate)\n",
    "            print('最大オッズ',odds_max)\n",
    "            print('中央オッズ',df[df['着順']==1]['単勝オッズ'].median())\n",
    "            print('標準偏差',odds_std)\n",
    "            print('レース数',race_num)\n",
    "            print('的中率',hit_rate)\n",
    "            print('単勝適正回収値',s_odds)\n",
    "    except ZeroDivisionError as e:\n",
    "        continue\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "ax = fig.add_subplot(111, xlabel=\"second_score\", ylabel='recovery_rate',title=score_name)\n",
    "ax.grid(color = \"gray\", linestyle=\"--\")\n",
    "ax.plot(x,y, label=\"recovery_rate\",alpha=0.9)\n",
    "ax.plot(x,z, label=\"race_len\",alpha=0.9)\n",
    "ax.plot(x,a, label=\"hit_rate\",alpha=0.9)\n",
    "ax.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f133bec-00ec-4ce2-9652-035e666c9af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3,return_money)\n",
    "\n",
    "taisyo = top3.copy()\n",
    "date1 = datetime(2022, 12, 3)\n",
    "date2 = date1 + relativedelta(days=3)  #年をまたいだ1ヶ月加算\n",
    "DAY = taisyo[pd.to_datetime(taisyo['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "DAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d371df-d56c-4940-b44c-ecad8de7c416",
   "metadata": {
    "tags": []
   },
   "source": [
    "### クラスによる的中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a221e-ee65-4cd1-bc82-30e52a3e0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_return(top3):\n",
    "    class_hikaku = pd.DataFrame()\n",
    "    class_hikaku['taisyo_class'] = top3['le_class'].value_counts()\n",
    "    class_hikaku['hit_class'] = top3[top3['着順']<=1]['le_class'].value_counts()\n",
    "    class_hikaku['hitrate_class'] = round(class_hikaku['hit_class']/class_hikaku['taisyo_class']*100,2)\n",
    "    class_hikaku = class_hikaku.sort_values(['hitrate_class'],ascending=False)    \n",
    "    return class_hikaku\n",
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3)\n",
    "with open(path_list[2]+'/クラス別的中率.txt', 'w', encoding='sjis') as f:\n",
    "    # print(class_return(top3),file=f)\n",
    "    print('レース目と当選数\\n',top3[top3['着順']<=1]['R'].value_counts(),file=f)\n",
    "    print('クラス別当選率\\n',class_return(top3),file=f)\n",
    "class_return(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66539d-b252-4e70-93e9-ca32acf83768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_return(top3):\n",
    "    place_hikaku = pd.DataFrame()\n",
    "    place_hikaku['taisyo_place'] = top3['le_place'].value_counts()\n",
    "    place_hikaku['hit_place'] = top3[top3['着順']<=1]['le_place'].value_counts()\n",
    "    place_hikaku['hitrate_place'] = round(place_hikaku['hit_place']/place_hikaku['taisyo_place']*100,2)\n",
    "    place_hikaku = place_hikaku.sort_values(['hitrate_place'],ascending=False)    \n",
    "    return place_hikaku\n",
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3)\n",
    "place_return(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424601c2-643d-48c2-a7ad-799f83cab324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_return(top3):\n",
    "    r_hikaku = pd.DataFrame()\n",
    "    r_hikaku['hazure_R'] = top3['R'].value_counts()\n",
    "    r_hikaku['hit_R'] = top3[top3['着順']<=1]['R'].value_counts()\n",
    "    r_hikaku['hitrate_R'] = round(r_hikaku['hit_R']/r_hikaku['hazure_R']*100,2)\n",
    "    r_hikaku = r_hikaku.sort_values(['hitrate_R' ],ascending=False)\n",
    "    return r_hikaku\n",
    "r_return(top3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd03ec-7601-49f5-a373-b187c8830092",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 月間回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c2810-c9bf-4c66-b1fc-9b8f534ddbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3)\n",
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = top3[pd.to_datetime(top3['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "with open(path_list[2]+'/一ケ月当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',summoney,file=f)\n",
    "    print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "    print('回収率',monthdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',summoney)\n",
    "print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfef62-490a-4981-bb33-9bc98a340869",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 週間回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063916ed-ac43-4825-879c-ebe31745087c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.now()-datetime(2022,1,1)\n",
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3)\n",
    "kakekin = 10000\n",
    "date1 = datetime(2022, 1, 1)\n",
    "sumprofit,sumprofit_rate,sum_syuppi,sum_hitmoney,divnum=0,0,0,0,0\n",
    "progress_date,progress_rate,progress_profit=[],[],[]\n",
    "a,b,c,d,e,f,g,h = [],[],[],[],[],[],[],[]\n",
    "hit_df = pd.DataFrame()\n",
    "bet_df = pd.DataFrame()\n",
    "for week in range(1,today.days,7):\n",
    "    date2 = date1 + relativedelta(weeks=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = top3[pd.to_datetime(top3['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    profit_rate = round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2)\n",
    "    hit_money = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum())\n",
    "    hit_rate = round(len(DAY[DAY['着順']==1])/race_num*100,1)\n",
    "    hit_num = len(DAY[DAY['着順']==1])\n",
    "    hit_df = pd.concat([hit_df,DAY[DAY['着順']==1]])\n",
    "    bet_df = pd.concat([bet_df,DAY[DAY['着順']!=1]])\n",
    "    a.append(str(date1.date())[5:]+' ~ '+str((date1 + relativedelta(days=1)).date())[8:])\n",
    "    b.append(syuppi)\n",
    "    c.append(hit_money)\n",
    "    d.append(profit)\n",
    "    e.append(hit_rate)\n",
    "    f.append(profit_rate)\n",
    "    g.append(race_num)\n",
    "    h.append(hit_num)\n",
    "    \n",
    "    date1 = date2\n",
    "    sumprofit = sumprofit+profit\n",
    "    sum_syuppi = sum_syuppi+syuppi\n",
    "    sum_hitmoney = sum_hitmoney+hit_money\n",
    "    progress_date.append(date2)\n",
    "    progress_rate.append(sum_hitmoney/sum_syuppi)\n",
    "    progress_profit.append(sumprofit)\n",
    "weekdf = pd.DataFrame(\n",
    "        data={'週': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g, '的中レース': h},\n",
    "        columns=['週', '出費', '当金', '利益', '当率', '回収率', '対象レース','的中レース'])\n",
    "with open(path_list[2]+'/一週間当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',weekdf['利益'].sum(),file=f)\n",
    "    print('合計損益',weekdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',weekdf['利益'].sum())\n",
    "weekdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b9014-1a34-4c58-b5e3-607b81cb16b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534785c-9f9d-4faf-a5d6-683fcb4c8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利益推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_profit, marker=\"o\")\n",
    "fig.savefig(path_list[2]+\"/利益推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd49505-028c-4611-b315-f7a2793d776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回収率推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_rate, marker=\"o\")\n",
    "fig.savefig(path_list[2]+\"/回収率推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2f343-d414-407e-ad45-ba9189956184",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## returnモデルの回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f56305-08fb-4dc2-b161-ab9ebe443452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_top3(first_result,flg=True):\n",
    "    top3 = first_result[first_result['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "    top3['期待値'] = top3['score_return']*top3['単勝オッズ']\n",
    "    top3 = top3.sort_values('期待値', ascending=True)\n",
    "    dropcol =['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "    # dropcol = ['score_rank','return_rank','複勝オッズ_min','複勝オッズ_max']\n",
    "    if flg:\n",
    "        top3.drop(columns=dropcol,inplace=True)\n",
    "    return top3\n",
    "def make_retrunmodel(first_result,minexp,maxexp):\n",
    "    top3 = making_top3(first_result,False)\n",
    "    top3=top3[(top3['期待値']>minexp) & (top3['期待値']<maxexp)]\n",
    "    top3['賭け金']=1/top3['単勝オッズ']\n",
    "    top3['minオッズ']=minexp/top3['score_return']\n",
    "    top3['maxオッズ']=maxexp/top3['score_return']\n",
    "    return top3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa98964-395e-4938-9765-cbce400a7998",
   "metadata": {
    "tags": []
   },
   "source": [
    "### クラスによる的中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70dbea-ddfe-4cfd-9f55-995447facb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hikaku = class_return(top3)\n",
    "with open(path_list[0]+'/当選傾向.txt', 'w', encoding='sjis') as f:\n",
    "    print('レース目と当選数\\n',top3[top3['着順']<=1]['R'].value_counts(),file=f)\n",
    "    print('クラス別当選率\\n',hikaku,file=f)\n",
    "hikaku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd61b67-1579-451f-8ed9-27d0eee81a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "minexp,maxexp = 12.5,14.5\n",
    "# minexp,maxexp = 11.4,13.4\n",
    "top3 = make_retrunmodel(first_result,minexp,maxexp)\n",
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = top3[pd.to_datetime(top3['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "with open(path_list[0]+'/一ケ月当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',summoney,file=f)\n",
    "    print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2),file=f)\n",
    "    print('期待値設定',minexp,'~',maxexp,file=f)\n",
    "    print('回収率',monthdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',summoney)\n",
    "print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993f3b5-3382-4214-8ee7-31ba0ba5fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利益推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_profit, marker=\"o\")\n",
    "fig.savefig(path_list[0]+\"/利益推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09d57c-3b00-4aa4-858d-9d5d0ac549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回収率推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_rate, marker=\"o\")\n",
    "fig.savefig(path_list[0]+\"/回収率推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524721c-d651-4e56-a5f2-ff5873228f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 期待値のスイートスポット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d1492-ea05-4765-8a44-a2ffab2a7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期待値ごとの回収値変化\n",
    "top3 = making_top3(first_result)\n",
    "x = np.arange(1, 30, 0.1) #1から20までを0.1きざみ\n",
    "y,z,a=[],[],[]\n",
    "hani=2\n",
    "tansyo_pro,old_tansyo = 0,0\n",
    "with open(path_list[0]+'/期待値ごとの回収値変化.txt', 'w', encoding='sjis') as f:\n",
    "    for num in x:\n",
    "        try:\n",
    "            plotdf = top3.sort_values('期待値', ascending=True).copy()\n",
    "            plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "            kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "            tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "            race_num = len(plotdf)\n",
    "            plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "            tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "            if kaisyu>1.2 and tekityu>0.1 and race_num>150:\n",
    "                print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),file=f)\n",
    "                print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2))\n",
    "                if tansyo_pro>old_tansyo:\n",
    "                    old_tansyo = tansyo_pro#更新\n",
    "                    print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2)\n",
    "            y.append(kaisyu)\n",
    "            z.append(tansyo_pro)\n",
    "            a.append(tekityu)\n",
    "        except ZeroDivisionError:\n",
    "            # print('skip_num',num)\n",
    "            y.append(0)\n",
    "            z.append(0)\n",
    "            a.append(0)\n",
    "            continue\n",
    "# print(print_text)\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,z)\n",
    "plt.plot(x,a)\n",
    "fig.savefig(path_list[0]+\"/期待値ごとの回収値変化.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d23f9-5d96-4cdc-81d5-6b75ef172076",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 月別回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8ef41-96d6-449e-a30a-f579ef3e4d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top3 = making_top3(first_result)\n",
    "for month in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, month, 1)# 期待値ごとの回収値変化\n",
    "    date2 = datetime(2022, month, calendar.monthrange(2022, month)[1])\n",
    "    x = np.arange(1, 20, 0.5) #1から20までを0.1きざみ\n",
    "    y,z,a=[],[],[]\n",
    "    hani=2\n",
    "    tansyo_pro,old_tansyo = 0,0\n",
    "    # with open(path_list[0]+'/月別回収値変化{}.txt'.format(month), 'w', encoding='sjis') as f:\n",
    "    for num in x:\n",
    "        try:\n",
    "            plotdf = top3[pd.to_datetime(top3['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "            plotdf = plotdf[pd.to_datetime(plotdf['date'], format=\"%Y年%m月%d日\")<=datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "            place = plotdf['le_place'].unique()\n",
    "            plotdf = plotdf.sort_values('期待値', ascending=True)\n",
    "            plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "            kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "            tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "            race_num = len(plotdf)\n",
    "            plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "            tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "            # if kaisyu>1.2:\n",
    "                # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),file=f)\n",
    "                # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2))\n",
    "            if tansyo_pro>old_tansyo:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2)\n",
    "            y.append(kaisyu)\n",
    "            z.append(tansyo_pro)\n",
    "            a.append(tekityu)\n",
    "        except ZeroDivisionError:\n",
    "            # print('skip_num',num)\n",
    "            y.append(0)\n",
    "            z.append(0)\n",
    "            a.append(0)\n",
    "            continue\n",
    "    print('month',date1,'~',date2,'\\n',place,'\\n',print_text)\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "    plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "    plt.title(str(month)+str(place)+'\\n'+str(print_text))\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,z)\n",
    "    plt.plot(x,a)\n",
    "    fig.savefig(path_list[0]+\"/月別の回収値変化{}月.png\".format(month), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a28e8e-ca89-424a-b6aa-016a10f6668f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 開催地別回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f84381-128a-4111-ae21-ad1117483957",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3,return_money)\n",
    "seting_exp = top3[['le_place','min_exp','max_exp']]\n",
    "seting_exp[~seting_exp.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be9922-3707-411b-b3bb-c4dc59033de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 期待値ごとの回収値変化(最低対象レース数30の場合)\n",
    "top3 = making_top3(first_result)\n",
    "place = top3['le_place'].unique()\n",
    "for p in place:\n",
    "    print(p)\n",
    "    x = np.arange(1, 15, 0.1) #1から20までを0.1きざみ\n",
    "    y,z,a=[],[],[]\n",
    "    hani=3\n",
    "    tansyo_pro,old_tansyo = 0,0\n",
    "    for num in x:\n",
    "        try:\n",
    "            plotdf = top3.sort_values('期待値', ascending=True)\n",
    "            plotdf = top3[top3['le_place']==p]\n",
    "            all_race_num = plotdf['race_id'].nunique()\n",
    "            plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "            kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "            tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "            race_num = len(plotdf)\n",
    "            plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "            tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "            # if kaisyu>1.2 and tekityu>0.1 and race_num>150:\n",
    "            # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2))\n",
    "            if tansyo_pro>old_tansyo and race_num>30:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2)\n",
    "            y.append(kaisyu)\n",
    "            z.append(tansyo_pro)\n",
    "            a.append(tekityu)\n",
    "        except ZeroDivisionError:\n",
    "            # print('skip_num',num)\n",
    "            y.append(0)\n",
    "            z.append(0)\n",
    "            a.append(0)\n",
    "            continue\n",
    "    print(print_text)\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "    plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "    plt.title(str(p)+'\\n'+str(print_text))\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,z)\n",
    "    plt.plot(x,a)\n",
    "    fig.savefig(path_list[0]+\"/開催地別の回収値変化_{}.png\".format(p), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5206fb-431c-4368-b851-598df47ba5a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 開催地別の詳細期待値分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb570179-5ae2-4a6b-9e48-4a804aa3f1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 期待値ごとの回収値変化\n",
    "p='福島'\n",
    "print(p)\n",
    "x = np.arange(1, 15, 0.1) #1から20までを0.1きざみ\n",
    "y,z,a=[],[],[]\n",
    "hani,tansyo_pro,old_tansyo = 3,0,0\n",
    "for num in x:\n",
    "    try:\n",
    "        plotdf = top3.sort_values('期待値', ascending=True)\n",
    "        plotdf = top3[top3['le_place']==p]\n",
    "        all_race_num = plotdf['race_id'].nunique()\n",
    "        plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "        kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "        tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "        race_num = len(plotdf)\n",
    "        plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "        tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "        if kaisyu>1.2 and tekityu>0.1 and race_num>15:\n",
    "            print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2))\n",
    "        if tansyo_pro>old_tansyo:\n",
    "            old_tansyo = tansyo_pro#更新\n",
    "            print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2)\n",
    "        y.append(kaisyu)\n",
    "        z.append(tansyo_pro)\n",
    "        a.append(tekityu)\n",
    "    except ZeroDivisionError:\n",
    "        # print('skip_num',num)\n",
    "        y.append(0)\n",
    "        z.append(0)\n",
    "        a.append(0)\n",
    "        continue\n",
    "print(print_text)\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,z)\n",
    "plt.plot(x,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a59cf-8626-4398-a6c4-c66943107ce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## top4モデルでの回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b916e-e0fc-4680-a785-bc29ea1f88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topモデルで使用する期待値表を作成する\n",
    "def maiking_top2(first_result,flg=True):\n",
    "    top2 = first_result[first_result['score_rank'] <= 2].sort_values(by = ['race_id','score_top4'], ascending=False)\n",
    "    top2['期待値'] = ((top2['score_top4']))*top2['単勝オッズ']\n",
    "    top2 = top2.sort_values('期待値', ascending=True)\n",
    "    dropcol =['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "    # dropcol = ['score_rank','return_rank','複勝オッズ_min','複勝オッズ_max']\n",
    "    if flg:\n",
    "        top2.drop(columns=dropcol,inplace=True)\n",
    "    return top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c551fa-d202-4e9c-9673-7c2ca5e5dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scoremodel(first_result,minexp,maxexp):\n",
    "    top2 = maiking_top2(first_result,False)\n",
    "    top2=top2[(top2['期待値']>minodds) & (top2['期待値']<maxodds)]\n",
    "    top2['賭け金']=1/top2['単勝オッズ']\n",
    "    top2['minオッズ']=minodds/top2['score_return']\n",
    "    top2['maxオッズ']=maxodds/top2['score_return']\n",
    "    return top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c821d6-da1b-4724-9273-40d520d61bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#順張りの場合\n",
    "minodds = 8.1\n",
    "maxodds = 10.1\n",
    "top2 = make_scoremodel(first_result,minodds,maxodds)\n",
    "print('回収率',top2[top2['着順']<=1]['単勝オッズ'].sum()/len(top2))\n",
    "print('対象レース',len(top2))\n",
    "print('的中レース',len(top2[top2['着順']<=1]))\n",
    "print('全レース',first_result['race_id'].nunique())\n",
    "print('対象レース割合',len(top2)/first_result['race_id'].nunique())\n",
    "print('的中率',(len(top2[top2['着順']<=1])/len(top2)))\n",
    "print('単勝適正回収値',len(top2[top2['着順']==1])/top2['賭け金'].sum())\n",
    "# ファイルへの書き込み\n",
    "with open(path_list[1]+'/overview.txt', 'a', encoding='sjis') as f:\n",
    "    print('回収率',top2[top2['着順']<=1]['単勝オッズ'].sum()/len(top2),file=f)\n",
    "    print('対象レース',len(top2),file=f)\n",
    "    print('的中レース',len(top2[top2['着順']<=1]),file=f)\n",
    "    print('全レース',first_result['race_id'].nunique(),file=f)\n",
    "    print('対象レース割合',len(top2)/first_result['race_id'].nunique(),file=f)\n",
    "    print('的中率',(len(top2[top2['着順']<=1])/len(top2)),file=f)\n",
    "    print('単勝適正回収値',len(top2[top2['着順']==1])*10000/top2['賭け金'].sum(),file=f)\n",
    "    print('設定オッズ',minodds,'~',maxodds,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa3e94-7a26-4e96-a9bc-6f94a1497fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hikaku = class_return(top2)\n",
    "with open(path_list[1]+'当選傾向.txt', 'w', encoding='sjis') as f:\n",
    "    print('レース目と当選数\\n',top2[top2['着順']<=1]['R'].value_counts(),file=f)\n",
    "    print('クラス別当選率\\n',hikaku,file=f)\n",
    "hikaku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f963f7-8905-4045-bf91-737bbaedf745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期待値ごとの回収値変化\n",
    "top2=maiking_top2(first_result)\n",
    "x = np.arange(1, 20, 0.1) #1から20までを0.1きざみ\n",
    "y,z,a=[],[],[]\n",
    "hani,tansyo_pro,old_tansyo = 2,0,0\n",
    "for num in x:\n",
    "    try:\n",
    "        plotdf = top2.sort_values('期待値', ascending=True)\n",
    "        plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "        kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "        tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "        race_num = len(plotdf)\n",
    "        plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "        tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "        if kaisyu>1 and tekityu>0.1 and race_num>100:\n",
    "            print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2))\n",
    "            if tansyo_pro>old_tansyo:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2)\n",
    "        y.append(kaisyu)\n",
    "        z.append(tansyo_pro)\n",
    "        a.append(tekityu)\n",
    "    except ZeroDivisionError:\n",
    "        # print('skip_num',num)\n",
    "        y.append(0)\n",
    "        z.append(0)\n",
    "        a.append(0)\n",
    "        continue\n",
    "print(print_text)\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,z)\n",
    "plt.plot(x,a)\n",
    "fig.savefig(path_list[1]+\"/期待値ごとの回収値変化.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1042409-e87b-4b10-a2bb-22dff893bb97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 開催地別期待値グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ab860-efaa-4474-8b8a-9b63d1de81f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "place = top2['le_place'].unique()\n",
    "for p in place:\n",
    "    print(p)\n",
    "    x = np.arange(1, 15, 0.1) #1から20までを0.1きざみ\n",
    "    y,z,a=[],[],[]\n",
    "    hani,tansyo_pro,old_tansyo = 2,0,0\n",
    "    for num in x:\n",
    "        try:\n",
    "            plotdf = top2.sort_values('期待値', ascending=True)\n",
    "            plotdf = top2[top2['le_place']==p]\n",
    "            all_race_num = len(plotdf['race_id'].unique())\n",
    "            plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "            kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "            tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "            race_num = len(plotdf)\n",
    "            plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "            tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "            # if kaisyu>1.2 and tekityu>0.1 and race_num>150:\n",
    "            # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2))\n",
    "            if tansyo_pro>old_tansyo:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),'レース数割合',round(race_num/all_race_num,2)\n",
    "            y.append(kaisyu)\n",
    "            z.append(tansyo_pro)\n",
    "            a.append(tekityu)\n",
    "        except ZeroDivisionError:\n",
    "            # print('skip_num',num)\n",
    "            y.append(0)\n",
    "            z.append(0)\n",
    "            a.append(0)\n",
    "            continue\n",
    "    print(print_text)\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "    plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,z)\n",
    "    plt.plot(x,a)\n",
    "    fig.savefig(path_list[1]+\"/開催地別の回収値変化_{}.png\".format(p), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6260c-91b6-4500-b6d0-54a33a01934c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top2=maiking_top2(first_result)\n",
    "for month in range(1,datetime.now().month+1):\n",
    "    date = datetime(2022, month, 1)# 期待値ごとの回収値変化\n",
    "    x = np.arange(1, 12, 0.5) #1から20までを0.1きざみ\n",
    "    y,z,a=[],[],[]\n",
    "    hani,tansyo_pro,old_tansyo = 2,0,0\n",
    "    # with open(dir_path1+'/期待値ごとの回収値変化.txt', 'w', encoding='sjis') as f:\n",
    "    for num in x:\n",
    "        try:\n",
    "            plotdf = top2[pd.to_datetime(top2['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date, format=\"%Y%m%d\")]\n",
    "            # plotdf = top2[top2['le_place']=='札幌']\n",
    "            # print((plotdf))\n",
    "            plotdf = plotdf.sort_values('期待値', ascending=True)\n",
    "            plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "            kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "            tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "            race_num = len(plotdf)\n",
    "            plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "            tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "            # if kaisyu>1.2:\n",
    "                # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2),file=f)\n",
    "                # print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2))\n",
    "            if tansyo_pro>old_tansyo:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2)\n",
    "            y.append(kaisyu)\n",
    "            z.append(tansyo_pro)\n",
    "            a.append(tekityu)\n",
    "        except ZeroDivisionError:\n",
    "            # print('skip_num',num)\n",
    "            y.append(0)\n",
    "            z.append(0)\n",
    "            a.append(0)\n",
    "            continue\n",
    "    print('month',month,'\\n',print_text)\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "    plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,z)\n",
    "    plt.plot(x,a)\n",
    "    fig.savefig(path_list[1]+\"/月別の回収値変化{}月.png\".format(month), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f467e-c68d-443e-8c06-8985700c39dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 月別回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286adf68-cc81-4f4b-8848-61b22546a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = make_scoremodel(top2,minodds,maxodds)\n",
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = top2[pd.to_datetime(top2['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "with open(path_list[1]+'/一ケ月当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',summoney,file=f)\n",
    "    print('回収率',round(monthdf['回収率'].mean(),2),file=f)\n",
    "    print('回収率',monthdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin,'\\n合計損益',summoney,'\\n回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f296253-7e55-44ee-a26f-5f223323719d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 週別回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c8452-844d-4496-bf9c-5cb9a64b38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = make_scoremodel(top2,minodds,maxodds)\n",
    "today = datetime.now()-datetime(2022,1,1)\n",
    "kakekin = 10000\n",
    "date1 = datetime(2022, 1, 1)\n",
    "sumprofit,sumprofit_rate,sum_syuppi,sum_hitmoney,divnum=0,0,0,0,0\n",
    "progress_date,progress_rate,progress_profit=[],[],[]\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for week in range(1,today.days,7):\n",
    "    try:\n",
    "    # print(week,'週------')\n",
    "    # date1 = datetime(2022, 1, 1)\n",
    "        date2 = date1 + relativedelta(weeks=1)  #年をまたいだ1ヶ月加算\n",
    "        # print(date1,date2)\n",
    "        DAY = top2[pd.to_datetime(top2['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "        DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "        syuppi = kakekin*len(DAY)\n",
    "        race_num = len(DAY)\n",
    "        # print(date2,race_num)\n",
    "        profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "        profit_rate = round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2)\n",
    "        hit_money = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum())\n",
    "        hit_rate = round(len(DAY[DAY['着順']==1])/race_num*100,1)\n",
    "        # print('出費',syuppi)\n",
    "        # print('当金',hit_money)\n",
    "        # print('利益',profit)\n",
    "        # print('当率',hit_rate)\n",
    "        # print('回収率',profit_rate)\n",
    "        # print('対象レース',race_num)\n",
    "        a.append(str(date1.date())[5:]+' ~ '+str(date2.date())[5:])\n",
    "        b.append(syuppi)\n",
    "        c.append(hit_money)\n",
    "        d.append(profit)\n",
    "        e.append(hit_rate)\n",
    "        f.append(profit_rate)\n",
    "        g.append(race_num)\n",
    "\n",
    "        date1 = date2\n",
    "        sumprofit = sumprofit+profit\n",
    "        sum_syuppi = sum_syuppi+syuppi\n",
    "        sum_hitmoney = sum_hitmoney+hit_money\n",
    "        progress_date.append(date2)\n",
    "        progress_rate.append(sum_hitmoney/sum_syuppi)\n",
    "        progress_profit.append(sumprofit)\n",
    "    except:\n",
    "        continue\n",
    "weekdf = pd.DataFrame(\n",
    "        data={'週': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['週', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "with open(path_list[1]+'/一週間当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',weekdf['利益'].sum(),file=f)\n",
    "    print('合計損益',weekdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin,'\\n合計損益',weekdf['利益'].sum())\n",
    "weekdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbc40b-6645-4226-b3a8-a6011df658c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 収益のグラフ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf50883-8b44-4ffc-9cc3-8f1727f1ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利益推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_profit, marker=\"o\")\n",
    "fig.savefig(path_list[1]+\"/利益推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2058e3b-ba6c-4a0d-889a-ed35b0e3910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回収率推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_rate, marker=\"o\")\n",
    "fig.savefig(path_list[1]+\"/回収率推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66dedea-5942-4db1-8447-629708985ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## top4モデル期待値変動型での回収率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bd3f4-9188-4014-b38c-cd161dfc81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#開催地別の期待値設定\n",
    "def set_exptop(top2):\n",
    "    #開催場別に期待値を設定する\n",
    "    top2.loc[top2['le_place'] == '札幌', 'min_exp'] = 8.4\n",
    "    top2.loc[top2['le_place'] == '札幌', 'max_exp'] = 10.4\n",
    "    top2.loc[top2['le_place'] == '小倉', 'min_exp'] = 14.8\n",
    "    top2.loc[top2['le_place'] == '小倉', 'max_exp'] = 16.8\n",
    "    top2.loc[top2['le_place'] == '新潟', 'min_exp'] = 9.1\n",
    "    top2.loc[top2['le_place'] == '新潟', 'max_exp'] = 11.1\n",
    "    # top2.loc[top2['le_place'] == '新潟', 'min_exp'] = 14.3\n",
    "    # top2.loc[top2['le_place'] == '新潟', 'max_exp'] = 17.3\n",
    "    top2.loc[top2['le_place'] == '阪神', 'min_exp'] = 9.6\n",
    "    top2.loc[top2['le_place'] == '阪神', 'max_exp'] = 11.6\n",
    "    top2.loc[top2['le_place'] == '中京', 'min_exp'] = 7.5\n",
    "    top2.loc[top2['le_place'] == '中京', 'max_exp'] = 9.5\n",
    "    top2.loc[top2['le_place'] == '中山', 'min_exp'] = 8\n",
    "    top2.loc[top2['le_place'] == '中山', 'max_exp'] = 10\n",
    "    top2.loc[top2['le_place'] == '東京', 'min_exp'] = 8.2\n",
    "    top2.loc[top2['le_place'] == '東京', 'max_exp'] = 10.2\n",
    "    top2.loc[top2['le_place'] == '福島', 'min_exp'] = 7.6\n",
    "    top2.loc[top2['le_place'] == '福島', 'max_exp'] = 9.6\n",
    "    top2.loc[top2['le_place'] == '函館', 'min_exp'] = 12.6\n",
    "    top2.loc[top2['le_place'] == '函館', 'max_exp'] = 14.6\n",
    "    return top2\n",
    "def top_expmodel(top2,return_money=10000):\n",
    "    top2 = set_exptop(top2)\n",
    "    top2=top2[(top2['期待値']>top2['min_exp']) & (top2['期待値']<top2['max_exp'])].copy()\n",
    "    top2['minオッズ']=round(top2['min_exp']/top2['score_top4'],2)\n",
    "    top2['maxオッズ']=round(top2['max_exp']/top2['score_top4'],2)\n",
    "    top2['賭け金']=1/top2['単勝オッズ']*return_money\n",
    "    top2['期待値'] = round(top2['期待値'],1)\n",
    "    return top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96974e-7e41-48df-8d3e-9375c87682cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_money=10000\n",
    "top2 = maiking_top2(first_result)\n",
    "top2 = top_expmodel(top2,return_money)\n",
    "print('回収率',top2[top2['着順']<=1]['単勝オッズ'].sum()/len(top2)),print('対象レース',len(top2)),print('的中レース',len(top2[top2['着順']<=1])),print('全レース',first_result['race_id'].nunique()),print('対象レース割合',top2['race_id'].nunique()/first_result['race_id'].nunique()),print('的中率',(len(top2[top2['着順']<=1])/len(top2))),print('単勝適正回収値',len(top2[top2['着順']==1])*return_money/top2['賭け金'].sum())\n",
    "with open(path_list[3]+'/overview.txt', 'a', encoding='sjis') as f:\n",
    "    print('回収率',top2[top2['着順']<=1]['単勝オッズ'].sum()/len(top2),file=f)\n",
    "    print('対象レース',len(top2),file=f)\n",
    "    print('的中レース',len(top2[top2['着順']<=1]),file=f)\n",
    "    print('全レース',first_result['race_id'].nunique(),file=f)\n",
    "    print('対象レース割合',len(top2)/first_result['race_id'].nunique(),file=f)\n",
    "    print('的中率',(len(top2[top2['着順']<=1])/len(top2)),file=f)\n",
    "    print('単勝適正回収値',len(top2[top2['着順']==1])*return_money/top2['賭け金'].sum(),file=f)\n",
    "    seting_exp = top2[['le_place','min_exp','max_exp']]\n",
    "    print('設定オッズ',seting_exp[~seting_exp.duplicated()],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b4a0d-5430-4708-9bf8-2ac01bea7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "taisyo = top2.copy()\n",
    "date1 = datetime(2022, 12, 3)\n",
    "date2 = date1 + relativedelta(days=3)  #年をまたいだ1ヶ月加算\n",
    "DAY = taisyo[pd.to_datetime(taisyo['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1458b6-34d1-43af-bf25-ae28e03f3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#順張りの場合\n",
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = top2[pd.to_datetime(top2['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "with open(path_list[3]+'/一ケ月当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',summoney,file=f)\n",
    "    print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2),file=f)\n",
    "    print('回収率',monthdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',summoney)\n",
    "print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf37c2-5e05-45f0-8bc5-9f5c9bb5590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#週間回収率\n",
    "kakekin = 10000\n",
    "date1 = datetime(2022, 1, 1)\n",
    "sumprofit,sumprofit_rate,sum_syuppi,sum_hitmoney,divnum=0,0,0,0,0\n",
    "progress_date,progress_rate,progress_profit=[],[],[]\n",
    "a,b,c,d,e,f,g,h = [],[],[],[],[],[],[],[]\n",
    "hit_df = pd.DataFrame()\n",
    "bet_df = pd.DataFrame()\n",
    "for week in range(1,today.days,7):\n",
    "    # try:\n",
    "    # print(week,'週------')\n",
    "    # date1 = datetime(2022, 1, 1)\n",
    "    date2 = date1 + relativedelta(weeks=1)  #年をまたいだ1ヶ月加算\n",
    "    # print(date1,date2)\n",
    "    DAY = top2[pd.to_datetime(top2['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    profit_rate = round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2)\n",
    "    hit_money = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum())\n",
    "    hit_rate = round(len(DAY[DAY['着順']==1])/race_num*100,1)\n",
    "    hit_num = len(DAY[DAY['着順']==1])\n",
    "    hit_df = pd.concat([hit_df,DAY[DAY['着順']==1]])\n",
    "    bet_df = pd.concat([bet_df,DAY[DAY['着順']!=1]])\n",
    "    # print('出費',syuppi)\n",
    "    # print('当金',hit_money)\n",
    "    # print('利益',profit)\n",
    "    # print('当率',hit_rate)\n",
    "    # print('回収率',profit_rate)\n",
    "    # print('対象レース',race_num)\n",
    "    # a.append(str(date1.date())[5:]+' ~ '+str(date2.date())[5:])\n",
    "    a.append(str(date1.date())[5:]+' ~ '+str((date1 + relativedelta(days=1)).date())[8:])\n",
    "    b.append(syuppi)\n",
    "    c.append(hit_money)\n",
    "    d.append(profit)\n",
    "    e.append(hit_rate)\n",
    "    f.append(profit_rate)\n",
    "    g.append(race_num)\n",
    "    h.append(hit_num)\n",
    "    \n",
    "    date1 = date2\n",
    "    sumprofit = sumprofit+profit\n",
    "    sum_syuppi = sum_syuppi+syuppi\n",
    "    sum_hitmoney = sum_hitmoney+hit_money\n",
    "    progress_date.append(date2)\n",
    "    progress_rate.append(sum_hitmoney/sum_syuppi)\n",
    "    progress_profit.append(sumprofit)\n",
    "weekdf = pd.DataFrame(\n",
    "        data={'週': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g, '的中レース': h},\n",
    "        columns=['週', '出費', '当金', '利益', '当率', '回収率', '対象レース','的中レース'])\n",
    "with open(path_list[3]+'/一週間当たりの回収率.txt', 'w', encoding='sjis') as f:\n",
    "    print('１レース当たりの掛け金',kakekin,file=f)\n",
    "    print('合計損益',weekdf['利益'].sum(),file=f)\n",
    "    print('合計損益',weekdf,file=f)\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',weekdf['利益'].sum())\n",
    "weekdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975a1d5-aac0-49be-80bf-3b62d89ad75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利益推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_profit, marker=\"o\")\n",
    "fig.savefig(path_list[3]+\"/利益推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93eb907-c2bf-4628-9d8d-595eda51f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回収率推移\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.plot(progress_date, progress_rate, marker=\"o\")\n",
    "fig.savefig(path_list[3]+\"/回収率推移グラフ.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25bde67-e416-443a-999f-a381b77986bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ハイブリット形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dd7ab-76a9-4ce1-b264-339f94c57ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top3の期待値範囲に該当せず20倍以上のオッズが付いている馬が1頭でもいる場合のレースで\n",
    "#top2の期待値範囲8-11に該当する場合の回収値\n",
    "#要約すると穴馬モデルが来ない可能性の高いレース(期待値範囲外かつ20倍以上一頭)で\n",
    "top2 = maiking_top2(first_result)\n",
    "top3 = making_top3(first_result)\n",
    "top3 = return_expmodel(top3,return_money)\n",
    "first_result['race_id']\n",
    "df = first_result[~first_result['race_id'].isin(top3['race_id'])]\n",
    "df2 = df[df['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "df3 = df2[df2['単勝オッズ']>20].value_counts('race_id')==1\n",
    "target_race_id = df3[df3].index\n",
    "target = top2[top2['race_id'].isin(target_race_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68568764-264f-4bcb-a854-35a21a7ea75d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kekka = target[(target['期待値']>8)&(target['期待値']<11)]\n",
    "kekka = kekka[kekka['score_top4']>=1.2]\n",
    "print('回収率',kekka[kekka['着順']<=1]['単勝オッズ'].sum()/len(kekka))\n",
    "print('平均的中オッズ',kekka[kekka['着順']<=1]['単勝オッズ'].mean())\n",
    "print('対象レース',len(kekka))\n",
    "print('対象レース割合',kekka['race_id'].nunique()/first_result['race_id'].nunique())\n",
    "print('的中レース',len(kekka[kekka['着順']<=1]))\n",
    "print('的中率',(len(kekka[kekka['着順']<=1])/len(kekka)))\n",
    "print('出現確率',kekka['date'].nunique()/first_result['date'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1fd30-7a50-440d-982a-fbdb4c809c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = datetime(2022, 12, 3)\n",
    "date2 = date1 + relativedelta(days=1000)  #年をまたいだ1ヶ月加算\n",
    "DAY = kekka[pd.to_datetime(kekka['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "print('回収率',DAY[DAY['着順']<=1]['単勝オッズ'].sum()/len(DAY))\n",
    "DAY.sort_values(['le_place','R','馬番'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51c7d7-6894-48c6-b208-98234c0d49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#月間回収率\n",
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = kekka[pd.to_datetime(kekka['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    if race_num == 0:\n",
    "        race_num=1\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',summoney)\n",
    "print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "print(monthdf[7:].mean())\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfac241-b39f-46f9-93d7-f933b232ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = kekka[pd.to_datetime(kekka['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "kekka['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f66cd1-0c93-4e78-9ac1-e099f1edc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_return(kekka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79f2a0-54e0-4ce7-ab7c-335cf471eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_return(kekka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d238e-a644-4032-bbb9-2ecd4193fbe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 期待値ごとの回収値変化\n",
    "x = np.arange(1, 15, 0.1) #1から20までを0.1きざみ\n",
    "y,z,a=[],[],[]\n",
    "hani,tansyo_pro,old_tansyo = 2,0,0\n",
    "for num in x:\n",
    "    try:\n",
    "        plotdf = target.sort_values('期待値', ascending=True)\n",
    "        plotdf=plotdf[(plotdf['期待値']>num) & (plotdf['期待値']<num+hani)]\n",
    "        kaisyu = plotdf[plotdf['着順']<=1]['単勝オッズ'].sum()/len(plotdf)\n",
    "        tekityu = len(plotdf[plotdf['着順']<=1])/len(plotdf)\n",
    "        race_num = len(plotdf)\n",
    "        plotdf['賭け金']=1/plotdf['単勝オッズ']*10000\n",
    "        tansyo_pro = len(plotdf[plotdf['着順']==1])*10000/plotdf['賭け金'].sum()\n",
    "        if kaisyu>1 and tekityu>0.1 and race_num>50:\n",
    "            print('回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2))\n",
    "            if tansyo_pro>old_tansyo:\n",
    "                old_tansyo = tansyo_pro#更新\n",
    "                print_text = '回収率',round(kaisyu,2),'期待値',round(num,1),'~',round(num+hani,1),'対象レース',race_num,'的中率',round(tekityu*100,1),'単勝適正回収値',round(tansyo_pro,2)\n",
    "        y.append(kaisyu)\n",
    "        z.append(tansyo_pro)\n",
    "        a.append(tekityu)\n",
    "    except ZeroDivisionError:\n",
    "        # print('skip_num',num)\n",
    "        y.append(0)\n",
    "        z.append(0)\n",
    "        a.append(0)\n",
    "        continue\n",
    "print(print_text)\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "plt.grid(color = \"gray\", linestyle=\"--\")\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,z)\n",
    "plt.plot(x,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645889c-9b27-4e25-86fa-b9921cc031b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#該当馬が存在せずtop2から単勝馬券を購入した場合\n",
    "print('回収率',kekka[kekka['着順']<=1]['単勝オッズ'].sum()/len(kekka))\n",
    "print('対象レース',len(kekka))\n",
    "print('的中レース',len(kekka[kekka['着順']<=1]))\n",
    "print('的中率',(len(kekka[kekka['着順']<=1])/len(kekka)))\n",
    "# print('単勝適正回収値',len(target[target['着順']==1])*return_money/target['賭け金'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512edb2-aeae-40b5-9e03-d17c3765ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#さらにtop2のscore1位から購入した場合\n",
    "sc1 = kekka[kekka['score_rank']==1]\n",
    "print('回収率',sc1[sc1['着順']<=1]['単勝オッズ'].sum()/len(sc1))\n",
    "print('対象レース',len(sc1))\n",
    "print('的中レース',len(sc1[sc1['着順']<=1]))\n",
    "print('的中率',(len(sc1[sc1['着順']<=1])/len(sc1)))\n",
    "# print('単勝適正回収値',len(sc1[sc1['着順']==1])*return_money/sc1['賭け金'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6a35b-4063-4d28-be60-0bb6caef1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#さらにtop2のscore２位から購入した場合\n",
    "sc2 = kekka[kekka['score_rank']==2]\n",
    "print('回収率',sc2[sc2['着順']<=1]['単勝オッズ'].sum()/len(sc2))\n",
    "print('対象レース',len(sc2))\n",
    "print('的中レース',len(sc2[sc2['着順']<=1]))\n",
    "print('的中率',(len(sc2[sc2['着順']<=1])/len(sc2)))\n",
    "# print('単勝適正回収値',len(sc2[sc2['着順']==1])*return_money/sc2['賭け金'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776c35d-bed6-4df2-a378-4d48a55cdd87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 指数モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3530b0-00c8-4ef1-b523-8b698df5d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_model_simyu(index_df):\n",
    "    def make3(first_result):\n",
    "        top3 = first_result[first_result['return_rank'] <= 3].sort_values(by = ['race_id','return_rank'], ascending=False)\n",
    "        # top3 = top3[~(top3['単勝オッズ'].str.contains('-', na=False))]\n",
    "        top3 = top3.astype({'単勝オッズ': float})\n",
    "        top3['期待値'] = top3['score_return']*top3['単勝オッズ']\n",
    "        top3 = top3.sort_values('期待値', ascending=True)\n",
    "        # ['course_len', 'race_type', 'race_round', 'weather','ground_state']\n",
    "        # dropcol = ['複勝オッズ_min','複勝オッズ_max']\n",
    "        # top3.drop(columns=dropcol,inplace=True)\n",
    "        return top3\n",
    "    def make2(first_result):\n",
    "        top2 = first_result[first_result['score_rank'] <= 2].sort_values(by = ['race_id','score_top4'], ascending=False)\n",
    "        # top2 = top2[~(top2['単勝オッズ'].str.contains('-', na=False))]\n",
    "        top2 = top2.astype({'単勝オッズ': float})\n",
    "        top2['期待値'] = (top2['score_top4'])*top2['単勝オッズ']\n",
    "        top2 = top2.sort_values('期待値', ascending=True)\n",
    "        # dropcol = ['複勝オッズ_min','複勝オッズ_max']\n",
    "        # top2.drop(columns=dropcol,inplace=True)\n",
    "        return top2\n",
    "    sumdf = pd.DataFrame()\n",
    "    top3 = make3(index_df)\n",
    "    group_re = top3.groupby('race_id').sum()\n",
    "    mergedf_re = top3.merge(group_re[['単勝オッズ','score_top4','score_return','score_rank','期待値']],on='race_id',how = 'left')\n",
    "    top2 = make2(index_df)\n",
    "    group_top = top2.groupby('race_id').sum()\n",
    "    mergedf = top2.merge(group_top[['単勝オッズ','score_top4','score_return','score_rank','期待値']],on='race_id',how = 'left')\n",
    "    sumdf = group_re.merge(group_top,how='outer',right_index=True,left_index=True,suffixes=['_re','_top'])\n",
    "    race_id = sumdf[(sumdf['score_return_re']>sumdf['score_top4_top'])].index\n",
    "    hits = top3[top3['race_id'].isin(race_id)].sort_values(['race_id','le_place','R','score_return']).copy()\n",
    "    target = hits[hits['単勝オッズ']<=20].copy()\n",
    "    target = target[target['score_return'].isin(target.groupby('race_id')['score_return'].max())]\n",
    "    target = target[(target['score_rank']>=9)&(target['score_rank']<=10)]\n",
    "    dropcol = ['course_len','race_type','race_round','weather','ground_state']\n",
    "    target.drop(columns=dropcol,inplace=True)\n",
    "    return target.sort_values(['le_place','R','馬番'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26595cf8-a2d2-42ce-8b14-2fb81e2cd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "indf = index_model_simyu(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206063b8-88ab-409e-adee-b166b77907be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('回収率',indf[indf['着順']<=1]['単勝オッズ'].sum()/len(indf))\n",
    "print('平均的中オッズ',indf[indf['着順']<=1]['単勝オッズ'].mean())\n",
    "print('対象レース',len(indf))\n",
    "print('対象レース割合',indf['race_id'].nunique()/first_result['race_id'].nunique())\n",
    "print('的中レース',len(indf[indf['着順']<=1]))\n",
    "print('的中率',(len(indf[indf['着順']<=1])/len(indf)))\n",
    "print('出現確率',indf['date'].nunique()/first_result['date'].nunique())\n",
    "indf[indf['着順']<=1]['単勝オッズ'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6f8c7-7fbb-41a1-b9e7-19cad5e03faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kakekin = 10000\n",
    "summoney = 0\n",
    "a,b,c,d,e,f,g = [],[],[],[],[],[],[]\n",
    "for mon in range(1,datetime.now().month+1):\n",
    "    date1 = datetime(2022, mon, 1)\n",
    "    date2 = date1 + relativedelta(months=1)  #年をまたいだ1ヶ月加算\n",
    "    DAY = indf[pd.to_datetime(indf['date'], format=\"%Y年%m月%d日\")>=datetime.strftime(date1, format=\"%Y%m%d\")]\n",
    "    DAY = DAY[pd.to_datetime(DAY['date'], format=\"%Y年%m月%d日\")<datetime.strftime(date2, format=\"%Y%m%d\")]\n",
    "\n",
    "    syuppi = kakekin*len(DAY)\n",
    "    race_num = len(DAY)\n",
    "    if race_num == 0:\n",
    "        race_num=1\n",
    "    profit = round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()-syuppi)\n",
    "    a.append(mon)\n",
    "    b.append(syuppi)\n",
    "    c.append(round(kakekin*DAY[DAY['着順']==1]['単勝オッズ'].sum()))\n",
    "    d.append(profit)\n",
    "    e.append(round(len(DAY[DAY['着順']==1])/race_num*100,1))\n",
    "    f.append(round(DAY[DAY['着順']==1]['単勝オッズ'].sum()/len(DAY),2))\n",
    "    g.append(race_num)\n",
    "    summoney = summoney+profit\n",
    "monthdf = pd.DataFrame(\n",
    "        data={'月': a, '出費': b, '当金': c, '利益': d, '当率': e, '回収率': f, '対象レース': g},\n",
    "        columns=['月', '出費', '当金', '利益', '当率', '回収率', '対象レース'])\n",
    "print('１レース当たりの掛け金',kakekin)\n",
    "print('合計損益',summoney)\n",
    "print('回収率',round(monthdf['当金'].sum()/monthdf['出費'].sum(),2))\n",
    "print(monthdf[7:].mean())\n",
    "monthdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993e8f9-b6f9-4dc7-87c5-c3c6d030e0a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ハイブリット２形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bc72a-7d3f-4b71-8676-48b58a17544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = first_result.copy()\n",
    "test['単勝オッズ'] = test['単勝オッズ'].astype(str)\n",
    "test[['複勝オッズ_min', '複勝オッズ_max']] = 0\n",
    "hybrid2 = hybrid2_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a7d24-a383-4a46-a391-67a74b914141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('回収率',hybrid2[hybrid2['着順']<=1]['単勝オッズ'].sum()/len(hybrid2))\n",
    "print('平均的中オッズ',hybrid2[hybrid2['着順']<=1]['単勝オッズ'].mean())\n",
    "print('対象レース',len(hybrid2))\n",
    "print('対象レース割合',hybrid2['race_id'].nunique()/first_result['race_id'].nunique())\n",
    "print('的中レース',len(hybrid2[hybrid2['着順']<=1]))\n",
    "print('的中率',(len(hybrid2[hybrid2['着順']<=1])/len(hybrid2)))\n",
    "print('出現確率',hybrid2['date'].nunique()/first_result['date'].nunique())\n",
    "hybrid2[hybrid2['着順']<=1]['単勝オッズ'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81565aee-9e9a-49bb-a48d-2192176cfdf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 後日作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18615cfd-1823-499f-a45b-13d90da4f322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "#その日に開催されるレースIDと日付けを指定する\n",
    "#日付は予測値に影響を与えるので注意(hrのマージの日付になる)\n",
    "\"\"\"\n",
    "date = '2022年10月30日'\n",
    "#開催場所に合わせて設定\n",
    "racenum = 12\n",
    "race_id_list1 = ['2022060401{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "race_id_list2 = ['2022070501{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "# race_id_list3 = ['2022010203{}'.format(str(i).zfill(2)) for i in range(1, racenum+1, 1)]\n",
    "# race_id_list = race_id_list1 + race_id_list2 + race_id_list3\n",
    "race_id_list = race_id_list1 + race_id_list2\n",
    "\n",
    "print(len(race_id_list))\n",
    "date_list = [date]*len(race_id_list)\n",
    "race_id_day_dict = dict(zip(race_id_list,date_list))\n",
    "race_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0a4e5-84e5-464d-93f9-8062d7da549b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle','pickle/syutuba/race/syutuba_{}.pickle'.format(date)])\n",
    "st.data.to_pickle('pickle/syutuba/race/syutuba_latest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6327e16-1ea2-4049-881c-bdf1002c2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=ShutubaTable.read_pickle(['pickle/syutuba/race/syutuba_latest.pickle'])\n",
    "#不足データがある場合、スクレイピングされ常に更新されていく\n",
    "hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "st.merge_horse_info(hi)\n",
    "jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "st.merge_jockey_info(jr,5)\n",
    "st.preprocessing()\n",
    "r = Results.read_pickle(['pickle/syutuba/r_data/r_data_latest.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a51d2-0d67-4c2c-90a3-eb17d16d4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(st.data.index[~st.data.index.isin(r.data.index)].unique()))\n",
    "st.data.index[~st.data.index.isin(r.data.index)].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cde2d7-7ed1-4579-ba91-e46776c2d041",
   "metadata": {},
   "source": [
    "## resultsの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fecb10-16b1-4888-98ea-933ebd6c31a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rデータのstとの差分をスクレイプし更新する\n",
    "date = '2022年11月27日'\n",
    "r = Results.read_pickle(['pickle/syutuba/r_data/r_data_latest.pickle'])\n",
    "diff_race_id_list = st.data.index[~st.data.index.isin(r.data.index)].unique()\n",
    "results = Results.scrape(diff_race_id_list)\n",
    "results.to_pickle('pickle/syutuba/r_data/r_data_{}.pickle'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0fb76-968f-4f05-aa5f-732b7188b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_race_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761c959-c280-4d94-bab0-679123f34eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd53287-88fc-4bd0-93b0-5f497211d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "del r\n",
    "r=Results.read_pickle(['pickle/syutuba/r_data/r_data_latest.pickle','pickle/syutuba/r_data/r_data_{}.pickle'.format(date)])\n",
    "r.data.to_pickle('pickle/syutuba/r_data/r_data_latest.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ccf71c-c240-4a07-a053-72ffbed5ac13",
   "metadata": {},
   "source": [
    "## return_tablesの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cad30f-e731-4812-aeb1-219e5e325ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stとの差分\n",
    "rt_st = Return.read_pickle(['pickle/syutuba/latest/return_table_latest.pickle'])\n",
    "my_list = st.data.index[~st.data.index.isin(rt_st.return_tables.index)].unique()\n",
    "\n",
    "#不足があった場合、適当な日付で取得\n",
    "my_dict = {}\n",
    "day = '2022年11月27日'\n",
    "day_list = [day]*len(my_list)\n",
    "my_dict = dict(zip(my_list,day_list))\n",
    "len(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f48cbb-c63a-4bca-8915-ed8b447634ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rt_st = Return.scrape(my_dict)\n",
    "rt_st.to_pickle('pickle/syutuba/return/return_table_{}.pickle'.format(date))\n",
    "\n",
    "# #最新に更新\n",
    "del rt_st\n",
    "rt_st = Return.read_pickle(['pickle/syutuba/latest/return_table_latest.pickle','pickle/syutuba/return/return_table_{}.pickle'.format(date)])\n",
    "rt_st.return_tables.to_pickle('pickle/syutuba/latest/return_table_latest.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7824bb-c1bc-433f-8c60-dd8ba4fffaf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## resultsの更新データを反映"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194db6b-b96b-4647-946e-181c171c049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#testデータ作成用\n",
    "#最新データかつSTデータと同様でなければシミュレーションとして成り立たないため\n",
    "r = Results.read_pickle(['pickle/syutuba/r_data/r_data_latest.pickle'])\n",
    "jr = jockey_results.read_pickle(['pickle/syutuba/latest/jockey_id_latest.pickle'])\n",
    "hr = HorseResults.read_pickle(['pickle/syutuba/latest/horse_results_latest.pickle'])\n",
    "hi = HorseInfo.read_pickle(['pickle/syutuba/latest/h_info_latest.pickle'])\n",
    "p = Peds.read_pickle(['pickle/syutuba/latest/peds_id_latest.pickle'])\n",
    "\n",
    "past_race_num=10\n",
    "t = time.time()\n",
    "r.merge_horse_info(hi)\n",
    "r.merge_jockey_info(jr,5)\n",
    "time_protcol()\n",
    "r.preprocessing()\n",
    "time_protcol()\n",
    "hr.preprocessing()\n",
    "hr_p_backup = hr.horse_results_p.copy() #毎回作成する必要がないようにbuckupとして保持\n",
    "time_protcol()\n",
    "r.merge_horse_results(hr, n_samples_list=[5,9,'all'])\n",
    "# r.merge_horse_results(hr, n_samples_list=[5])\n",
    "r.concat_past_data(hr,past_race_num)\n",
    "t = time.time()\n",
    "p.encode()\n",
    "r.merge_peds(p.peds_e)\n",
    "r.process_categorical(past_race_num)\n",
    "time_protcol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5025cb-b0c3-4f54-bce9-151a9799f361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r.data_p['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def142d5-40f8-4aea-8676-46e37cee8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_p.to_pickle('pickle/r_data19_21/r_data_p22.pickle')\n",
    "r.data_pe.to_pickle('pickle/r_data19_21/r_data_pe22.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ee1dc-8701-47a8-ad57-8f6649dad74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
